<!-- Re-define labels for tables and figures -->
\captionsetup[table]{name=Supplementary Table}
\captionsetup[figure]{name=Supplementary Fig.}

<!-- Restart numbering of figures, tables, equations, and pages -->
\renewcommand{\thefigure}{\arabic{figure}}
\renewcommand{\thetable}{\arabic{table}}
\renewcommand{\theequation}{\arabic{table}}
\setcounter{figure}{0}
\setcounter{table}{0}
\setcounter{equation}{0}
\setcounter{page}{1}

# Supplementary information

<!-- Supplementary methods -->

## Supplementary Methods 1: Correlation between dependent samples

```{r, r_assumed}
# Compute empirical estimate of the correlation between dependent samples
dat %>%
  mutate(
    # Get effect size from paired samples t-test, one sample t-test, or ANOVA
    d_diff = case_when(
      !is.na(d) ~ d,
      !is.na(d_z_t) ~ d_z_t,
      !is.na(d_z_f) ~ d_z_f,
      !is.na(d_z_diff) ~ d_z_diff
    ),
    # Compute empirical correlation
    # Based on the SD of the difference and the SDs within the two conditions
    sd_diff = mean_diff / d_diff,
    ri = (sd_diff^2 - sd_novel^2 - sd_familiar^2) /
      (-2 * sd_novel * sd_familiar)
  ) %>%
  pull(ri) -> ri_empirical

# Subset articles that have an empirical estimate for the correlation
dat_ri_empirical <- filter(dat, !is.na(ri_empirical))

# Summarise the estimated correlations
(summ_ri_empirical <- print_num(summary(ri_empirical)))
```

Meta-analytic methods require an estimate of the sampling variance of each included experiment [@harrer2021]. For within-participant experimental designs (i.e., repeated measures on the same individuals in different conditions), this sampling variance needs to reflect that repeated measures from the same participant will be more similar to one another than measures from two randomly selected participants, thus not providing independent information. This is reflected by the correlation term $r$ in the formula of the standard error of the effect size ${SE}_\text{rotation}$ (see Methods) [@goulet-pelletier2018]. This correlation between repeated measures unfortunately tends to go unreported in research articles. In fact, none of the `r descs$n_articles` articles in the present meta-analysis provided a direct numerical estimate for the correlation between infants' looking times in the novel and familiar rotation object conditions.

However, there were `r nrow(dat_ri_empirical)` experiments taken from seven different articles that included enough statistical information to reconstruct this correlation. This was done using the following procedure:

1. Extract an effect size $d_\text{diff}$ based on a paired $t$-test, a one-sample $t$-test of difference scores, or an ANOVA (see Rows (1) to (4) in Table 1). All three of these tests take the correlation between the repeated measures into account.

2. Extract the mean looking time difference $m_\text{diff}$ (in seconds) between the novel and familiar conditions.

3. Compute the standard deviation of the mean looking time difference: $${SD}_\text{diff}=\frac{m_\text{diff}}{d_\text{diff}}$$

4. Extract the standard deviations ${SD}_\text{novel}$ and ${SD}_\text{familiar}$ of looking times within each of the two conditions.

5. Compute the observed correlation between conditions based on rearranging an equation by @cohen1988: $$r=\frac{{SD}_\text{diff}^2-{SD}_\text{novel}^2-{SD}_\text{familiar}}{-2\cdot{SD}_\text{novel}^2\cdot{SD}_\text{familiar}^2}$$

Across these $`r nrow(dat_ri_empirical)`$ experiments, the average observed correlation was $r = `r summ_ri_empirical["Mean"]`$ (median $r = `r summ_ri_empirical["Median"]`$, range [`r summ_ri_empirical["Min."]`, `r summ_ri_empirical["Max."]`]). However, we decided to assume a correlation of $r  = .50$ when computing ${SE}_\text{rotation}$ for all `r descs$n_experiments` experiments. This was to ensure the comparability of our methods to meta-analyses of between-participant studies [@cohen1988; @lakens2013; @morris2002]. We ran a sensitivity analysis to test the robustness of our Bayesian meta-analytic model against this assumption (Supplementary Table 4).

## Supplementary Methods 2: Bias correction and sensitivity analysis for frequentist results

We used a simplified two-level version (i.e., dropping the article level) of our frequentist three-level model to further correct our results for publication bias. We conducted a trim-and-fill analysis [@duval2000] to impute possible effect sizes of non-published experiments and then observed their influence on the meta-analytic effect size (Supplementary Tables 8 and 9).

Next, we used selection models to approximate the selection process of experiments into the meta-analysis under the assumption that experiments that observe significant effects (i.e., with low p-values) are more likely to get published. We ran one selection model assuming a weight function with fixed *p*-value cutoffs [@vevea1995] at *p* = .01, *p* = .05, and *p* = .30, as well as multiple models with a priori selection functions that assume bias of varying severity [@vevea2005]. These analyses show that our results are robust to small to medium amounts of publication bias (Supplementary Tables 8 and 9).

<!-- Supplementary tables -->

```{r, tabs1, include=TRUE}
# Save within-analysis table of experiments
dat %>%
  mutate(
    age_mean = print_days_months(age_mean),
    age_sd = str_c(as.character(round(age_sd)), "d"),
  ) %>%
  transmute(
    Article = if_else(article == lag(article, default = ""), "", article),
    Experiment = group_long,
    `Sample size` = as.integer(sample_size),
    `Females` = as.integer(round(female_percent * sample_size)),
    Age = str_c(age_mean, "Â±", age_sd, sep = " "),
    Task = task,
    `Stimulus type` = str_to_sentence(stimuli_presentation),
    `Stimulus dimensions` = stimuli_dimensions
  ) -> tabs1

# Display the table
apa_table(
  tabs1,
  caption = "Experiments included in the main analysis",
  landscape = TRUE, font_size = "scriptsize"
)

# Save the table
dir.create(tables_dir, showWarnings = FALSE)
write_csv(tabs1, file = here(tables_dir, "tabs1_experiments.csv"), na = "n/a")
```

```{r, frequentist}
# Three-level model
res_freq <- rma.mv(
  gi, vi,
  random = ~ 1 | article / experiment,
  data = dat,
  slab = experiment
)
print(res_freq)

# Check share of variance at each level of the model
round(res_freq$sigma2[1] / sum(res_freq$sigma2), 3) # Between-art. (ICC)
round(res_freq$sigma2[2] / sum(res_freq$sigma2), 3) # Within-art. (between-exp.)

# Get profile likelihoods for sigmas to check that REML has converged
prof_liks <- profile(res_freq, plot = FALSE)

# Meta-regression with gender, age, and task
res_reg_freq <- rma.mv(
  gi, vi,
  mods = ~ gender * age_c + task,
  random = ~ 1 | article / experiment,
  data = dat,
  slab = experiment
)
print(res_reg_freq)

# Meta-analysis of gender differences
res_gender_freq <- rma.mv(
  gi, vi,
  random = ~ 1 | article / experiment,
  data = dat_gender,
  slab = experiment
)
print(res_gender_freq)
```

```{r, tabs2, include=TRUE}
# Format all frequentist results together as a table
map2_dfr(
  list(res_freq, res_reg_freq, res_gender_freq),
  c(
    "Meta-analysis of mental rotation",
    "Meta-regression of mental rotation",
    "Meta-analysis of gender differences"
  ),
  ~ print_res_freq_table(
    res_freq = .x, label_1 = .y, label_col_1 = "Model", print_sigma2s = TRUE
  )
) %>%
  # Rename parameters for readability
  mutate(
    Parameter = c(
      "Hedges' $g$",
      "$\\sigma_{\\text{Article}}^2$",
      "$\\sigma_{\\text{Experiment}}^2$",
      "Intercept (Hedges' $g$)",
      "Female - mixed",
      "Male - female",
      "Age (per year)",
      "Habituation - VoE",
      "(Female - mixed) $\\times$ age",
      "(Male - female) $\\times$ age",
      "$\\sigma_{\\text{Article}}^2$",
      "$\\sigma_{\\text{Experiment}}^2$",
      "Hedges' $g$",
      "$\\sigma_{\\text{Article}}^2$",
      "$\\sigma_{\\text{Experiment}}^2$"
    )
  ) %>%
  # Replace NAs with blank cells
  mutate(across(.fns = ~ ifelse(is.na(.), "", .))) -> tab_freq

# Display the table
apa_table(
  tab_freq,
  caption = "Frequentist meta-analyses and meta-regression",
  font_size = "scriptsize",
  escape = FALSE,
  align = "llrrrrr",
)

# Save the table
write_csv(tab_freq, file = here(tables_dir, "tabs2_frequentist.csv"))
```

```{r, jackknife}
# Re-run the jackknife analysis only if requested
if (run$jackknife_analysis) {

  # Re-fit the meta-analysis, leaving one experiment out at a time
  # Using parallelization with `furrr`
  n_cores <- availableCores()
  n_workers <- n_cores %/% n_chains
  plan(multisession, workers = n_workers)
  future_map_dfr(seq_len(nrow(dat)), function(jackknife_index) {
    dat_jackknife <- dat[-jackknife_index, ]
    res_jackknife <- update(res_brm, newdata = dat_jackknife, refresh = 0)
    print_res_table(
      res_jackknife,
      label_1 = dat$article[jackknife_index],
      label_2 = dat$group_long[jackknife_index],
      label_col_1 = "Article", label_col_2 = "Experiment"
    )
  }) %>%
    # Show article labels only for the first experiment per article
    mutate(
      Article = if_else(Article == lag(Article, default = ""), "", Article),
    ) -> tab_jackknife

  # Save the table
  write_csv(tab_jackknife, file = here(tables_dir, "jackknife.csv"))
}
```

```{r, tabs3, include=TRUE}
# Read jackknife table from file
tab_jackknife <- read_csv(
  here(tables_dir, "jackknife.csv"),
  col_types = "c", na = character()
)

# Display the table
apa_table(
  tab_jackknife,
  caption = "Jackknife (leave-one-out) analysis", font_size = "scriptsize",
  landscape = TRUE, escape = FALSE, align = "llrrrr"
)
```

```{r, tabs4, include=TRUE}
# Read PRISMA checklist from file
tab_prisma <- read_csv(
  here(data_dir, "prisma_checklist.csv"),
  col_types = "ccc"
)

# Display the table
apa_table(
  tab_prisma,
  caption = "PRISMA 2020 checklist",
  font_size = "scriptsize",
  align = "lrl",
)
```

```{r, sensitivity_analysis}
# Re-run the sensitivity analyses only if requested
if (run$sensitivity_analysis) {

  # Re-run the meta-analysis for different values of r_assumed
  seq(-0.9, 0.9, by = 0.3) %>%
    map_dfr(function(ri_sens) {

      # Re-compute standard errors of the effect sizes
      mutate(
        dat,
        vi = (dfi / (dfi - 2)) * ((2 * (1 - ri_sens)) / ni) *
          (1 + gi^2 * (ni / (2 * (1 - ri_sens)))) - (gi^2 / ji^2),
        sei = sqrt(vi)
      ) -> dat_ri_sens

      # Re-run meta-analysis
      res <- update(res_brm, newdata = dat_ri_sens, refresh = 0)

      # Re-run meta-regression
      res_reg <- update(res_brm_reg, newdata = dat_ri_sens, refresh = 0)

      # Return both as a tibble together with the label
      return(
        tibble(
          manipulation_value = str_c("$r$ = ", print_num(ri_sens)),
          res = list(res),
          res_reg = list(res_reg),
        )
      )
    }) %>%
    bind_cols(
      manipulation_name = c("Assumed correlation", rep("", nrow(.) - 1)), .
    ) -> sens_ri

  # Prior sensitivity analysis
  list(
    `$b\\sim\\mathcal{U}(-10,10)$` = c(
      set_prior("uniform(-10, 10)", class = "b", coef = "Intercept"),
      set_prior("normal(0, 0.5)", class = "b"),
      set_prior("cauchy(0, 0.3)", class = "sd")
    ),
    `$b\\sim\\mathcal{N}(0,0.2)$` = c(
      set_prior("normal(0, 0.2)", class = "b", coef = "Intercept"),
      set_prior("normal(0, 0.5)", class = "b"),
      set_prior("cauchy(0, 0.3)", class = "sd")
    ),
    `$\\sigma\\sim\\mathcal{U}(0,10)$` = c(
      set_prior("normal(0, 1)", class = "b", coef = "Intercept"),
      set_prior("normal(0, 0.5)", class = "b"),
      set_prior("uniform(0, 10)", class = "sd")
    ),
    `$\\sigma\\sim\\text{Student-}t(10,0,0.2)$` = c(
      set_prior("normal(0, 1)", class = "b", coef = "Intercept"),
      set_prior("normal(0, 0.5)", class = "b"),
      set_prior("student_t(10, 0, 0.2)", class = "sd")
    )
  ) %>%
    map2_dfr(names(.), function(prior_sens, prior_name) {

      # Re-run meta-analysis of mental rotation performance
      res <- update(res_brm, prior = prior_sens, refresh = 0)

      # Re-run meta-regression of mental rotation performance
      res_reg <- update(res_brm_reg, prior = prior_sens, refresh = 0)

      # Re-run meta-analysis of gender differences
      res_gender <- update(res_brm_gender, prior = prior_sens, refresh = 0)

      # Return both as a tibble together with the label
      return(
        tibble(
          manipulation_value = prior_name,
          res = list(res),
          res_reg = list(res_reg),
          res_gender = list(res_gender)
        )
      )
    }) %>%
    bind_cols(
      manipulation_name = c("Prior specification", rep("", nrow(.) - 1)), .
    ) -> sens_prior

  # Combine results from all sensitivity analyses
  sens <- bind_rows(sens_ri, sens_prior)

  # Create table for the (main) meta-analysis of mental rotation performance
  sens %>%
    select(res, manipulation_name, manipulation_value) %>%
    pmap_dfr(function(res, manipulation_name, manipulation_value) {
      print_res_table(
        res,
        label_1 = manipulation_name, label_2 = manipulation_value,
        label_col_1 = "Manipulation", label_col_2 = " "
      )
    }) -> tab_sens
  write_csv(tab_sens, file = here(tables_dir, "sens.csv"))

  # Create table for the meta-regression of mental rotation performance
  sens %>%
    select(
      res_reg, manipulation_name, manipulation_value
    ) %>%
    pmap_dfr(function(res_reg, manipulation_name, manipulation_value) {
      print_res_reg_table(
        res_reg,
        label_1 = manipulation_name, label_2 = manipulation_value,
        label_col_1 = "Manipulation", label_col_2 = " "
      )
    }) -> tab_sens_reg
  write_csv(tab_sens_reg, file = here(tables_dir, "sens_reg.csv"))

  # Create table for the meta-analysis of gender differences
  sens %>%
    filter(!map_lgl(res_gender, is.null)) %>%
    select(res_gender, manipulation_name, manipulation_value) %>%
    pmap_dfr(function(res_gender, manipulation_name, manipulation_value) {
      print_res_table(
        res_gender,
        label_1 = manipulation_name, label_2 = manipulation_value,
        label_col_1 = "Manipulation", label_col_2 = " "
      )
    }) -> tab_sens_gender
  write_csv(tab_sens_gender, file = here(tables_dir, "sens_gender.csv"))
}
```

```{r, tabs5, include=TRUE}
# Load sensitivity analysis table from file
tab_sens <- read_csv(
  here(tables_dir, "sens.csv"),
  col_types = "c", na = character(), trim_ws = FALSE
)

# Display the table
apa_table(
  tab_sens,
  caption = "Sensitivity analyses for the meta-analysis of mental rotation performance",
  font_size = "scriptsize", escape = FALSE, align = "llrrrr"
)
```

```{r, tabs6, include=TRUE}
# Load sensitivity analysis table from file
tab_sens_reg <- read_csv(
  here(tables_dir, "sens_reg.csv"),
  col_types = "c", na = character(), trim_ws = FALSE
)

# Display the table
apa_table(
  tab_sens_reg,
  caption = "Sensitivity analyses for the meta-regression of mental rotation performance",
  font_size = "scriptsize", landscape = TRUE, escape = FALSE,
  align = "llrrrrrrr"
)
```

```{r, tabs7, include=TRUE}
# Load sensitivity analysis table from file
tab_sens_gender <- read_csv(
  here(tables_dir, "sens_gender.csv"),
  col_types = "c", na = character(), trim_ws = FALSE
)

# Display the table
apa_table(
  tab_sens_gender,
  caption = "Sensitivity analyses for the meta-analysis of gender differences",
  font_size = "scriptsize", escape = FALSE, align = "llrrrrrrr"
)
```

```{r, trim_fill_selection, include=TRUE}
# Re-fit the two frequentist meta-analyses using a two-level model
# This is because `rma.mv()` is not supported for trim-and-fill/selection models
list(meta = dat, gender = dat_gender) %>%
  map(function(x) rma.uni(gi, vi, data = x)) -> res_freq_2_lvl

# Trim-and-fill analysis
res_freq_2_lvl %>% map(trimfill) -> res_trim_fill

# Easy weight function selection model (see metafor docs and Lauer et al., 2019)
res_freq_2_lvl %>%
  map(selmodel, type = "stepfun", steps = c(0.01, 0.05, 0.30, 1.00)) ->
res_selection_weights

# More selection models based on four different step functions
res_freq_2_lvl %>%
  map(function(res) {

    # Define custom step functions
    tibble(
      delta_one_tailed_moderate = c(
        1, 0.99, 0.95, 0.80, 0.75, 0.65, 0.60, 0.55,
        0.50, 0.50, 0.50, 0.50, 0.50, 0.50
      ),
      delta_one_tailed_severe = c(
        1, 0.99, 0.90, 0.75, 0.60, 0.50, 0.40, 0.35,
        0.30, 0.25, 0.10, 0.10, 0.10, 0.10
      ),
      delta_two_tailed_moderate = c(
        1, 0.99, 0.95, 0.90, 0.80, 0.75, 0.60, 0.60,
        0.75, 0.80, 0.90, 0.95, 0.99, 1.00
      ),
      delta_two_tailed_severe = c(
        1, 0.99, 0.90, 0.75, 0.60, 0.50, 0.25, 0.25,
        0.50, 0.60, 0.75, 0.90, 0.99, 1.00
      )
    ) %>%
      # Fit selection model for every step function
      map(function(delta) {
        selmodel(
          res,
          type = "stepfun",
          steps = c(
            0.005, 0.01, 0.05, 0.10, 0.25, 0.35, 0.50,
            0.65, 0.75, 0.90, 0.95, 0.99, 0.995, 1
          ),
          delta = delta
        )
      })
  }) -> res_selection_steps

# Create separate tables for the two different meta-analyses (rotation/gender)
# Each table will contain the results of all trim-and-fill and selection models
map(names(res_freq_2_lvl), function(name) {

  # Combine two-level, trim-and-fill, and selection models
  tibble(
    res = c(
      list(
        res_freq_2_lvl[[name]],
        res_trim_fill[[name]],
        res_selection_weights[[name]]
      ),
      res_selection_steps[[name]]
    ),
    label_1 = c(
      "Two-level model", "Trim-and-fill model",
      "Selection models", "", "", "", ""
    ),
    label_2 = c(
      "--", "--", "Weight function [.01, .05, .30]",
      "One-tailed, moderate bias", "One-tailed, severe bias",
      "Two-tailed, moderate bias", "Two-tailed, severe bias"
    )
  ) %>%
    # Combine and format as a table
    pmap_dfr(
      ~ print_res_freq_table(
        res_freq = ..1, label_1 = ..2, label_2 = ..3,
        label_col_1 = "Model", label_col_2 = "Sub-model",
        print_sigma2s = FALSE
      )
    ) %>%
    select(-Parameter) %>%
    rename(`Hedges' $g$` = Estimate)
}) %>%
  set_names(names(res_freq_2_lvl)) -> tabs_trim_fill_selection

# Save the tables
write_csv(
  tabs_trim_fill_selection$meta,
  file = here(tables_dir, "trim_fill_selection_meta.csv")
)
write_csv(
  tabs_trim_fill_selection$gender,
  file = here(tables_dir, "trim_fill_selection_gender.csv")
)
```

```{r, tabs8, include=TRUE}
# Display the table
apa_table(
  tabs_trim_fill_selection$meta,
  caption = "Publication bias correction for the meta-analysis of mental rotation performance",
  font_size = "scriptsize", escape = FALSE, align = "llrrrrr"
)
```

```{r, tabs9, include=TRUE}
# Display the table
apa_table(
  tabs_trim_fill_selection$gender,
  caption = "Publication bias correction for the meta-analysis of gender differences",
  font_size = "scriptsize", escape = FALSE, align = "llrrrrr",
)
```

<!-- Supplementary figures -->

```{r, figs1, include=TRUE, fig.height=10, fig.width=12, fig.cap="(ref:figs1-caption)"}
# Get posterior draws for the effect in each experiment
epred_draws_brm_gender <- epred_draws(res_brm_gender, dat_gender, ndraws = NULL) %>%
  mutate(experiment_f = factor(experiment))

# Create forest plot
dat_gender %>%
  # Make sure the plot will be ordered alphabetically by experiment IDs
  arrange(experiment) %>%
  mutate(
    experiment_f = fct_rev(fct_expand(factor(experiment), "model")),
    # Show article labels only for the first experiment per article
    article = if_else(article == lag(article, default = ""), "", article),
    # Compute frequentist confidence intervals
    ci_lb = gi - qnorm(0.05 / 2, lower.tail = FALSE) * sqrt(vi),
    ci_ub = gi + qnorm(0.05 / 2, lower.tail = FALSE) * sqrt(vi),
    ci_print = print_mean_ci(gi, ci_lb, ci_ub)
  ) %>%
  # Prepare plotting canvas
  ggplot(aes(x = gi, y = experiment_f)) +
  geom_vline(xintercept = seq(-3, 3, 0.5), color = "grey90") +
  # Add article and group labels as text on the left
  geom_text(aes(x = -9.9, label = article), hjust = 0) +
  geom_text(aes(x = -7.1, label = group_long), hjust = 0) +
  # Add experiment-specific effect sizes and CIs as text on the right
  geom_text(aes(x = 3.7, label = print_num(gi)), hjust = 1) +
  geom_text(aes(x = 4.4, label = print_num(ci_lb)), hjust = 1) +
  geom_text(aes(x = 5.1, label = print_num(ci_ub)), hjust = 1) +
  # Add Bayesian highest posterior density intervals for each experiment
  stat_interval(
    aes(x = .epred),
    data = epred_draws_brm_gender,
    alpha = .8,
    point_interval = "mean_qi",
    .width = c(0.5, 0.95),
  ) +
  scale_color_grey(
    start = 0.85, end = 0.65,
    labels = as_mapper(~ scales::percent(as.numeric(.x)))
  ) +
  # Add experiment-specific effect sizes and CIs as dots with error bars
  geom_linerange(aes(xmin = ci_lb, xmax = ci_ub), size = 0.35) +
  geom_point(aes(size = ni), shape = 22, fill = "white") + # Or (1 / vi)?
  # Add posterior distribution for the meta-analytic effect
  stat_halfeye(
    aes(x = intercept, y = -1),
    draws_brm_gender,
    point_interval = "mean_qi",
    .width = c(0.95)
  ) +
  annotate(
    "text",
    x = c(-9.9, 3.7, 4.4, 5.1),
    y = -0.5,
    label = c(
      "Three-level model",
      print_num(summ_brm_gender$intercept),
      print_num(summ_brm_gender$intercept.lower),
      print_num(summ_brm_gender$intercept.upper)
    ),
    hjust = c(0, 1, 1, 1),
    fontface = "bold"
  ) +
  # Add headers for each of the for columns
  annotate( # Just to make the grid lines disappear
    "rect",
    xmin = -Inf,
    xmax = Inf,
    ymin = nrow(dat_gender) + 0.5,
    ymax = Inf,
    fill = "white"
  ) +
  annotate(
    "text",
    x = c(-9.9, -7.1, 0, 3.7, 4.4, 5.1),
    y = nrow(dat_gender) + 1.5,
    label = c(
      "Article",
      "Experiment",
      "Effect size plot",
      "Effect size",
      "Lower",
      "Upper"
    ),
    hjust = c(0, 0, 0.5, 1, 1, 1),
    fontface = "bold"
  ) +
  # Styling
  coord_cartesian(
    ylim = c(-1.5, nrow(dat_gender) + 2), expand = FALSE, clip = "off"
  ) +
  scale_x_continuous(breaks = seq(-3, 3, 0.5)) +
  annotate("segment", x = -3.3, xend = 3.3, y = -1.5, yend = -1.5) +
  labs(
    x = expression("Hedges'" ~ italic("g")),
    size = "Sample size",
    color = "CrI level"
  ) +
  theme_minimal() +
  theme(
    legend.position = "bottom",
    axis.text.x = element_text(family = "Helvetica", color = "black"),
    axis.text.y = element_blank(),
    axis.ticks.x = element_line(colour = "black"),
    axis.title.x = element_text(hjust = 0.67, margin = margin(b = -15)),
    axis.title.y = element_blank(),
    panel.grid = element_blank(),
    text = element_text(family = "Helvetica")
  )

# Save the plot
ggsave(here(figures_dir, "figs1_gender.pdf"), width = 12, height = 8)
```

(ref:figs1-caption) **Meta-analysis of gender differences.** A Bayesian three-level meta-analysis provided evidence for a small gender difference in mental rotation performance between male and female infants. White squares indicate the effect sizes (Hedges' $g$) for gender difference in all individual experiments and black lines their 95% confidence intervals. Note that for experiments that observed a non-significant gender difference and did not specify the exact size of this effect, we assumed an effect size of $g = 0.00$. Gray bars indicate the 95% and 50% Bayesian credible interval (CrI) based on a Bayesian three-level random-effects model. Note that these intervals got shrunk towards the meta-analytic effect size because of partial pooling, that is, the three-level model regularizing the impact of experiments with small sample sizes and/or unrealistically large effect sizes. The last line shows the meta-analytic effect size from the three-level model (black dot) together with its 95% CrI (black line) and its posterior distribution (gray curve).

```{r, figs2, include=TRUE, fig.height=6, fig.width=12, fig.cap="(ref:figs2-caption)"}
# Extract convergence statistics from results
conv_stats <- with(summary(res_brm), tibble(
  parameter = c(
    "b_Intercept", "sd_article__Intercept", "sd_article:experiment__Intercept"
  ),
  name_expr = c(
    "\"Hedges'\" ~ italic(g)",
    "italic(sigma)[article]",
    "italic(sigma)[experiment]"
  ),
  r_hat = print_num(c(fixed$Rhat, map_dbl(random, ~ .$Rhat)), digits = 4),
  bulk_ess = round(c(fixed$Bulk_ESS, map_dbl(random, ~ .$Bulk_ESS))),
  tail_ess = round(c(fixed$Tail_ESS, map_dbl(random, ~ .$Tail_ESS))),
  r_hat_expr = str_c("italic(R)[hat] == ", r_hat),
  bulk_ess_expr = str_c("italic(N)[eff(bulk)] == ", bulk_ess),
  tail_ess_expr = str_c("italic(N)[eff(tail)] == ", tail_ess),
  y_pos = c(0.7, 0.75, 0.8)
))

# Create trace plot
n_draws <- n_iter - n_warmup
bayesplot::mcmc_trace(
  res_brm,
  pars = conv_stats$parameter, facet_args = list(ncol = 1)
) +
  geom_text(
    aes(y = 0.45, label = name_expr, color = NA),
    conv_stats,
    y = 0.45, x = -0.042 * n_draws, color = "black", parse = TRUE,
    vjust = 1, angle = 90
  ) +
  geom_text(
    aes(y = y_pos, label = r_hat_expr, color = NA),
    conv_stats,
    x = 0.684 * n_draws, hjust = 1, color = "black", parse = TRUE,
  ) +
  geom_text(
    aes(y = y_pos, label = bulk_ess_expr, color = NA),
    conv_stats,
    x = 0.842 * n_draws, hjust = 1, color = "black", parse = TRUE,
  ) +
  geom_text(
    aes(y = y_pos, label = tail_ess_expr, color = NA),
    conv_stats,
    x = n_draws, hjust = 1, color = "black", parse = TRUE,
  ) +
  labs(x = "Sample number", y = NULL, color = "MCMC\nchain") +
  coord_cartesian(expand = FALSE, clip = "off") +
  scale_x_continuous(limits = c(0, n_draws), breaks = seq(0, n_draws, 2000)) +
  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.2)) +
  scale_color_grey(start = 0.0, end = 0.9) +
  theme_classic() +
  theme(
    axis.line = element_line(colour = "black"),
    axis.text = element_text(family = "Helvetica", color = "black"),
    axis.ticks = element_line(color = "black"),
    plot.margin = margin(t = 10, l = 25),
    strip.background = element_blank(),
    strip.text = element_blank(),
    text = element_text(family = "Helvetica", color = "black")
  )

# Save the plot
ggsave(here(figures_dir, "figs2_convergence.pdf"), width = 12, height = 6)
```

(ref:figs2-caption) **Convergence checks for the Bayesian meta-analysis.** For each of the three parameters in the three-level meta-analytic model, gray traces show the exploration of the posterior distribution by four independent Markov Chain Monte Carlo (MCMC) chains. Overlap of the gray traces as well as random upward and downward fluctuations (rather than systematic drifts) indicate efficient exploration of the posterior distribution. $R\text{hat}$ = potential scale reduction factor, with values close to 1.0 indicating convergence of the chains, $N_\text{eff(bulk)}$ = bulk effective sample size, with larger values indicating better sampling efficiency in the bulk of the distribution (e.g., for estimating the posterior mean), $N_\text{eff(tail)}$ = tail effective sample size, with larger values indicating better sampling efficiency in the tails of the distribution (e.g., for estimating the 95% credible interval [CrI]). For details about these and other convergence criteria, we refer the reader to @vehtari2021.

```{r, figs3, include=TRUE, fig.height=4, fig.width=12, fig.cap="(ref:figs3-caption)"}
# Combine profile likelihood results into one data frame
prof_liks %>%
  head(-1) %>% # Remove the `comp` element
  map(~ tibble(sigma2 = .$sigma2, ll = .$ll)) %>%
  bind_rows(.id = "parameter") %>%
  # Create new labels for plotting
  mutate(parameter = factor(
    parameter,
    levels = c(1, 2),
    labels = c("italic(sigma)[article]^2", "italic(sigma)[experiment]^2")
  )) -> prof_liks_df

# Find the best-fitting parameter estimates
prof_liks_df %>%
  group_by(parameter) %>%
  filter(ll == max(ll)) -> prof_liks_max

# Create plot
prof_liks_df %>%
  ggplot(aes(x = sigma2, y = ll)) +
  facet_wrap(~parameter, scales = "free", labeller = label_parsed) +
  # Best fitting parameters
  geom_hline(
    aes(yintercept = ll),
    data = prof_liks_max, linetype = "dashed"
  ) +
  geom_vline(
    aes(xintercept = sigma2),
    data = prof_liks_max, linetype = "dashed"
  ) +
  # All tested parameters
  geom_point() +
  geom_line() +
  # Styling
  labs(x = "Parameter value", y = "Restricted log-likelihood") +
  theme_classic() +
  theme(
    axis.line = element_line(colour = "black"),
    axis.text = element_text(family = "Helvetica", color = "black"),
    axis.ticks = element_line(color = "black"),
    strip.background = element_blank(),
    strip.text = element_text(family = "Helvetica", color = "black", size = 12),
    text = element_text(family = "Helvetica", color = "black")
  )

# Save the plot
ggsave(here(figures_dir, "figs3_convergence_freq.pdf"), width = 12, height = 4)
```

(ref:figs3-caption) **Convergence checks for the frequentist meta-analysis.** Black curves show the profile of the restricted log likelihood for the two variance components in the frequentist three-level model. The two peaks indicate that restricted maximum likelihood estimation (REML) was able to converge on the most likely parameter estimates [@raue2009; @viechtbauer2010].

```{r, figs4, include=TRUE, fig.width=12, fig.height=3.5, fig.cap="(ref:figs4-caption)"}
# Create new funnel plots that take the trim-and-fill results into account
map2(res_trim_fill, plots_funnel, function(res, plot) {

  # Compute new funnel
  funnel_trim_fill <- with(
    list(
      z_crit_05 = stats::qnorm(0.975),
      max_se = max(sqrt(res$vi)) + 0.05
    ),
    {
      data.frame(
        x = c(
          res$b - z_crit_05 * sqrt(max_se^2),
          res$b,
          res$b + z_crit_05 * sqrt(max_se^2)
        ),
        y = c(max_se, 0, max_se)
      )
    }
  )

  # Add new funnel on top of the original funnel plot
  trim_fill_color <- ifelse(sum(res$fill) >= 1, "#e42536", NA)
  plot +
    # Add trim and fill funnel
    geom_path(
      data = funnel_trim_fill,
      aes(x = x, y = y),
      color = trim_fill_color
    ) +
    geom_vline(xintercept = res$b, color = trim_fill_color) +
    # Add filled in studies
    geom_point(
      data = with(res, tibble(gi = yi[fill], sei = sqrt(vi[fill]))),
      color = trim_fill_color, shape = 0
    )
}) -> plots_funnel_trim_fill

# Combine plots and legend
plot_grid(
  plotlist = plots_funnel_trim_fill, nrow = 1, labels = "auto",
  label_size = 11, label_fontfamily = "Helvetica"
) +
  draw_plot(legend_funnel, x = -0.39, y = 0.355)

# Save the plot
ggsave(here(figures_dir, "funnel_trim_fill.pdf"), width = 12, height = 3.5)
```

(ref:figs4-caption) **Trim-and-fill analyses.** As in Figure 3 in the main text, black squares indicate the effect sizes (x-axis) and standard errors (y-axis) of the individual experiments included in the meta-analysis of mental rotation performance (**a**) and in the meta-analysis of gender differences within each article (**b**). The funnel contours (diagonal black lines) depict a 95% pseudo-confidence interval around the meta-analytic effect sizes (vertical black lines). Gray shades indicate 95% pseudo-confidence intervals (dark gray) and 99% pseudo-confidence intervals (light gray) under the null hypothesis. Red squares show (fictional) experiments that were imputed via the trim-and-fill analyses, compensating for the small publication bias observed in the original funnel plots. Red lines show the meta-analytic effect sizes and its 95% pseudo-confidence interval for the trim-and-fill-corrected meta-analyses. Note that for the meta-analysis of gender differences, the trim-and-fill analysis suggested that no additional experiments had to be imputed.
