<!-- Re-define labels for tables and figures -->
\captionsetup[table]{name=Supplementary Table}
\captionsetup[figure]{name=Supplementary Fig.}

<!-- Restart numbering of figures, tables, equations, and pages -->
\renewcommand{\thefigure}{\arabic{figure}}
\renewcommand{\thetable}{\arabic{table}}
\renewcommand{\theequation}{\arabic{table}}
\setcounter{figure}{0}
\setcounter{table}{0}
\setcounter{equation}{0}
\setcounter{page}{1}

# Supplementary information

<!-- Supplementary methods -->

## Supplementary Methods 1 | Correlation between dependent samples

```{r, r_assumed}
# Compute empirical estimate of the correlation between dependent samples
dat_meta %>%
  mutate(
    # Get effect size from paired samples t-test, one sample t-test, or ANOVA
    d_diff = case_when(
      !is.na(d) ~ d,
      !is.na(d_z_t) ~ d_z_t,
      !is.na(d_z_f) ~ d_z_f,
      !is.na(d_z_diff) ~ d_z_diff
    ),
    # Compute empirical correlation
    # Based on the SD of the difference and the SDs within the two conditions
    sd_diff = mean_diff / d_diff,
    ri = (sd_diff^2 - sd_novel^2 - sd_familiar^2) /
      (-2 * sd_novel * sd_familiar)
  ) %>%
  pull(ri) -> ri_empirical

# Subset articles that have an empirical estimate for the correlation
dat_ri_empirical <- filter(dat_meta, !is.na(ri_empirical))

# Summarise the estimated correlations
(summ_ri_empirical <- print_num(summary(ri_empirical)))
```

Meta-analytic methods require an estimate of the sampling variance of each included experiment [@harrer2021]. For within-participant experimental designs, this sampling variance needs to account for the fact that repeated measures are taken from the same individuals in different conditions. Repeated measures from the same participant will be more similar to one another than measures from two randomly selected participants and thus do not provide independent information. This is accounted for by the correlation term $r$ in the formula of the standard error of the effect size ${SE}_\text{rotation}$ (see Methods) [@goulet-pelletier2018]. However, the correlation between repeated measures tends to go unreported in research articles. In fact, none of the `r descriptives$n_articles` articles in the present meta-analysis provided a direct numerical estimate for the correlation between infants' looking times in the novel and familiar rotation object conditions.

However, there were `r nrow(dat_ri_empirical)` experiments taken from seven different articles that included enough statistical information to reconstruct this correlation. This was done using the following procedure:

1. Extract an effect size $d_\text{diff}$ based on a paired $t$-test, a one-sample $t$-test of difference scores, or an analysis of variance (ANOVA) (see Rows (1) to (4) in Table 1). All three of these tests take the correlation between the repeated measures into account.

2. Extract the mean looking time difference $m_\text{diff}$ (in seconds) between the novel and familiar conditions.

3. Compute the standard deviation ($SD$) of the mean looking time difference: $${SD}_\text{diff}=\frac{m_\text{diff}}{d_\text{diff}}$$

4. Extract the standard deviation of looking times for the novel condition ${SD}_\text{novel}$ and the familiar condition ${SD}_\text{familiar}$.

5. Compute the observed correlation between conditions based on a rearranged equation by @cohen1988: $$r=\frac{{SD}_\text{diff}^2-{SD}_\text{novel}^2-{SD}_\text{familiar}}{-2\cdot{SD}_\text{novel}^2\cdot{SD}_\text{familiar}^2}$$

Across these $`r nrow(dat_ri_empirical)`$ experiments, the average observed correlation was $r = `r summ_ri_empirical["Mean"]`$ (median $r = `r summ_ri_empirical["Median"]`$, range [`r summ_ri_empirical["Min."]`, `r summ_ri_empirical["Max."]`]). However, we decided to assume a correlation of $r  = .50$ when computing the effect size ${SE}_\text{rotation}$ for all `r descriptives$n_experiments` experiments. This was to ensure the comparability of our methods to meta-analyses of between-participant studies [@cohen1988; @lakens2013; @morris2002]. To  evaluate the robustness of our Bayesian meta-analytic model against the assumption of a correlation of $r  = .50$ we ran a sensitivity analysis (Supplementary Table 4).

## Supplementary Methods 2 | Bias correction and sensitivity analysis for frequentist results

We used trim-and-fill analysis and selection models to examine if and how our meta-analytic results would change under different degrees of publication bias. For both of these types of models, we used a simplified two-level version of our frequentist three-level model as a basis. In our first step, we computed a trim-and-fill model [@duval2000] by imputing possible effect sizes of non-published experiments. This new model produces a symmetric funnel plot with no association between effect sizes and standard errors (Supplementary Tables 8 and 9).

In our next step, we used selection models to approximate the process by which experiments got selected into the meta-analysis. These models were based on the assumption that experiments yielding significant effects (i.e., small *p*-values) are more likely to get published. Specifically, we ran one selection model assuming a weight function with fixed *p*-value cutoffs [@vevea1995] at *p* = .01, *p* = .05, and *p* = .30. Additionally, we ran multiple models with a priori selection functions assuming biases of varying severity [@vevea2005]. These analyses  revealed that our results are robust to small to medium publication bias (Supplementary Tables 8 and 9).

<!-- Supplementary tables -->

\singlespacing
\renewcommand{\arraystretch}{0.97}

```{r, tabs1, include=TRUE}
# Save table of experiments for the meta-analysis of rotation
dat_meta %>%
  mutate(
    age_mean = print_days_months(age_mean),
    age_sd = str_c(as.character(round(age_sd)), "d"),
  ) %>%
  transmute(
    Article = if_else(article == lag(article, default = ""), "", article),
    Experiment = group_long,
    `Sample size` = as.integer(sample_size),
    Females = as.integer(round(female_percent * sample_size)),
    Age = str_c(age_mean, "Â±", age_sd, sep = " "),
    Task = task,
    `Stimulus type` = str_to_sentence(stimuli_presentation),
    `Stimulus dimensions` = stimuli_dimensions
  ) %>%
  mutate(
    across(.fns = function(x) ifelse(is.na(x), "n/a", x))
  ) -> tabs1

# Display the table
apa_table(
  tabs1,
  caption = "Experiments included in the main analysis",
  landscape = TRUE, font_size = "scriptsize"
)

# Save the table
dir.create(tables_dir, showWarnings = FALSE)
write_csv(tabs1, file = here(tables_dir, "tabs1_experiments.csv"), na = "n/a")
```

```{r, frequentist}
# Compute frequentist three-level model for the meta-analysis of rotation
res_freq_meta <- rma.mv(
  gi, vi,
  random = ~ 1 | article / experiment,
  data = dat_meta,
  slab = experiment
)
print(res_freq_meta)

# Check share of variance at each level of the model
round(res_freq_meta$sigma2[1] / sum(res_freq_meta$sigma2), 3)
round(res_freq_meta$sigma2[2] / sum(res_freq_meta$sigma2), 3)

# Get profile likelihoods for sigmas to check that REML has converged
prof_liks <- profile(res_freq_meta, plot = FALSE)

# Compute frequentist meta-regression with gender, age, and task
res_freq_reg <- rma.mv(
  gi, vi,
  mods = ~ gender * age_c + task,
  random = ~ 1 | article / experiment,
  data = dat_meta,
  slab = experiment
)
print(res_freq_reg)

# Compute frequentist three-level model for the meta-analysis of gender
res_freq_gender <- rma.mv(
  gi, vi,
  random = ~ 1 | article / experiment,
  data = dat_gender,
  slab = experiment
)
print(res_freq_gender)
```

\renewcommand{\arraystretch}{1.10}

```{r, tabs2, include=TRUE}
# Format all frequentist results together as a table
map2_dfr(
  list(res_freq_meta, res_freq_reg, res_freq_gender),
  c(
    "Meta-analysis of mental rotation",
    "Meta-regression of mental rotation",
    "Meta-analysis of gender differences"
  ),
  ~ print_res_freq_table(
    res_freq = .x, label_1 = .y, label_col_1 = "Model",
    print_sigma2s = TRUE
  )
) %>%
  # Rename parameter labels
  mutate(
    Parameter = c(
      "Hedges' $g$",
      "$\\sigma_{\\text{Article}}^2$",
      "$\\sigma_{\\text{Experiment}}^2$",
      "Intercept (Hedges' $g$)",
      "Female - mixed",
      "Male - female",
      "Age (per year)",
      "Habituation - VoE",
      "(Female - mixed) $\\times$ age",
      "(Male - female) $\\times$ age",
      "$\\sigma_{\\text{Article}}^2$",
      "$\\sigma_{\\text{Experiment}}^2$",
      "Hedges' $g$",
      "$\\sigma_{\\text{Article}}^2$",
      "$\\sigma_{\\text{Experiment}}^2$"
    )
  ) %>%
  # Replace NAs with blank cells
  mutate(across(.fns = ~ ifelse(is.na(.), "", .))) -> tabs2

# Display the table
apa_table(
  tabs2,
  caption = "Frequentist meta-analyses and meta-regression",
  font_size = "scriptsize",
  escape = FALSE,
  align = "llrrrrr",
)

# Save the table
write_csv(tabs2, file = here(tables_dir, "tabs2_frequentist.csv"))
```

```{r, jackknife}
# Re-run the jackknife analysis if requested
if (run$jackknife_analysis) {

  # Re-fit the meta-analysis, leaving out one experiment at a time
  # Using parallelization with `furrr`
  n_cores <- availableCores()
  n_workers <- n_cores %/% n_chains
  plan(multisession, workers = n_workers)
  future_map_dfr(seq_len(nrow(dat_meta)), function(jackknife_index) {
    dat_jackknife <- dat_meta[-jackknife_index, ]
    res_jackknife <- update(res_meta, newdata = dat_jackknife, refresh = 0)
    print_res_table(
      res_jackknife,
      label_1 = dat_meta$article[jackknife_index],
      label_2 = dat_meta$group_long[jackknife_index],
      label_col_1 = "Article", label_col_2 = "Experiment"
    )
  }) %>%
    # Show article labels only for the first experiment (row) per article
    mutate(
      Article = if_else(Article == lag(Article, default = ""), "", Article),
    ) -> tabs3

  # Save the table
  write_csv(tabs3, file = here(tables_dir, "tabs3_jackknife.csv"))
}
```

\renewcommand{\arraystretch}{0.97}

```{r, tabs3, include=TRUE}
# Read jackknife table from file
tabs3 <- read_csv(
  here(tables_dir, "tabs3_jackknife.csv"),
  col_types = "c", na = character()
)

# Display the table
apa_table(
  tabs3,
  caption = "Jackknife (leave-one-out) analysis", font_size = "scriptsize",
  landscape = TRUE, escape = FALSE, align = "llrrrr"
)
```

\renewcommand{\arraystretch}{1.30}

```{r, tabs4, include=TRUE}
# Read PRISMA checklist from file
tabs4 <- read_csv(
  here(data_dir, "prisma_checklist.csv"),
  col_types = "ccc", na = character()
)

# Display the table
apa_table(
  tabs4,
  caption = "PRISMA 2020 checklist", font_size = "scriptsize",
  landscape = TRUE, align = "p{1.5cm}p{2.5cm}p{1cm}p{12cm}p{5.5cm}",
)
```

```{r, sensitivity}
# Re-run the sensitivity analyses if requested
if (run$sensitivity_analysis) {

  # Re-run the meta-analysis for different values of r_assumed
  seq(-0.9, 0.9, by = 0.3) %>%
    map_dfr(function(ri_sens) {

      # Re-compute standard errors of the effect sizes
      mutate(
        dat_meta,
        vi = (dfi / (dfi - 2)) * ((2 * (1 - ri_sens)) / ni) *
          (1 + gi^2 * (ni / (2 * (1 - ri_sens)))) - (gi^2 / ji^2),
        sei = sqrt(vi)
      ) -> dat_ri_sens

      # Re-run meta-analysis of mental rotation performance
      res_meta <- update(res_meta, newdata = dat_ri_sens, refresh = 0)

      # Re-run meta-regression of mental rotation performance
      res_reg <- update(res_reg, newdata = dat_ri_sens, refresh = 0)

      # Return both as a tibble and add a label
      return(
        tibble(
          manipulation_value = str_c("$r$ = ", print_num(ri_sens)),
          res_meta = list(res_meta),
          res_reg = list(res_reg),
        )
      )
    }) %>%
    bind_cols(
      manipulation_name = c("Assumed correlation", rep("", nrow(.) - 1)), .
    ) -> sens_ri

  # Prior sensitivity analysis
  list(
    # Less informative prior for the intercept
    `$b\\sim\\mathcal{U}(-10,10)$` = c(
      set_prior("uniform(-10, 10)", class = "b", coef = "Intercept"),
      set_prior("normal(0, 0.5)", class = "b"),
      set_prior("cauchy(0, 0.3)", class = "sd")
    ),
    # More informative prior for the intercept
    `$b\\sim\\mathcal{N}(0,0.2)$` = c(
      set_prior("normal(0, 0.2)", class = "b", coef = "Intercept"),
      set_prior("normal(0, 0.5)", class = "b"),
      set_prior("cauchy(0, 0.3)", class = "sd")
    ),
    # Less informative prior for the standard deviations
    `$\\sigma\\sim\\mathcal{U}(0,10)$` = c(
      set_prior("normal(0, 1)", class = "b", coef = "Intercept"),
      set_prior("normal(0, 0.5)", class = "b"),
      set_prior("uniform(0, 10)", class = "sd")
    ),
    # More informative prior for the standard deviations
    `$\\sigma\\sim\\text{Student-}t(10,0,0.2)$` = c(
      set_prior("normal(0, 1)", class = "b", coef = "Intercept"),
      set_prior("normal(0, 0.5)", class = "b"),
      set_prior("student_t(10, 0, 0.2)", class = "sd")
    )
  ) %>%
    map2_dfr(names(.), function(prior_sens, prior_name) {

      # Re-run meta-analysis of mental rotation performance
      res_meta <- update(res_meta, prior = prior_sens, refresh = 0)

      # Re-run meta-regression of mental rotation performance
      res_reg <- update(res_reg, prior = prior_sens, refresh = 0)

      # Re-run meta-analysis of gender differences
      res_gender <- update(res_gender, prior = prior_sens, refresh = 0)

      # Return both as a tibble together with the label
      return(
        tibble(
          manipulation_value = prior_name,
          res_meta = list(res_meta),
          res_reg = list(res_reg),
          res_gender = list(res_gender)
        )
      )
    }) %>%
    bind_cols(
      manipulation_name = c("Prior specification", rep("", nrow(.) - 1)), .
    ) -> sens_prior

  # Combine results from all sensitivity analyses
  sens <- bind_rows(sens_ri, sens_prior)

  # Create table for the meta-analysis of mental rotation performance
  sens %>%
    select(res, manipulation_name, manipulation_value) %>%
    pmap_dfr(function(res, manipulation_name, manipulation_value) {
      print_res_table(
        res,
        label_1 = manipulation_name, label_2 = manipulation_value,
        label_col_1 = "Manipulation", label_col_2 = " "
      )
    }) -> tabs5
  write_csv(tabs5, file = here(tables_dir, "tabs5_sens_meta.csv"))

  # Create table for the meta-regression of mental rotation performance
  sens %>%
    select(
      res_reg, manipulation_name, manipulation_value
    ) %>%
    pmap_dfr(function(res_reg, manipulation_name, manipulation_value) {
      print_res_reg_table(
        res_reg,
        label_1 = manipulation_name, label_2 = manipulation_value,
        label_col_1 = "Manipulation", label_col_2 = " "
      )
    }) -> tabs6
  write_csv(tabs6, file = here(tables_dir, "tabs6_sens_reg.csv"))

  # Create table for the meta-analysis of gender differences
  sens %>%
    filter(!map_lgl(res_gender, is.null)) %>%
    select(res_gender, manipulation_name, manipulation_value) %>%
    pmap_dfr(function(res_gender, manipulation_name, manipulation_value) {
      print_res_table(
        res_gender,
        label_1 = manipulation_name, label_2 = manipulation_value,
        label_col_1 = "Manipulation", label_col_2 = " "
      )
    }) -> tabs7
  write_csv(tabs7, file = here(tables_dir, "tabs7_sens_gender.csv"))
}
```

\renewcommand{\arraystretch}{1.10}

```{r, tabs5, include=TRUE}
# Load sensitivity analysis table from file
tabs5 <- read_csv(
  here(tables_dir, "tabs5_sens_meta.csv"),
  col_types = "c", na = character(), trim_ws = FALSE
)

# Display the table
apa_table(
  tabs5,
  caption = "Sensitivity analyses for the meta-analysis of mental rotation performance",
  font_size = "scriptsize", escape = FALSE, align = "llrrrr"
)
```

```{r, tabs6, include=TRUE}
# Load sensitivity analysis table from file
tabs6 <- read_csv(
  here(tables_dir, "tabs6_sens_reg.csv"),
  col_types = "c", na = character(), trim_ws = FALSE
)

# Display the table
apa_table(
  tabs6,
  caption = "Sensitivity analyses for the meta-regression of mental rotation performance",
  font_size = "scriptsize", landscape = TRUE, escape = FALSE,
  align = "llrrrrrrr"
)
```

```{r, tabs7, include=TRUE}
# Load sensitivity analysis table from file
tabs7 <- read_csv(
  here(tables_dir, "tabs7_sens_gender.csv"),
  col_types = "c", na = character(), trim_ws = FALSE
)

# Display the table
apa_table(
  tabs7,
  caption = "Sensitivity analyses for the meta-analysis of gender differences",
  font_size = "scriptsize", escape = FALSE, align = "llrrrrrrr"
)
```

```{r, correction}
# Re-fit the two frequentist meta-analyses using a two-level model
# This is because `rma.mv()` is not supported for trim-and-fill/selection models
list(meta = dat_meta, gender = dat_gender) %>%
  map(function(x) rma.uni(gi, vi, data = x)) -> res_freq_2_lvl

# Trim-and-fill analysis
res_freq_2_lvl %>% map(trimfill) -> res_trim_fill

# Easy weight function selection model (see metafor docs and Lauer et al., 2019)
res_freq_2_lvl %>%
  map(selmodel, type = "stepfun", steps = c(0.01, 0.05, 0.30, 1.00)) ->
res_selection_weights

# More selection models based on four different step functions
res_freq_2_lvl %>%
  map(function(res) {

    # Define custom step functions
    tibble(
      delta_one_tailed_moderate = c(
        1, 0.99, 0.95, 0.80, 0.75, 0.65, 0.60, 0.55,
        0.50, 0.50, 0.50, 0.50, 0.50, 0.50
      ),
      delta_one_tailed_severe = c(
        1, 0.99, 0.90, 0.75, 0.60, 0.50, 0.40, 0.35,
        0.30, 0.25, 0.10, 0.10, 0.10, 0.10
      ),
      delta_two_tailed_moderate = c(
        1, 0.99, 0.95, 0.90, 0.80, 0.75, 0.60, 0.60,
        0.75, 0.80, 0.90, 0.95, 0.99, 1.00
      ),
      delta_two_tailed_severe = c(
        1, 0.99, 0.90, 0.75, 0.60, 0.50, 0.25, 0.25,
        0.50, 0.60, 0.75, 0.90, 0.99, 1.00
      )
    ) %>%
      # Fit selection model for every step function
      map(function(delta) {
        selmodel(
          res,
          type = "stepfun",
          steps = c(
            0.005, 0.01, 0.05, 0.10, 0.25, 0.35, 0.50,
            0.65, 0.75, 0.90, 0.95, 0.99, 0.995, 1
          ),
          delta = delta
        )
      })
  }) -> res_selection_steps

# Create separate tables for the two different meta-analyses (rotation/gender)
# Each table will contain the results of all trim-and-fill and selection models
map(names(res_freq_2_lvl), function(name) {

  # Combine two-level, trim-and-fill, and selection models
  tibble(
    res = c(
      list(
        res_freq_2_lvl[[name]],
        res_trim_fill[[name]],
        res_selection_weights[[name]]
      ),
      res_selection_steps[[name]]
    ),
    label_1 = c(
      "Two-level model", "Trim-and-fill model",
      "Selection models", "", "", "", ""
    ),
    label_2 = c(
      "--", "--", "Weight function [.01, .05, .30]",
      "One-tailed, moderate bias", "One-tailed, severe bias",
      "Two-tailed, moderate bias", "Two-tailed, severe bias"
    )
  ) %>%
    # Combine and format as a table
    pmap_dfr(
      ~ print_res_freq_table(
        res_freq = ..1, label_1 = ..2, label_2 = ..3,
        label_col_1 = "Model", label_col_2 = "Sub-model",
        print_sigma2s = FALSE
      )
    ) %>%
    select(-Parameter) %>%
    rename(`Hedges' $g$` = Estimate)
}) %>%
  set_names(names(res_freq_2_lvl)) -> tabs_correction

# Save the tables
write_csv(
  tabs_correction$meta,
  file = here(tables_dir, "tabs8_correction_meta.csv")
)
write_csv(
  tabs_correction$gender,
  file = here(tables_dir, "tabs9_correction_gender.csv")
)
```

```{r, tabs8, include=TRUE}
# Display the table
apa_table(
  tabs_correction$meta,
  caption = "Publication bias correction for the meta-analysis of mental rotation performance",
  font_size = "scriptsize", escape = FALSE, align = "llrrrrr"
)
```

```{r, tabs9, include=TRUE}
# Display the table
apa_table(
  tabs_correction$gender,
  caption = "Publication bias correction for the meta-analysis of gender differences",
  font_size = "scriptsize", escape = FALSE, align = "llrrrrr",
)
```

<!-- Supplementary figures -->

```{r, figs1, include=TRUE, fig.height=10, fig.width=12, fig.cap="(ref:figs1-caption)"}
# Get posterior draws for the effect *in each experiment*
epred_draws_gender <- epred_draws(res_gender, dat_gender, ndraws = NULL) %>%
  mutate(experiment_f = factor(experiment))

# Create forest plot
dat_gender %>%
  # Make sure the plot will be ordered alphabetically by experiment IDs
  arrange(experiment) %>%
  mutate(
    experiment_f = fct_rev(fct_expand(factor(experiment), "model")),
    # Show article labels only for the first experiment (row) per article
    article = if_else(article == lag(article, default = ""), "", article),
    # Compute frequentist confidence intervals
    ci_lb = gi - qnorm(0.05 / 2, lower.tail = FALSE) * sqrt(vi),
    ci_ub = gi + qnorm(0.05 / 2, lower.tail = FALSE) * sqrt(vi),
    ci_print = print_mean_ci(gi, ci_lb, ci_ub)
  ) %>%
  # Prepare plotting canvas
  ggplot(aes(x = gi, y = experiment_f)) +
  geom_vline(xintercept = seq(-3, 3, 0.5), color = "grey90") +
  # Add article and group labels as text on the left
  geom_text(aes(x = -9.9, label = article), hjust = 0) +
  geom_text(aes(x = -7.1, label = group_long), hjust = 0) +
  # Add experiment-specific effect sizes and CIs as text on the right
  geom_text(aes(x = 3.7, label = print_num(gi)), hjust = 1) +
  geom_text(aes(x = 4.4, label = print_num(ci_lb)), hjust = 1) +
  geom_text(aes(x = 5.1, label = print_num(ci_ub)), hjust = 1) +
  # Add Bayesian credible intervals for each experiment
  stat_interval(
    aes(x = .epred),
    data = epred_draws_gender,
    alpha = .8,
    point_interval = "mean_qi",
    .width = c(0.5, 0.95),
  ) +
  scale_color_grey(
    start = 0.85, end = 0.65,
    labels = as_mapper(~ scales::percent(as.numeric(.x)))
  ) +
  # Add experiment-specific effect sizes and CIs as dots with error bars
  geom_linerange(aes(xmin = ci_lb, xmax = ci_ub), size = 0.35) +
  geom_point(aes(size = ni), shape = 22, fill = "white") + # Or (1 / vi)?
  # Add posterior distribution for the meta-analytic effect
  stat_halfeye(
    aes(x = intercept, y = -1),
    draws_gender,
    point_interval = "mean_qi",
    .width = c(0.95)
  ) +
  annotate(
    "text",
    x = c(-9.9, 3.7, 4.4, 5.1),
    y = -0.5,
    label = c(
      "Three-level model",
      print_num(summ_gender$intercept),
      print_num(summ_gender$intercept.lower),
      print_num(summ_gender$intercept.upper)
    ),
    hjust = c(0, 1, 1, 1),
    fontface = "bold"
  ) +
  # Add column headers
  annotate(
    "rect",
    xmin = -Inf,
    xmax = Inf,
    ymin = nrow(dat_gender) + 0.5,
    ymax = Inf,
    fill = "white"
  ) +
  annotate(
    "text",
    x = c(-9.9, -7.1, 0, 3.7, 4.4, 5.1),
    y = nrow(dat_gender) + 1.5,
    label = c(
      "Article",
      "Experiment",
      "Effect size plot",
      "Effect size",
      "Lower",
      "Upper"
    ),
    hjust = c(0, 0, 0.5, 1, 1, 1),
    fontface = "bold"
  ) +
  # Styling
  coord_cartesian(
    ylim = c(-1.5, nrow(dat_gender) + 2), expand = FALSE, clip = "off"
  ) +
  scale_x_continuous(breaks = seq(-3, 3, 0.5)) +
  annotate("segment", x = -3.3, xend = 3.3, y = -1.5, yend = -1.5) +
  labs(
    x = expression("Hedges'" ~ italic("g")),
    size = "Sample size",
    color = "CrI level"
  ) +
  theme_minimal() +
  theme(
    legend.position = "bottom",
    axis.text.x = element_text(family = "Helvetica", color = "black"),
    axis.text.y = element_blank(),
    axis.ticks.x = element_line(colour = "black"),
    axis.title.x = element_text(hjust = 0.67, margin = margin(b = -15)),
    axis.title.y = element_blank(),
    panel.grid = element_blank(),
    text = element_text(family = "Helvetica")
  )

# Save the plot
ggsave(here(figures_dir, "figs1_gender.pdf"), width = 12, height = 8)
```

(ref:figs1-caption) **Meta-analysis of gender differences.** A Bayesian three-level meta-analysis provided evidence for a small gender difference in mental rotation performance between male and female infants. White squares indicate the effect sizes (Hedges' $g$) of gender differences in all individual experiments and black lines indicate their 95% confidence intervals. For experiments resulting in a non-significant gender difference and for which the authors did not specify the exact size of this effect, we assumed an effect size of $g = 0.00$. Gray bars depict the 95% and 50% Bayesian credible interval (CrI) based on a Bayesian three-level random-effects model. These intervals got shrunk towards the meta-analytic effect size because of partial pooling, that is, the three-level model regularizing the impact of experiments with small sample sizes and/or unrealistically large effect sizes. The bold line at the bottom of the figure shows the meta-analytic effect size obtained from the three-level model (black dot) together with its 95% CrI (black line) and its posterior distribution (gray curve).

```{r, figs2, include=TRUE, fig.height=6, fig.width=12, fig.cap="(ref:figs2-caption)"}
# Extract convergence statistics (Rhat, Neff) from Bayesian results
conv_stats <- with(summary(res_meta), tibble(
  parameter = c(
    "b_Intercept", "sd_article__Intercept", "sd_article:experiment__Intercept"
  ),
  name_expr = c(
    "\"Hedges'\" ~ italic(g)",
    "italic(sigma)[article]",
    "italic(sigma)[experiment]"
  ),
  r_hat = print_num(c(fixed$Rhat, map_dbl(random, ~ .$Rhat)), digits = 4),
  bulk_ess = round(c(fixed$Bulk_ESS, map_dbl(random, ~ .$Bulk_ESS))),
  tail_ess = round(c(fixed$Tail_ESS, map_dbl(random, ~ .$Tail_ESS))),
  r_hat_expr = str_c("italic(R)[hat] == ", r_hat),
  bulk_ess_expr = str_c("italic(N)[eff(bulk)] == ", bulk_ess),
  tail_ess_expr = str_c("italic(N)[eff(tail)] == ", tail_ess),
  y_pos = c(0.7, 0.75, 0.8)
))

# Create trace plot
n_draws <- n_iter - n_warmup
bayesplot::mcmc_trace(
  res_meta,
  pars = conv_stats$parameter, facet_args = list(ncol = 1)
) +
  # Parameter label
  geom_text(
    aes(y = 0.45, label = name_expr, color = NA),
    conv_stats,
    y = 0.45, x = -0.042 * n_draws, color = "black", parse = TRUE,
    vjust = 1, angle = 90
  ) +
  # Rhat label
  geom_text(
    aes(y = y_pos, label = r_hat_expr, color = NA),
    conv_stats,
    x = 0.684 * n_draws, hjust = 1, color = "black", parse = TRUE,
  ) +
  # Neff labels
  geom_text(
    aes(y = y_pos, label = bulk_ess_expr, color = NA),
    conv_stats,
    x = 0.842 * n_draws, hjust = 1, color = "black", parse = TRUE,
  ) +
  geom_text(
    aes(y = y_pos, label = tail_ess_expr, color = NA),
    conv_stats,
    x = n_draws, hjust = 1, color = "black", parse = TRUE,
  ) +
  # Styling
  labs(x = "Sample number", y = NULL, color = "MCMC\nchain") +
  coord_cartesian(expand = FALSE, clip = "off") +
  scale_x_continuous(limits = c(0, n_draws), breaks = seq(0, n_draws, 2000)) +
  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.2)) +
  scale_color_grey(start = 0.0, end = 0.9) +
  theme_classic() +
  theme(
    axis.line = element_line(colour = "black"),
    axis.text = element_text(family = "Helvetica", color = "black"),
    axis.ticks = element_line(color = "black"),
    plot.margin = margin(t = 10, l = 25),
    strip.background = element_blank(),
    strip.text = element_blank(),
    text = element_text(family = "Helvetica", color = "black")
  )

# Save the plot
ggsave(here(figures_dir, "figs2_convergence.pdf"), width = 12, height = 6)
```

(ref:figs2-caption) **Convergence checks for the Bayesian meta-analysis.** For each of the three parameters in the three-level meta-analytic model, gray traces show the exploration of the posterior distribution by four independent Markov Chain Monte Carlo (MCMC) chains. Overlap of the gray traces as well as random upward and downward fluctuations (rather than systematic drifts) indicate efficient exploration of the posterior distribution. $R_\text{hat}$ = potential scale reduction factor, with values close to 1.0 indicating convergence of the chains, $N_\text{eff(bulk)}$ = bulk effective sample size, with larger values indicating better sampling efficiency in the bulk of the distribution (e.g., for estimating the posterior mean), $N_\text{eff(tail)}$ = tail effective sample size, with larger values indicating better sampling efficiency in the tails of the distribution (e.g., for estimating the 95% credible interval [CrI]). Details about these convergence criteria can be found in @vehtari2021.

```{r, figs3, include=TRUE, fig.height=4, fig.width=12, fig.cap="(ref:figs3-caption)"}
# Combine frequentist profile likelihood results into one data frame
prof_liks %>%
  head(-1) %>% # Remove the `comp` element
  map(~ tibble(sigma2 = .$sigma2, ll = .$ll)) %>%
  bind_rows(.id = "parameter") %>%
  # Create new labels for plotting
  mutate(parameter = factor(
    parameter,
    levels = c(1, 2),
    labels = c("italic(sigma)[article]^2", "italic(sigma)[experiment]^2")
  )) -> prof_liks_df

# Find the best-fitting parameter estimates
prof_liks_df %>%
  group_by(parameter) %>%
  filter(ll == max(ll)) -> prof_liks_max

# Create plot
prof_liks_df %>%
  ggplot(aes(x = sigma2, y = ll)) +
  facet_wrap(~parameter, scales = "free", labeller = label_parsed) +
  # Best fitting parameters
  geom_hline(
    aes(yintercept = ll),
    data = prof_liks_max, linetype = "dashed"
  ) +
  geom_vline(
    aes(xintercept = sigma2),
    data = prof_liks_max, linetype = "dashed"
  ) +
  # All tested parameters
  geom_point() +
  geom_line() +
  # Styling
  labs(x = "Parameter value", y = "Restricted log-likelihood") +
  theme_classic() +
  theme(
    axis.line = element_line(colour = "black"),
    axis.text = element_text(family = "Helvetica", color = "black"),
    axis.ticks = element_line(color = "black"),
    strip.background = element_blank(),
    strip.text = element_text(family = "Helvetica", color = "black", size = 12),
    text = element_text(family = "Helvetica", color = "black")
  )

# Save the plot
ggsave(here(figures_dir, "figs3_convergence_freq.pdf"), width = 12, height = 4)
```

(ref:figs3-caption) **Convergence checks for the frequentist meta-analysis.** Black curves show the profile of the restricted log likelihood for the two variance components in the frequentist three-level model. The two peaks indicate that restricted maximum likelihood estimation (REML) was able to converge on the most likely parameter estimates [@raue2009; @viechtbauer2010].

```{r, figs4, include=TRUE, fig.width=12, fig.height=3.5, fig.cap="(ref:figs4-caption)"}
# Create new funnel plots that take the trim-and-fill results into account
map2(res_trim_fill, plots_funnel, function(res, plot) {

  # Compute new funnel
  funnel_trim_fill <- with(
    list(
      z_crit_05 = stats::qnorm(0.975),
      max_se = max(sqrt(res$vi)) + 0.05
    ),
    {
      data.frame(
        x = c(
          res$b - z_crit_05 * sqrt(max_se^2),
          res$b,
          res$b + z_crit_05 * sqrt(max_se^2)
        ),
        y = c(max_se, 0, max_se)
      )
    }
  )

  # Add new funnel on top of the original funnel plot
  trim_fill_color <- ifelse(sum(res$fill) >= 1, "#e42536", NA)
  plot +
    # Add trim-and-fill funnel
    geom_path(
      data = funnel_trim_fill,
      aes(x = x, y = y),
      color = trim_fill_color
    ) +
    geom_vline(xintercept = res$b, color = trim_fill_color) +
    # Add trim-and-fill studies
    geom_point(
      data = with(res, tibble(gi = yi[fill], sei = sqrt(vi[fill]))),
      color = trim_fill_color, shape = 0
    )
}) -> plots_funnel_trim_fill

# Combine plots and legend
plot_grid(
  plotlist = plots_funnel_trim_fill, nrow = 1, labels = "auto",
  label_size = 11, label_fontfamily = "Helvetica"
) +
  draw_plot(legend_funnel, x = -0.39, y = 0.355)

# Save the plot
ggsave(here(figures_dir, "funnel_trim_fill.pdf"), width = 12, height = 3.5)
```

(ref:figs4-caption) **Trim-and-fill analyses.** As in Figure 3 in the main text, black squares indicate the effect sizes (x-axis) and standard errors (y-axis) of the individual experiments included in the meta-analysis of mental rotation performance (**a**) and in the meta-analysis of gender differences within each article (**b**). The funnel contours (diagonal black lines) depict a 95% pseudo-confidence interval around the meta-analytic effect sizes (vertical black lines). Gray shades indicate 95% pseudo-confidence intervals (dark gray) and 99% pseudo-confidence intervals (light gray) under the null hypothesis. Red squares show fictional experiments that were imputed using the trim-and-fill method  to compensate for the small publication bias observed in the original funnel plots. Red lines depict the meta-analytic effect size and its 95% pseudo-confidence interval for the trim-and-fill-corrected meta-analysis of mental rotation performance. For the meta-analysis of gender differences, the results of the trim-and-fill analysis suggested that no additional experiments had to be imputed to compensate for publication bias.
