---
title             : "Gender differences in infant mental rotation"
shorttitle        : "Infant mental rotation"

author:
  - name          : "Alexander Enge"
    affiliation   : "1,2"
    corresponding : "yes"
    address       : "Stephanstraße 1a, 04103 Leipzig"
    email         : "enge@cbs.mpg.de"
  - name          : "Shreya Kapoor"
    affiliation   : "1"
  - name          : "Anne-Sophie Kieslinger"
    affiliation   : "1"
  - name          : "Michael A. Skeide"
    affiliation   : "1"
affiliation:
  - id            : "1"
    institution   : "Research Group Learning in Early Childhood, Max Planck Institute for Human Cognitive and Brain Sciences, Stephanstraße 1a, 04103 Leipzig"
  - id            : "2"
    institution   : "Department of Psychology, Humboldt-Universität zu Berlin, Rudower Chaussee 18, 12489 Berlin"

authornote: |
  \addORCIDlink{Alexander Enge}{0000-0003-0100-2297}

  \addORCIDlink{Shreya Kapoor}{0000-0003-2619-8257}

  \addORCIDlink{Anne-Sophie Kieslinger}{https://orcid.org/0000-0001-9240-4077}

  We have no conflict of interest to disclose.
  There were no ethical concerns since we did not collect any new data.

abstract: |
  Mental rotation, the cognitive process of moving an object in mind to predict how it looks in a new orientation, is tightly coupled to intelligence, learning and educational achievement [@shepard1971; @hegarty1999; @johnson2005]. On average, males solve mental rotation tasks slightly faster than females [@linn1985; @voyer1995; @voyer2011; @maeda2013]. When such behavioral differences emerge during development, however, remains poorly understood [@lauer2019a]. Here we analyzed effect sizes derived from 59 experiments conducted in 1,798 infants aged 3 to 16 months. We robustly found that male infants recognized novel rotated objects more reliably than female infants. The effect size of this average difference was small and did not change with age. These findings indicate that gender differences in mental rotation are already present in the first months of life.

keywords          : "mental rotation, spatial cognition, spatial ability, infants, children, gender, meta-analysis"

bibliography      : "manuscript_files/references.bib"
csl               : "manuscript_files/nature.csl"

appendix          : "supplement.Rmd"

floatsintext      : yes
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

documentclass     : "apa7"
classoption       : "man,donotrepeattitle"
fontsize          : "10pt"
output            : papaja::apa6_pdf
header-includes:
  - \geometry{a4paper}
  - \raggedbottom
  - \usepackage[all]{nowidow}
  - \usepackage{makecell}
  - \usepackage{setspace}
  - \renewcommand{\arraystretch}{0.59}
  - \DeclareCaptionLabelSeparator{bar}{ | }
  - \DeclareCaptionTextFormat{tabletext}{\textup{#1}}
  - \captionsetup[table]{belowskip=20pt,font=small,labelfont=bf,labelsep=bar,textfont=bf,textformat=tabletext}
  - \captionsetup[figure]{belowskip=10pt,font=small,labelfont=bf,labelsep=bar,name=Fig.,textfont=normalfont}
---

```{r, setup, include=FALSE}
# Load packages
library(papaja)
library(here)
library(readxl)
library(scales)
library(tidyverse)
library(magrittr)
library(furrr)
library(metafor)
library(brms)
library(bayestestR)
library(tidybayes)
library(cowplot)

# Load custom helper functions
source(here("manuscript_files", "helper_functions.R"))

# Global chunk options
knitr::opts_chunk$set(
  include = FALSE,
  message = FALSE,
  fig.align = "center",
  fig.height = 10,
  fig.pos = "tp",
  fig.width = 7.5,
  out.width = "100%",
  warning = FALSE
)

# Re-run steps that take a long time?
run <- list(
  bayesian_models = FALSE,
  jackknife_analysis = FALSE,
  sensitivity_analysis = FALSE
)

# Options for MCMC sampling when fitting Bayesian multilevel models
n_iter <- 4000 # Posterior samples per chain, including `n_warmup`
n_warmup <- 1000 # Warmup samples per chain
n_chains <- 4 # Number of (parallel) chains
seed <- 1234 # Random seed to make the results reproducible

# Directory paths
data_dir <- here("data")
models_dir <- here("results/models")
figures_dir <- here("results/figures")
tables_dir <- here("results/tables")

# Download literature search spreadsheet from Google Drive
excel_url <- "https://docs.google.com/spreadsheets/d/1xnC0NlQYTXavXaeqQidhi7UKb1pCGAl9Ry3h3Uz3mi0"
excel_file <- here(data_dir, "literature_search.xlsx")
# googledrive::drive_auth(use_oob = TRUE)
# googledrive::drive_download(excel_url, excel_file, overwrite = TRUE)

# Read sheets
screening <- read_excel(excel_file, sheet = "screening")
included <- read_excel(excel_file, sheet = "included", na = "NA")
gender <- read_excel(excel_file, sheet = "gender_differences", na = "NA")

# Add columns to the table of included experiments
included %>%
  mutate(

    # Add unique experiment identifier
    experiment = str_c(year, article, group_long, sep = ", "),

    # Add difference between condition means
    mean_diff = case_when(
      !is.na(mean_diff) ~ mean_diff,
      TRUE ~ mean_novel - mean_familiar
    ),
    # Add d_z from paired t test of condition means (Rosenthal, 1991)
    d_z_t = t / sqrt(sample_size),
    # Add d_z from ANOVA F value via conversion to a t value
    d_z_f = sqrt(f) / sqrt(sample_size) * sign_f,
    # Add d_z from mean and standard deviation of the difference
    d_z_diff = mean_diff / sd_diff,
    # Add d_av from mean difference and standard deviations
    # See http://dx.doi.org/10.20982/tqmp.14.4.p242
    sd_av = sqrt((sd_novel^2 + sd_familiar^2) / 2),
    d_av = mean_diff / sd_av,
    # Add d from one-sample t test of novelty preference scores
    d_nov_pref = (nov_pref - 0.5) / sd_nov_pref,

    # Choose one type of outcome variable for each experiment
    di = case_when(
      # 1. If d was reported directed
      !is.na(d) ~ d,
      # 2. If a paired sample t test was reported
      !is.na(d_z_t) ~ d_z_t,
      # 3. If ANOVA was reported
      !is.na(d_z_f) ~ d_z_f,
      # 4. If the difference between means and its SD were reported
      !is.na(d_z_diff) ~ d_z_diff,
      # 5. If the individual condition means and their SDs were reported
      !is.na(d_av) ~ d_av,
      # 6. If a novelty preference score and its SD were reported
      !is.na(d_nov_pref) ~ d_nov_pref
    ),
    # Keep track which type of outcome measure was chosen for each article
    di_type = case_when(
      !is.na(d) ~ "d",
      !is.na(d_z_t) ~ "d_z_t",
      !is.na(d_z_f) ~ "d_z_f",
      !is.na(d_z_diff) ~ "d_z_diff",
      !is.na(d_av) ~ "d_av",
      !is.na(d_nov_pref) ~ "d_nov_pref",
      TRUE ~ "none"
    ) %>%
      factor(levels = c(
        "d", "d_z_t", "d_z_f", "d_z_diff", "d_av", "d_nov_pref", "none"
      )),

    # Apply small sample correction using Hedges' exact method
    # See http://dx.doi.org/10.20982/tqmp.14.4.p242
    dfi = 2 * (sample_size - 1),
    ji = exp(lgamma(dfi / 2) - log(sqrt(dfi / 2)) - lgamma((dfi - 1) / 2)),
    gi = di * ji,

    # Recode gender as a categorical (factor) variable for meta-regression
    gender = case_when(
      female_percent == 1.0 ~ "Female",
      female_percent == 0.0 ~ "Male",
      TRUE ~ "Mixed"
    ) %>% factor(levels = c("Mixed", "Female", "Male")),

    # Recode mean sample age in years (centered) for meta-regression
    age = age_mean / 365.25,
    age_c = age - mean(age, na.rm = TRUE),
    age_sd = age_sd / 365.25,

    # Recode task type as a categorical (factor) variable for meta-regression
    task = factor(task, levels = c("Habituation", "VoE")),

    # Combine gender and task into one column for plotting
    gender_task = factor(
      str_c(gender, task, sep = ", "),
      levels = c(
        "Female, Habituation",
        "Male, Habituation",
        "Mixed, Habituation",
        "Mixed, VoE"
      )
    )
  ) %>%
  # Order rows by experiment ID
  arrange(experiment) -> dat_all

# Overview of the different effect sizes
dat_all %>%
  select(
    article,
    group,
    gender_split,
    gi,
    di,
    di_type,
    d,
    d_z_t,
    d_z_f,
    d_z_diff,
    d_av,
    d_nov_pref
  ) %>%
  print(n = Inf)

# Compute standard error of Cohen's d based on assumed correlation
# See Hedges' formula on p. 253 in http://dx.doi.org/10.20982/tqmp.14.4.p242
# This will need a sensitivity analysis regarding the values of `r_assumed`
r_assumed <- 0.5
dat_all %>%
  mutate(
    ni = sample_size,
    vi = (dfi / (dfi - 2)) * ((2 * (1 - r_assumed)) / ni) *
      (1 + gi^2 * (ni / (2 * (1 - r_assumed)))) - (gi^2 / ji^2),
    sei = sqrt(vi)
  ) %>%
  filter(!is.na(gi)) -> dat_all_r

# Show number of experiments per gender grouping strategy
table(dat_all_r$gender_split)

# Extract split or mixed experiments only
dat_split <- filter(dat_all_r, gender_split %in% c("split", "split_only"))
dat_mixed <- filter(dat_all_r, gender_split %in% c("mixed", "mixed_only"))

# Combine both strategies, preferring split experiments
dat_both_split <- filter(
  dat_all_r, gender_split %in% c("split", "mixed_only", "split_only")
)

# Combine both strategies, preferring mixed experiments
dat_both_mixed <- filter(
  dat_all_r, gender_split %in% c("mixed", "mixed_only", "split_only")
)

# We go ahead with the last solution as to use the maximum amount of information
# while not biasing the gender results
dat <- dat_both_mixed

# Extract some descriptive statistics for usage in the main text
descs <- list(
  n_articles = length(unique(dat$article)),
  n_experiments = nrow(dat),
  n_infants = sum(dat$sample_size),
  percent_female = mean(dat$female_percent, na.rm = TRUE),
  min_age_months = as.integer(min(dat$age_min, na.rm = TRUE) / 30.417),
  max_age_months = as.integer(max(dat$age_max, na.rm = TRUE) / 30.417),
  mean_age_weighted = print_days_months(
    sum(dat$age_mean * dat$ni) / (sum(dat$ni)),
    long = TRUE
  ),
  n_experiments_habituation = nrow(filter(dat, task == "Habituation")),
  n_experiments_voe = nrow(filter(dat, task == "VoE"))
)
```

# Introduction

The cognitive ability to move visual object representations in mind for recognition across different orientations, known as mental rotation, emerges in the first three months of life [@moore2020; @johnson2020]. Mental rotation is a key component of intelligence and a powerful predictor of learning outcome and educational achievement [@shepard1971; @hegarty1999; @johnson2005].

Previous meta-analyses revealed that males solve mental rotation tasks slightly faster than females on average [@linn1985; @voyer1995; @voyer2011; @maeda2013]. Effect sizes of this difference, however, are heterogeneous and often only medium in size (mean weighted $g = 0.37\text{--}0.73$). Interestingly, a recent meta-analysis [@lauer2019a] in 3-17-year-old children and adolescents suggests even only a small-to-medium difference (mean weighted $g = 0.39$). Whether gender differences in mental rotation behavior already emerge during infancy remains unknown.

In the present study, we meta-analyzed `r descs$n_experiments` effect sizes derived from looking times in mental rotation tasks conducted by `r formatC(descs$n_infants, big.mark = ",")` infants (`r print_perc(descs$percent_female)` female) aged `r descs$min_age_months` to `r descs$max_age_months` months (mean age of `r descs$mean_age_weighted`; Supplementary Table 1). All tasks were embedded either into habituation experiments (`r descs$n_experiments_habituation`) or violation of expectation experiments (`r descs$n_experiments_voe`) [@fantz1964; @baillargeon1985]. These experiments comprised real world stimuli (e.g., toy objects [@antrilli2016]), three-dimensional digital stimuli (e.g., cube figures [@moore2008]), or two-dimensional digital stimuli (e.g., digits [@quinn2008]). In habituation experiments, infants repeatedly saw an object until their looking times declined before they were presented with a mirror image of the object. Longer looking times at the mirror image were taken as evidence that an infant still recognized the familiar object after rotation through the new orientation. In violation of expectation experiments, infants were habituated to an object that was revolving repeatedly through a certain angle. Then, either the familiar object or an unseen object was shown while they were revolving through a certain angle. Subsequently, the object disappeared behind an occluder. Finally, the occluder was removed and either the object or its mirror object were shown. Larger differences in looking times for the familiar object versus the unseen mirror image (at the new angle) were taken as evidence that an infant still recognized the familiar object after rotation through the new angle. In contrast, looking times for both objects were expected to be similar if an infant did not recognize the familiar object from the new angle.

Following previous work in older populations, we hypothesized that looking times in mental rotation experiments are on average longer in male compared to female infants. Effect sizes were assumed to be small.

\newpage

# Results

## Mental rotation performance

```{r, meta_analysis}
# Specify priors
prior_c <- c(
  set_prior("normal(0, 1)", class = "b"),
  set_prior("cauchy(0, 0.3)", class = "sd")
)

# Run prior predictive simulation
dir.create(models_dir, showWarnings = FALSE, recursive = TRUE)
brms_file_refit <- ifelse(run$bayesian_models, "always", "never")
res_prior <- brm(
  gi | se(sei) ~ 0 + Intercept + (1 | article / experiment),
  data = dat,
  prior = prior_c,
  sample_prior = "only",
  save_pars = save_pars(all = TRUE),
  chains = n_chains,
  iter = n_iter,
  warmup = n_warmup,
  cores = n_chains,
  control = list(adapt_delta = 0.99),
  seed = seed,
  file = here(models_dir, "res_prior"),
  file_refit = brms_file_refit
)
summary(res_prior)
# plot(res_prior)

# Run Bayesian multilevel model
res_brm <- update(
  res_prior,
  sample_prior = FALSE,
  file = here(models_dir, "res_brm"),
  file_refit = brms_file_refit
)
summary(res_brm)
# plot(res_brm)

# Get posterior probability mass > 0 for the meta-analytic effect
(hyp_brm <- hypothesis(res_brm, "Intercept > 0")$hypothesis)

# # Summarise fixed effects (incl. Bayes factors)
# describe_posterior(
#   res_brm,
#   centrality = "mean", ci = 0.95, ci_method = "ETI",
#   test = c("p_direction", "rope", "bayesfactor"),
#   rope_range = c(-0.1, 0.1)
# )

# Extract posterior draws for the meta-analytic effects
spread_draws(res_brm, `b_.*`, `sd_.*`, regex = TRUE, ndraws = NULL) %>%
  # Compute variances and ICC
  mutate(
    intercept = b_Intercept,
    sigma_article = sd_article__Intercept,
    sigma_experiment = `sd_article:experiment__Intercept`,
    sigma2_article = sigma_article^2,
    sigma2_experiment = sigma_experiment^2,
    sigma2_total = sigma2_article + sigma2_experiment,
    icc = sigma2_article / sigma2_total,
    .keep = "unused"
  ) -> draws_brm

# Summarize as mean and 95% credible intervals
(summ_brm <- as.list(mean_qi(draws_brm)))
```

```{r, fig1, include=TRUE, fig.height=14, fig.width=12, fig.cap="(ref:fig1-caption)"}
# Get posterior draws for the effect in each experiment
epred_draws_brm <- epred_draws(res_brm, dat, ndraws = NULL) %>%
  mutate(experiment_f = factor(experiment))

# Create forest plot
dat %>%
  # Make sure the plot will be ordered alphabetically by experiment IDs
  arrange(experiment) %>%
  mutate(
    experiment_f = fct_rev(fct_expand(factor(experiment), "model")),
    # Show article labels only for the first experiment per article
    article = if_else(article == lag(article, default = ""), "", article),
    # Compute frequentist confidence intervals
    ci_lb = gi - qnorm(0.05 / 2, lower.tail = FALSE) * sqrt(vi),
    ci_ub = gi + qnorm(0.05 / 2, lower.tail = FALSE) * sqrt(vi),
    ci_print = print_mean_ci(gi, ci_lb, ci_ub)
  ) %>%
  # Prepare plotting canvas
  ggplot(aes(x = gi, y = experiment_f)) +
  geom_vline(xintercept = seq(-3, 3, 0.5), color = "grey90") +
  # Add article and group labels as text on the left
  geom_text(aes(x = -9.9, label = article), hjust = 0) +
  geom_text(aes(x = -7.1, label = group_long), hjust = 0) +
  # Add experiment-specific effect sizes and CIs as text on the right
  geom_text(aes(x = 3.7, label = print_num(gi)), hjust = 1) +
  geom_text(aes(x = 4.4, label = print_num(ci_lb)), hjust = 1) +
  geom_text(aes(x = 5.1, label = print_num(ci_ub)), hjust = 1) +
  # Add Bayesian highest posterior density intervals for each experiment
  stat_interval(
    aes(x = .epred),
    data = epred_draws_brm,
    alpha = .8,
    point_interval = "mean_qi",
    .width = c(0.5, 0.95),
  ) +
  scale_color_grey(
    start = 0.85, end = 0.65,
    labels = as_mapper(~ scales::percent(as.numeric(.x)))
  ) +
  # Add experiment-specific effect sizes and CIs as dots with error bars
  geom_linerange(aes(xmin = ci_lb, xmax = ci_ub), size = 0.35) +
  geom_point(aes(size = ni), shape = 22, fill = "white") + # Or (1 / vi)?
  # Add posterior distribution for the meta-analytic effect
  stat_halfeye(
    aes(x = intercept, y = -1),
    draws_brm,
    point_interval = "mean_qi",
    .width = c(0.95)
  ) +
  annotate(
    "text",
    x = c(-9.9, 3.7, 4.4, 5.1),
    y = -0.5,
    label = c(
      "Three-level model",
      print_num(summ_brm$intercept),
      print_num(summ_brm$intercept.lower),
      print_num(summ_brm$intercept.upper)
    ),
    hjust = c(0, 1, 1, 1),
    fontface = "bold"
  ) +
  # Add headers for each of the for columns
  annotate(
    "rect",
    xmin = -Inf,
    xmax = Inf,
    ymin = descs$n_experiments + 0.5,
    ymax = Inf,
    fill = "white"
  ) +
  annotate(
    "text",
    x = c(-9.9, -7.1, 0, 3.7, 4.4, 5.1),
    y = descs$n_experiments + 1.5,
    label = c(
      "Article",
      "Experiment",
      "Effect size plot",
      "Effect size",
      "Lower",
      "Upper"
    ),
    hjust = c(0, 0, 0.5, 1, 1, 1),
    fontface = "bold"
  ) +
  # Styling
  coord_cartesian(
    ylim = c(-1.5, descs$n_experiments + 2), expand = FALSE, clip = "off"
  ) +
  scale_x_continuous(breaks = seq(-3, 3, 0.5)) +
  annotate("segment", x = -3.3, xend = 3.3, y = -1.5, yend = -1.5) +
  labs(
    x = expression("Hedges'" ~ italic("g")),
    size = "Sample size",
    color = "CrI level"
  ) +
  theme_minimal() +
  theme(
    legend.position = "bottom",
    axis.text.x = element_text(family = "Helvetica", color = "black"),
    axis.text.y = element_blank(),
    axis.ticks.x = element_line(colour = "black"),
    axis.title.x = element_text(hjust = 0.67, margin = margin(b = -15)),
    axis.title.y = element_blank(),
    panel.grid = element_blank(),
    text = element_text(family = "Helvetica")
  )

# Save the plot
dir.create(figures_dir, showWarnings = FALSE)
ggsave(here(figures_dir, "forest.pdf"), width = 12, height = 14)
```

(ref:fig1-caption) **Mental rotation performance.** A Bayesian three-level meta-analysis provided evidence for mental rotation ability in infants. White squares depict the effect sizes (Hedges' $g$) for infants' mental rotation performance in all individual experiments and black lines depict their 95% confidence intervals. Gray bars indicate the 95% and 50% Bayesian credible intervals (CrI). These intervals got shrunk towards the meta-analytic effect size because of partial pooling which regularized the impact of experiments with small sample sizes or unrealistically large effect sizes to prevent overfitting the model. The last line shows the meta-analytic effect size (black dot) together with its 95% CrI (black line) and its posterior distribution (gray curve).

For our first meta-analytic model effect sizes were quantified as the standardized mean difference in infants' looking times for novel and familiar rotated objects. Using this effect size index we ran a Bayesian three-level random-effects model to test if there was evidence that infants did perform mental rotation. Across studies, infants indeed looked longer at novel rotated objects than at familiar rotated objects, with a standardized mean difference of $g = `r summ_brm$intercept`$, 95% credible interval (CrI) [`r summ_brm$intercept.lower`, `r summ_brm$intercept.upper`] (Fig. 1). The probability for this effect being greater than zero was `r print_perc(hyp_brm$Post.Prob)`. The heterogeneity of effect sizes was $\sigma_{\text{Experiment}}^2 = `r summ_brm$sigma2_experiment`$, 95% CrI [`r summ_brm$sigma2_experiment.lower`, `r summ_brm$sigma2_experiment.upper`], at the experiment level and $\sigma_{\text{Article}}^2 = `r summ_brm$sigma2_article`$, 95% CrI [`r summ_brm$sigma2_article.lower`, `r summ_brm$sigma2_article.upper`] at the article level. Therefore, approximately `r print_perc(1 - summ_brm$icc)` of the heterogeneity between effect sizes was attributable to differences between experiments *within* articles and `r print_perc(summ_brm$icc)` was attributable to differences *between* articles.

## Effects of gender, age, and task type

```{r, meta_regression}
# Set numerical contrasts for factor variables
contrasts(dat$gender) <- MASS::contr.sdif(3)
contrasts(dat$task) <- MASS::contr.sdif(2)

# Specify priors
prior_c <- c(
  set_prior("normal(0, 1)", class = "b", coef = "Intercept"),
  set_prior("normal(0, 0.5)", class = "b"),
  set_prior("cauchy(0, 0.3)", class = "sd")
)

# Run prior predictive simulation
res_prior_reg <- brm(
  gi | se(sei) ~ 0 + Intercept + gender * age_c + task +
    (1 | article / experiment),
  data = dat,
  prior = prior_c,
  sample_prior = "only",
  save_pars = save_pars(all = TRUE),
  chains = n_chains,
  iter = n_iter,
  warmup = n_warmup,
  cores = n_chains,
  control = list(adapt_delta = 0.99),
  seed = seed,
  file = here(models_dir, "res_prior_reg"),
  file_refit = brms_file_refit
)
summary(res_prior_reg)
# plot(res_prior_reg)

# Run Bayesian multilevel model
res_brm_reg <- update(
  res_prior_reg,
  sample_prior = FALSE,
  file = here(models_dir, "res_brm_reg"),
  file_refit = brms_file_refit
)
summary(res_brm_reg)
# plot(res_brm_reg)

# Get posterior probability mass > 0 for all regression weights
(hyps_brm_reg <- list(
  intercept = hypothesis(res_brm_reg, "Intercept > 0")$hypothesis,
  female_mixed = hypothesis(res_brm_reg, "gender2M1 < 0")$hypothesis,
  male_female = hypothesis(res_brm_reg, "gender3M2 > 0")$hypothesis,
  age = hypothesis(res_brm_reg, "age_c > 0")$hypothesis,
  voe_habituation = hypothesis(res_brm_reg, "task2M1 > 0")$hypothesis,
  female_mixed_age = hypothesis(res_brm_reg, "gender2M1:age_c > 0")$hypothesis,
  male_female_age = hypothesis(res_brm_reg, "gender3M2:age_c > 0")$hypothesis
))

# # Summarise fixed effects (incl. Bayes factors)
# describe_posterior(
#   res_brm_reg,
#   centrality = "mean", ci = 0.95, ci_method = "ETI",
#   test = c("p_direction", "rope", "bayesfactor"),
#   rope_range = c(-0.1, 0.1)
# )

# Extract posterior draws for the meta-analytic effects
spread_draws(res_brm_reg, `b_.*`, `sd_.*`, regex = TRUE, ndraws = NULL) %>%
  # Compute variances and ICC
  mutate(
    intercept = b_Intercept,
    female_mixed = b_gender2M1,
    male_female = b_gender3M2,
    age = b_age_c,
    voe_habituation = b_task2M1,
    female_mixed_age = `b_gender2M1:age_c`,
    male_female_age = `b_gender3M2:age_c`,
    sigma_article = sd_article__Intercept,
    sigma_experiment = `sd_article:experiment__Intercept`,
    sigma2_article = sd_article__Intercept^2,
    sigma2_experiment = `sd_article:experiment__Intercept`^2,
    sigma2_total = sigma2_article + sigma2_experiment,
    icc = sigma2_article / sigma2_total,
  ) -> draws_brm_reg

# Summarize as mean and 95% credible intervals
(summ_brm_reg <- as.list(mean_qi(draws_brm_reg)))
```

As a next step, we conducted a meta-regression analysis to test if the gender of the infants, their age, or the type of mental rotation task was related to mental rotation performance (Fig. 2).
Indeed, experiments with all-male samples revealed larger looking time differences than experiments with all-female samples, $b = `r summ_brm_reg$male_female`$, 95% CrI [`r summ_brm_reg$male_female.lower`, `r summ_brm_reg$male_female.upper`].
The probability for this effect being larger than zero was `r print_perc(hyps_brm_reg$male_female$Post.Prob)`.
We found no difference between mixed-gender and all-female samples, $b = `r -summ_brm_reg$female_mixed`$, 95% CrI [`r -summ_brm_reg$female_mixed.lower`, `r -summ_brm_reg$female_mixed.upper`] (`r print_perc(hyps_brm_reg$female_mixed$Post.Prob)` probability of an effect larger than zero).
Additionally, mean age was not related to mental rotation performance, with a change per year of $b = `r summ_brm_reg$age`$, 95% [`r summ_brm_reg$age.lower`, `r summ_brm_reg$age.upper`].
We also did not detect an interaction between gender and age ([females - mixed] $\times$ age: $b = `r summ_brm_reg$female_mixed_age`$, 95% CrI [`r summ_brm_reg$female_mixed_age.lower`, `r summ_brm_reg$female_mixed_age.upper`]; [males - females] $\times$ age: $b = `r summ_brm_reg$male_female_age`$, 95% CrI [`r summ_brm_reg$male_female_age.lower`, `r summ_brm_reg$male_female_age.upper`]).
Finally, there was weak evidence that violation of expectation tasks yielded larger effects than habituation tasks, $b = `r summ_brm_reg$voe_habituation`$, 95% [`r summ_brm_reg$voe_habituation.lower`, `r summ_brm_reg$voe_habituation.upper`].
The probability for this effect being greater than zero was `r print_perc(hyps_brm_reg$voe_habituation$Post.Prob)`.

```{r, fig2, include=TRUE, fig.height=5, fig.width=12, fig.cap="(ref:fig2-caption)"}
# Get draws from the posterior distribution
draws_reg <- epred_draws(
  res_brm_reg,
  dat,
  ndraws = NULL,
  re_formula = NA
)

# Use colors as proposed in https://arxiv.org/abs/2107.02270
habi_colors <- c(
  "Female, Habituation" = "#5790fc",
  "Male, Habituation" = "#f89c20",
  "Mixed, Habituation" = "#e42536"
)
voe_colors <- c("Mixed, VoE" = "#964a8b")

# Regression plot
dat %>%
  ggplot(aes(x = age * 12, y = gi)) +
  geom_hline(yintercept = seq(-1, 2, 0.5), color = "grey90") +
  annotate(
    "rect",
    xmin = 5.5, xmax = Inf, ymin = 1.25, ymax = Inf,
    color = NA, fill = "white"
  ) +
  # Regression lines and HPDIs - Habituation tasks
  stat_lineribbon(
    aes(y = .epred, color = gender_task),
    data = draws_reg,
    alpha = .4,
    point_interval = "mean_qi",
    .width = c(0.5, 0.95)
  ) +
  # Individual study effect sizes - Habituation tasks
  geom_point(aes(color = gender_task, size = ni), shape = 0) +
  scale_color_manual(
    values = habi_colors,
    breaks = names(habi_colors),
    labels = c("Females", "Males", "Mixed gender"),
    na.value = NA
  ) +
  guides(color = guide_legend(
    title = "Habituation tasks",
    override.aes = list(fill = NA),
    order = 1
  )) +
  # Regression lines and HPDIs - VoE tasks
  ggnewscale::new_scale_color() +
  stat_lineribbon(
    aes(y = .epred, color = gender_task),
    data = draws_reg,
    fill = NA,
    alpha = .4,
    point_interval = "mean_qi",
    .width = c(0.5, 0.95)
  ) +
  # Individual study effect sizes - VoE tasks
  geom_point(aes(color = gender_task, size = ni), shape = 0) +
  scale_color_manual(
    values = voe_colors,
    breaks = names(voe_colors),
    labels = c("Mixed gender"),
    na.value = NA
  ) +
  guides(color = guide_legend(title = "VoE tasks", order = 2)) +
  # Styling
  coord_cartesian(expand = FALSE) +
  scale_x_continuous(limits = c(2.9, 16.1), breaks = seq(3, 16, 1)) +
  scale_y_continuous(limits = c(-1.2, 2.2), breaks = seq(-1, 2, 0.5)) +
  scale_fill_grey(
    start = 0.85, end = 0.65,
    labels = as_mapper(~ scales::percent(as.numeric(.x)))
  ) +
  labs(
    x = "Age (months)",
    y = expression("Hedges'" ~ italic("g")),
    fill = "CrI level",
    size = "Sample size"
  ) +
  theme_classic() +
  theme(
    axis.text = element_text(family = "Helvetica", color = "black"),
    axis.ticks = element_line(color = "black"),
    legend.direction = "vertical",
    legend.key = element_blank(),
    legend.position = "none",
    panel.grid = element_blank(),
    text = element_text(family = "Helvetica", color = "black")
  ) -> plot_reg

# Extract the legend so that we can put it inside the plotting area
plot_reg_legend <- get_legend(plot_reg + theme(legend.position = "top"))

# Define new labels for the regression coefficients
coef_colnames <- c(
  b_Intercept = expression("Intercept (Hedges" ~ italic(g) * ")"),
  b_gender2M1 = expression("Females - mixed"),
  b_gender3M2 = expression("Males - females"),
  b_age_c = expression("Age (per year)"),
  b_task2M1 = expression("Habituation - VoE"),
  `b_gender2M1:age_c` = expression("(Females - Mixed)" %*% "age"),
  `b_gender3M2:age_c` = expression("(Males - Females)" %*% "age")
)

# Plot posterior distributions of the regression coefficients
draws_reg_coef <- tidy_draws(res_brm_reg)
draws_reg_coef %>%
  select(all_of(names(coef_colnames))) %>%
  gather() %>%
  mutate(coef = factor(key, levels = names(coef_colnames))) %>%
  ggplot(aes(x = value, y = fct_rev(coef))) +
  geom_vline(xintercept = seq(-1, 1, 0.5), color = "grey90") +
  stat_halfeye(point_interval = "mean_qi", .width = c(0.5, 0.95)) +
  coord_cartesian(xlim = c(-1.25, 1.25), clip = "off") +
  scale_x_continuous(breaks = seq(-1, 1, 0.5)) +
  scale_y_discrete(labels = coef_colnames) +
  labs(x = expression("Regression weight (" * Delta * italic("g") * ")")) +
  annotate(
    "text",
    label = "Fixed effects", x = -3.175, y = 7.86, hjust = 0,
    family = "Helvetica", fontface = "bold", color = "black"
  ) +
  theme_minimal() +
  theme(
    axis.line.x = element_line(colour = "black"),
    axis.text.x = element_text(family = "Helvetica", color = "black"),
    axis.text.y = element_text(
      family = "Helvetica", color = "black", size = 3.88 * .pt,
      hjust = 0, vjust = -0.1, margin = margin(l = 20)
    ),
    axis.ticks.x = element_line(color = "black"),
    axis.ticks.y = element_blank(),
    axis.title.y = element_blank(),
    panel.grid = element_blank(),
    text = element_text(family = "Helvetica", color = "black")
  ) -> plot_coef

# Combine plots
plot_grid(
  plot_reg, plot_coef,
  nrow = 1, rel_widths = c(3, 2), labels = "auto",
  label_size = 11, label_fontfamily = "Helvetica",
  label_x = 0.008, label_y = 0.99
) +
  draw_plot(plot_reg_legend, x = 0.385, y = 0.865, hjust = 0.5, vjust = 0.5)

# Save plot
ggsave(here(figures_dir, "regression_coef.pdf"), width = 12, height = 5)
```

(ref:fig2-caption) **Effects of gender, age, and task.** **a,** Squares show the effect size (Hedges' $g$) for infants' mental rotation performance in each of the 59 individual experiments. Squares are color-coded according to the type of habituation task and the gender of the infants (blue = habituation task, all-female sample, yellow = habituation task, all-male sample, red = habituation task, mixed-gender sample, purple = violation of expectation [VoE] task, mixed-gender sample). Lines indicate the best-fit regression estimates according to a Bayesian three-level meta-regression model and gray ribbons indicate their corresponding 95% and 50% credible interval (CrI). **b,** Fixed effect estimates obtained from the Bayesian three-level meta-regression model are depicted as black dots together with their 95% Crl (thin black lines) and 50% Crl (thick black lines). Gray curves indicate the posterior distribution for each effect.

```{r, gender_differences}
# Extract relevant effect sizes
gender %>%
  # Remove redundant samples
  filter(!redundant) %>%
  # Add columns
  mutate(

    # Add unique experiment identifier
    experiment = str_c(year, article, group_long, sep = ", "),

    # Re-code non-significant f values as an effect of 0
    f = as.numeric(f),
    f_assumed = ifelse(is.nan(f), 0, f),

    # Add d from two-samples t test (Lakens, 2013)
    d_t = t * sqrt(1 / female_n + 1 / male_n),

    # Add d from ANOVA F value via conversion to a t value
    d_f = sqrt(f_assumed) * sqrt(1 / female_n + 1 / male_n),

    # Add d from mean difference and pooled standard deviation
    mean_diff = mean_diff_males_mean - mean_diff_females_mean,
    sd_diff_pooled_numerator = (male_n - 1) * (mean_diff_males_sd^2) +
      (female_n - 1) * (mean_diff_females_sd^2),
    df = male_n + female_n - 2,
    sd_diff_pooled = sqrt(sd_diff_pooled_numerator / df),
    d_diff = mean_diff / sd_diff_pooled,

    # Add d from one-sample t test of novelty preference scores
    mean_nov_pref = novelty_pref_males_mean - novelty_pref_females_mean,
    sd_nov_pref_pooled_numerator = (male_n - 1) * (novelty_pref_males_sd^2) +
      (female_n) * (novelty_pref_females_sd^2),
    sd_nov_pref_pooled = sqrt(sd_nov_pref_pooled_numerator / df),
    d_nov_pref = mean_nov_pref / sd_nov_pref_pooled,

    # Choose one type of outcome variable for each experiment
    di = case_when(
      # 1. If d was reported directed
      !is.na(d) ~ d,
      # 2. If a t test was reported
      !is.na(d_t) ~ d_t,
      # 3. If ANOVA was reported
      !is.na(d_f) ~ d_f,
      # 4. If the difference between means and their SDs were reported
      !is.na(d_diff) ~ d_diff,
      # 5. If novelty preference scores and their SDs were reported
      !is.na(d_nov_pref) ~ d_nov_pref
    ),
    # Keep track which type of outcome measure was chosen for each article
    di_type = case_when(
      !is.na(d) ~ "d",
      !is.na(d_t) ~ "d_t",
      !is.na(d_f) ~ "d_f",
      !is.na(d_diff) ~ "d_diff",
      !is.na(d_nov_pref) ~ "d_nov_pref"
    ) %>%
      factor(levels = c("d", "d_t", "d_f", "d_diff", "d_nov_pref")),

    # Apply small sample correction using Hedges' exact method
    # See http://dx.doi.org/10.20982/tqmp.14.4.p242
    j = exp(lgamma(df / 2) - log(sqrt(df / 2)) - lgamma((df - 1) / 2)),
    gi = di * j,

    # Compute standard error of Cohen's d, using harmonic mean of sample sizes
    ni = female_n + male_n,
    nhi = 2 / (1 / female_n + 1 / male_n),
    vi = (df / (df - 2)) * (2 / nhi) * (1 + gi^2 * (nhi / 2)) - (gi^2 / (j^2)),
    sei = sqrt(vi)
  ) %>%
  # Remove experiments that didn't provide an effect size
  filter(!is.na(gi)) -> dat_gender

# Overview of the different effect sizes
dat_gender %>%
  select(
    article,
    group_long,
    gi,
    di,
    di_type,
    d,
    d_t,
    d_f,
    d_diff,
    sei
  ) %>%
  print(n = Inf)

# Specify priors
prior_c <- c(
  set_prior("normal(0, 1)", class = "b"),
  set_prior("cauchy(0, 0.3)", class = "sd")
)

# Run prior predictive simulation
res_prior_gender <- brm(
  gi | se(sei) ~ 0 + Intercept + (1 | article / experiment),
  data = dat_gender,
  prior = prior_c,
  sample_prior = "only",
  save_pars = save_pars(all = TRUE),
  chains = n_chains,
  iter = n_iter,
  warmup = n_warmup,
  cores = n_chains,
  control = list(adapt_delta = 0.99),
  seed = seed,
  file = here(models_dir, "res_prior_gender"),
  file_refit = brms_file_refit
)
summary(res_prior_gender)
# plot(res_prior_gender)

# Run Bayesian multilevel model
res_brm_gender <- update(
  res_prior_gender,
  sample_prior = FALSE,
  file = here(models_dir, "res_brm_gender"),
  file_refit = brms_file_refit
)
summary(res_brm_gender)
# plot(res_brm_gender)

# Get posterior probability mass > 0 for the meta-analytic effect
(hyp_brm_gender <- hypothesis(res_brm_gender, "Intercept > 0")$hypothesis)

# # Summarise fixed effects (incl. Bayes factors)
# describe_posterior(
#   res_brm_gender,
#   centrality = "mean", ci = 0.95, ci_method = "ETI",
#   test = c("p_direction", "rope", "bayesfactor"),
#   rope_range = c(-0.1, 0.1)
# )

# Extract posterior draws for the meta-analytic effects
spread_draws(res_brm_gender, `b_.*`, `sd_.*`, regex = TRUE, ndraws = NULL) %>%
  # Compute variances and ICC
  mutate(
    intercept = b_Intercept,
    sigma_article = sd_article__Intercept,
    sigma_experiment = `sd_article:experiment__Intercept`,
    sigma2_article = sigma_article^2,
    sigma2_experiment = sigma_experiment^2,
    sigma2_total = sigma2_article + sigma2_experiment,
    icc = sigma2_article / sigma2_total,
    .keep = "unused"
  ) -> draws_brm_gender

# Summarize as mean and 95% credible intervals
(summ_brm_gender <- as.list(mean_qi(draws_brm_gender)))
```

To confirm the gender difference between males and females we set up another Bayesian meta-analysis, this time focusing on the looking-time contrasts between all-male and all-female groups reported *within* each experiment by the original authors.
Our additional analysis revealed a meta-analytic effect size of $g = `r summ_brm_gender$intercept`$, 95% Crl [`r summ_brm_gender$intercept.lower`, `r summ_brm_gender$intercept.upper`] (Supplementary Fig. 1) and a probability of this effect being greater than zero of `r print_perc(hyp_brm_gender$Post.Prob)`.
The heterogeneity of effect sizes was $\sigma_{\text{Experiment}}^2 = `r summ_brm_gender$sigma2_experiment`$, 95% CrI [`r summ_brm_gender$sigma2_experiment.lower`, `r summ_brm_gender$sigma2_experiment.upper`], at the experiment level and $\sigma_{\text{Article}}^2 = `r summ_brm_gender$sigma2_article`$, 95% CrI [`r summ_brm_gender$sigma2_article.lower`, `r summ_brm_gender$sigma2_article.upper`] at the article level. This means that `r print_perc(summ_brm_gender$icc)` of the total variance can be attributed to differences *between* articles and `r print_perc(1 - summ_brm_gender$icc)` to differences between experiments *within* articles.

## Publication bias and certainty assessment

```{r, publication_bias, echo=TRUE}
# Classical Egger regression test for the meta-analysis of rotation performance
(egger <- with(
  dat, regtest(x = gi, sei = sei, model = "lm", predictor = "sei")
))
(egger_ci <- confint(egger$fit)["Xsei", ])

# Classical Egger regression test for the meta-analysis of gender_differences
(egger_gender <- with(
  dat_gender, regtest(x = gi, sei = sei, model = "lm", predictor = "sei")
))
(egger_ci_gender <- confint(egger_gender$fit)["Xsei", ])
```

We inspected funnel plots and performed Egger regression tests to examine the possibility of publication bias in the literature included here. For the meta-analysis of mental rotation performance (Fig. 3a), we observed a slight asymmetry in the funnel plot, indicating a small publication bias. This was confirmed by an Egger regression test that showed a reliable association between effect sizes and their corresponding standard errors, $b = `r coef(egger$fit)["Xsei"]`$, $t(`r egger$dfs`) = `r egger$zval`$, $p = `r print_p(egger$pval)`$, 95% confidence interval (CI) [`r egger_ci["2.5 %"]`, `r egger_ci["97.5 %"]`] (two-sided test). Nevertheless, a jackknife (leave-one-out analysis) confirmed that the current results are robust to the effects of individual outlier studies (Supplementary Table 3). For the meta-analysis of gender differences in mental rotation performance (Fig. 3a), the asymmetry in the funnel plot was less pronounced and the slope of the Egger regression test was not statistically significant, $b = `r coef(egger_gender$fit)["Xsei"]`$, $t(`r egger_gender$dfs`) = `r egger_gender$zval`$, $p = `r print_p(egger_gender$pval)`$, 95% confidence interval (CI) [`r egger_ci_gender["2.5 %"]`, `r egger_ci_gender["97.5 %"]`] (two-sided test).

```{r, fig3, include=TRUE, fig.height=3.5, fig.width=12, fig.cap="(ref:fig3-caption)"}
# Create funnel plots
list(dat, dat_gender) %>%
  map(function(plot_dat) {

    # Define maximul SE of interest (a bit larger than the largest observed one)
    max_se <- max(plot_dat$sei) + 0.05

    # Compute a 95% funnel under the null hypothesis
    z_crit_05 <- stats::qnorm(0.975)
    funnel_greater_05 <- data.frame(
      x = c(0 - z_crit_05 * sqrt(max_se^2), 0, 0 + z_crit_05 * sqrt(max_se^2)),
      y = c(max_se, 0, max_se),
      level = "greater_05"
    )

    # Compute a 99% funnel under the null hypothesis
    z_crit_01 <- stats::qnorm(0.995)
    funnel_smaller_05 <- data.frame(
      x = c(0 - z_crit_01 * sqrt(max_se^2), 0, 0 + z_crit_01 * sqrt(max_se^2)),
      y = c(max_se, 0, max_se),
      level = "smaller_05"
    )

    # Create a third pseudo-funnel under the null hypothesis just for the legend
    funnel_smaller_01 <- mutate(funnel_greater_05, level = "smaller_01")

    # Compute a 95% funnel around the observed meta-analytic effect size
    funnel_observed <- mutate(funnel_greater_05, x = x + summ_brm$intercept)

    # Plot the funnel(s)
    ggplot(plot_dat, aes(x = gi, y = sei)) +
      # Funnels under the null hypothesis
      geom_polygon(data = funnel_smaller_01, aes(x = x, y = y, fill = level)) +
      geom_polygon(data = funnel_smaller_05, aes(x = x, y = y, fill = level)) +
      geom_polygon(data = funnel_greater_05, aes(x = x, y = y, fill = level)) +
      scale_fill_manual(
        values = c("gray80", "grey90", "white"),
        breaks = c("greater_05", "smaller_05", "smaller_01"),
        labels = c(
          expression(italic(p) > .05),
          expression(italic(p) < .05),
          expression(italic(p) < .01)
        )
      ) +
      # Grid lines
      geom_vline(xintercept = seq(-2, 2, 0.5), color = "grey90") +
      # Observed_funnel
      geom_path(data = funnel_observed, aes(x = x, y = y)) +
      # Meta-analytic effect size
      geom_vline(xintercept = summ_brm$intercept, color = "black") +
      # Experiment-specific effect sizes
      geom_point(shape = 0) +
      # Styling
      scale_x_continuous(breaks = seq(-2, 2, 0.5)) +
      scale_y_reverse() +
      coord_cartesian(
        xlim = c(-2.5, 2.5),
        ylim = c(max_se, 0),
        expand = FALSE
      ) +
      labs(
        x = expression("Hedges'" ~ italic("g")), y = "Standard error",
        fill = "Significance level"
      ) +
      theme_classic() +
      theme(
        axis.line = element_line(colour = "black"),
        axis.text = element_text(family = "Helvetica", color = "black"),
        axis.ticks = element_line(color = "black"),
        legend.position = "none",
        text = element_text(family = "Helvetica", color = "black")
      )
  }) -> plots_funnel

# Extract legend
legend_funnel <- get_legend(
  plots_funnel[[1]] + theme(legend.position = "right")
)

# Combine plots and legend
plot_grid(
  plotlist = plots_funnel, nrow = 1, labels = "auto",
  label_size = 11, label_fontfamily = "Helvetica"
) +
  draw_plot(legend_funnel, x = -0.39, y = 0.355)

# Save the plot
ggsave(here(figures_dir, "funnel.pdf"), width = 12, height = 3.5)
```

(ref:fig3-caption) **Evaluation of publication bias.**  Funnel plots for the meta-analysis of mental rotation performance (**a**) and for the meta-analysis of gender differences in mental rotation performance (**b**). The plots show the standard error and effect size for each of the individual experiments as a black square. The funnel contours (diagonal black lines) depict a 95% pseudo-confidence interval around the meta-analytic effect size (vertical black line). Gray shades indicate a 95% pseudo-confidence interval (dark gray) and 99% pseudo-confidence interval (light gray) under the null hypothesis. These shades thus illustrate which of the original studies observed a significant effect. For the meta-analysis of mental rotation performance, a slight asymmetry induced by the underrepresentation of studies with high standard errors and small effect sizes suggests a small publication bias.

# Discussion

We analyzed looking times during mental rotation in `r formatC(descs$n_infants, big.mark = ",")` infants ranging from `r descs$min_age_months` to `r descs$max_age_months` months of age. To this end, we scrutinized the robustness of `r descs$n_experiments` experimental effect sizes. We found that male infants looked on average slightly longer at novel rotated objects compared to female infants. This effect was small and unrelated to age in the current range.

## Effect size estimates

We interpret the meta-regression-based estimate of the gender difference ($b = `r summ_brm_reg$male_female`$, where $b = \Delta{g}$) as an upper bound of the true effect size since this estimate is based on experiments that reported only separate effect sizes for males and females. The gender effect of these experiments can be considered as positively biased when assuming that authors who observe a statistically significant gender difference more likely report separate effect sizes for males and females. In contrast, the meta-analytic estimate derived from the observed gender differences within each experiment ($g = `r summ_brm_gender$intercept`$) can be viewed as a lower bound of the true effect size. This view is plausible because the unknown effect sizes of experiments without significant gender differences were set to zero although non-zero differences were likely also observed but just not reported because of missing power to render these effects statistically significant.

## Gender differences

The gender differences observed here remain to be explained by interacting genetic and environmental factors that are largely unknown. To the best of our knowledge, there are currently no genetic association or gene-environment interaction studies with a focus on mental rotation. Nevertheless, it is documented that genetic contributions to behavioral variance in mental rotation are substantially smaller than unique non-shared environmental contributions both in male and female adults [@shakeshaft2016]. Whether this observation also applies to infants remains to be explored.

One recent study on 5--6-month-old female infants provided preliminary evidence for possible social-environmental effects related to parental attitudes towards gender which might partly explain the results of our present work [@constantinescu2018]. As far as we know, potentially mediating and moderating factors that could already be operational in infancy, however, are not yet empirically established. In a similar vein, while mental rotation training has small-to-medium post-test effects in children, it is unclear whether it can remove gender differences and be adapted to infants [@uttal2013].

Sex hormone concentration in male infants, especially postnatal testosterone in the first six months of life, could also contribute to gender differences in mental rotation performance [@toivainen2018; @constantinescu2018; @erdmann2019]. Possible biological developmental pathways, however, bridging the gap from hormonal to behavioral differences are currently far from understood.

## Additional factors

A number of additional factors have been associated with individual differences in infant mental rotation performance. For example, mental rotation is related to previous relevant experience with the particular objects used in the specific task [@mohring2013; @schwarzer2013a; @slone2018]. This relation also applies to previous experience with manually rotating toys [@schwarzer2013a]. While these preliminary results require replication they are in line with the longstanding notion that prior knowledge is the strongest predictor of learning outcomes in a range of cognitive domains (e.g. [@ausubel1968; @bradley1983; @halberda2008]). Furthermore, there is yet to be confirmed preliminary evidence for possible links between mental rotation performance and several sensory motor skills including fine and gross motor skills, oculomotor control, and crawling skills [@schwarzer2013; @schwarzer2013a].

# Conclusion

The present study robustly revealed that male infants look longer at novel rotated objects than female infants. Thus, on average, males show more reliable mental rotation behavior already in the first months of life.

# Methods

## Protocol

In the present meta-analysis we followed the established PRISMA 2020 guidelines (Preferred Reporting Items for Systematic reviews and Meta-Analyses) [@page2021]. The PRISMA flowchart is provided in Fig. 4 and Supplementary Table 4 contains the PRISMA checklist.

## Eligibility criteria

Articles needed to fulfill six criteria for being included in this meta-analysis: (1) The article was written in English or German; (2) The article includes results from a group study with human samples (thus excluding review articles, meta-analyses, case studies, and animal studies); (3) These samples include at least one group of infants (mean age between 0 months and 36 months); (4) Infants were not born preterm and had no clinical diagnosis; (5) Infants performed a mental rotation task; (6) The article contains quantitative scores that could be converted into a standardized mean difference (see Data collection process and items below). We explicitly included works that were not peer reviewed (e.g., dissertations and preprints) to reduce the impact of publication bias.

```{r, fig4, include=TRUE, fig.width=6, fig.cap="(ref:fig4-caption)", out.width="50%"}
# Include the flowchart (created with MS PowerPoint)
knitr::include_graphics(here("manuscript_files/flowchart.pdf"))
```

(ref:fig4-caption) **Literature search and selection process.** **a,** We searched four online databases as well as reviews and reference sections to identify articles in which mental rotation experiments in infants were reported. **b,** Experiments were included in the meta-analysis if they fulfilled six pre-specified inclusion criteria. **c,** Redundant articles comprising the same experiment(s) were excluded. Additionally, we excluded an article that was based on an uncommon experimental paradigm differing substantially from all other articles (1 article). Finally, we excluded an article that was based on a sample of infants  who were substantially older compared to all other articles (1 article).

## Information sources and search strategy

We entered the search terms (“mental rotation” OR “mental transformation” OR “spatial rotation” OR “spatial transformation” OR “spatial ability” OR “spatial skills”) AND (“infant” OR “infants” OR “infanthood” OR “toddler” OR “toddlers” OR “toddlerhood” OR “child” OR “children” OR “childhood” OR “month” OR “months”) into four online databases (APA PsycINFO, PubMed/MEDLINE, Scopus, and ProQuest Dissertations & Theses Global). All database queries were completed on December 6, 2021. We configured the databases to check for article titles, abstracts, and keywords while applying no other filters or limits. This yielded 2,616 articles in total, 1,954 of which remained after removing duplicate records (Figure 4a). We further identified 76 articles by screening the reference sections of previous reviews and meta-analyses on mental rotation and related skills [@frick2014; @johnson2020; @kubicek2018; @lauer2019a; @linn1985; @moore2020; @uttal2013; @voyer1995; @yang2020]. Of these, 34 articles had not been covered by the database search. We also identified 94 articles by screening the reference sections of all publications that had been included after the first pass of the selection process. Of these, 49 articles had not been covered by the database search. Accordingly, we screened 2,037 unique articles in total.

## Selection process

```{r, selection_process}
# Compute interrater agreement for binary decision (include vs. exclude)
(irr_bin_perc <- with(screening, mean(bin_1 == bin_2)))
(irr_bin_kappa <- with(screening, psych::cohen.kappa(cbind(bin_1, bin_2))))
irr_bin_kappa_w <- as.list(irr_bin_kappa$confid["weighted kappa", ])

# Compute interrater agreement for specific exclusion codes
(irr_code_perc <- with(screening, mean(code_1 == code_2)))
(irr_code_kappa <- with(screening, psych::cohen.kappa(cbind(code_1, code_2))))
irr_code_kappa_w <- as.list(irr_code_kappa$confid["weighted kappa", ])

# Justify exclusion of @pedrett2020 based on outlier mean age
descs_pedrett2020 <- list(age_years = 2.56)
descs_pedrett2020 <- within(descs_pedrett2020, {
  age_months <- age_years * 12
  next_largest_age_months <- max(dat$age_mean) / 30.417
  age <- age_years * 365.25
  z <- (age - mean(dat$age_mean)) / sd(dat$age_mean)
})
```

Two independent raters read the abstract and, if necessary, relevant sections of the full text to check if an article fulfilled the inclusion criteria. Interrater agreement for the binary decision to include versus exclude an article was `r print_perc(irr_bin_perc)` ($\kappa_w$ [Cohen's weighted kappa] $= `r irr_bin_kappa_w$estimate`$, 95% CI [`r irr_bin_kappa_w$lower`, `r irr_bin_kappa_w$upper`]). Interrater agreement for the specific eligibility criteria were `r print_perc(irr_code_perc)` ($\kappa_w$ $= `r irr_code_kappa_w$estimate`$, 95% CI [`r irr_code_kappa_w$lower`, `r print_num(irr_code_kappa_w$upper)`]). Cases where the two ratings diverged were resolved via discussion among all raters until a consensus was reached. One article [@mash2007] was excluded because the authors used a unique mental rotation paradigm that was not comparable to the paradigm used in the other articles. Another article [@pedrett2020] was excluded because the average age of the infants studied (`r print_num(descs_pedrett2020$age_months, 1)` months) was almost twice as high as the average age of the next article (`r print_num(descs_pedrett2020$next_largest_age_months, 1)` months; $z = `r descs_pedrett2020$z`$ compared to all articles). We therefore decided to narrow our analysis from the first 3 years of life to the first 16 months of life. This procedure led to a total of `r descs$n_articles` articles being included in the meta-analysis (Fig. 4).

Many of these articles consisted of multiple experiments, e.g., using different variations of the mental rotation task or different subsamples of infants. We included all of these experiments in the meta-analysis and accounted for the dependencies between them by means of multilevel modeling with by-article random effects (see Bayesian meta-analysis below). However, we excluded experiments if there was insufficient information to compute a standardized effect size (see Data collection process and items below). Whenever an article reported separate effect sizes for males and females---or other subgroups like crawling and non-crawling infants---but also an effect size combining these groups, we only included the combined effect size. Moreover, we disregarded effect sizes that were clearly based on the same data but reported in different articles. This procedure led to a total of `r descs$n_experiments` experiments being included in the meta-analysis of mental rotation performance (Supplementary Table 1) and 30 articles being included in the meta-analysis of gender differences in mental rotation performance.

## Data collection process and items

Outcome measures and other relevant variables were extracted from each article by one of three raters and verified by a second rater. For the meta-analysis of mental rotation performance, outcome measures were any summary statistic (Table 1) that could be used to determine the standardized mean difference between novel/unexpected rotation events and familiar/expected rotation events (see Introduction). Other extracted variables included, if available, the sample size, the number of males and females, the mean age and its standard deviation, the minimum and maximum age, the type of mental rotation task (habituation or violation of expectation), the modality of stimulus presentation (real objects or objects on a computer screen), and the dimensionality of the stimuli (2D or 3D; Supplementary Table 1).

\scriptsize

+----------------------------------------------------------------+---------------------------------------------------------------------------------------------+
| Available statistics                                           | Conversion to standardized mean difference (Hedges' $g$)                                    |
+================================================================+=============================================================================================+
| (1\) Cohen's $d$ and sample size                               | ${df}=2(n-1)$;\quad                                                                         |
| [@goulet-pelletier2018; @hedges1985]                           | $J({df})=\frac{\Gamma(\frac{1}{2}{df})}{\sqrt{\frac{{df}}{2}}\Gamma(\frac{1}{2}({df}-1))}$; |
|                                                                | \quad $g_\text{rotation}=d\cdot{J}({df})$                                                   |
+----------------------------------------------------------------+---------------------------------------------------------------------------------------------+
| (2\) $t$-statistic and sample size [@rosenthal1991]            | $d=\frac{t}{\sqrt{n}}$;\quad then (1)                                                       |
+----------------------------------------------------------------+---------------------------------------------------------------------------------------------+
| (3\) $F$-statistic and sample size [@lakens2013]               | $t=\sqrt{f}$;\quad then (2\)                                                                |
+----------------------------------------------------------------+---------------------------------------------------------------------------------------------+
| (4\) Mean difference between conditions [@lakens2013]          | $d=\frac{m_\text{diff}}{{SD}_\text{diff}}$;\quad then (1)                                   |
+----------------------------------------------------------------+---------------------------------------------------------------------------------------------+
| (5\) Mean looking time and ${SD}$ per condition [@cumming2012] | ${SD}_\text{av}=\sqrt{\frac{{SD}_\text{novel}^2+{SD}_\text{familiar}^2}{2}}$;\quad          |
|                                                                | $d=\frac{m_\text{novel}-m_\text{familiar}}{{SD}_\text{av}}$;\quad then (1)                  |
+----------------------------------------------------------------+---------------------------------------------------------------------------------------------+
| (6\) Mean novelty preference score [@lakens2013]               | $d=\frac{m_\text{pref}}{{SD}_\text{pref}}$;\quad then (1)                                   |
+----------------------------------------------------------------+---------------------------------------------------------------------------------------------+

Table: Extracted between-article summary statistics and conversion to effect sizes

\normalsize

We also conducted a meta-analysis of the gender differences in mental rotation performance observed within the original articles. For this analysis, the outcome measures were any summary statistic (Table 2) that could be used to determine the standardized mean difference between male infants' mental rotation performance and female infants' mental rotation performance. Other extracted variables included the sample size, the mean age and its standard deviation, and the minimum and maximum age of each gender group.

\scriptsize

+----------------------------------------+--------------------------------------------------------------------------------------------------+
| Available statistics                   | Conversion to standardized mean difference (Hedges' $g$)                                         |
+========================================+==================================================================================================+
| (1\) Cohen's $d$ and group sizes       | ${df}=n_\text{female}+n_\text{male}-1$; \quad                                                    |
| [@goulet-pelletier2018; @hedges1985]   | $J({df})=\frac{\Gamma(\frac{1}{2}{df})}{\sqrt{\frac{{df}}{2}}\Gamma(\frac{1}{2}({df}-1))}$;\quad |
|                                        | $g_\text{gender}=d\cdot{J({df})}$                                                                |
+----------------------------------------+--------------------------------------------------------------------------------------------------+
| (2\) $t$-statistic and group sizes     | $d=t\sqrt{\frac{1}{n_\text{female}}+\frac{1}{n_\text{male}}}$;\quad then (1)                     |
| [@lakens2013]                          |                                                                                                  |
+----------------------------------------+--------------------------------------------------------------------------------------------------+
| (3\) $F$-statistic and group sizes     | $t=\sqrt{f}$;\quad then (2\)                                                                     |
| [@lakens2013]                          |                                                                                                  |
+----------------------------------------+--------------------------------------------------------------------------------------------------+
| (4\) Mean differences between          | ${SD}_\text{pooled}=\sqrt{\frac{(n_\text{female}-1){SD}_\text{female}^2                          |
| conditions or preference scores        | +(n_\text{male}-1){SD}_\text{male}^2}{df}}$;\quad                                                |
| [@lakens2013]                          | $d=\frac{m_\text{female}-m_\text{male}}{{SD}_\text{pooled}}$;\quad then (1)                      |
+----------------------------------------+--------------------------------------------------------------------------------------------------+

Table: Extracted within-article summary statistics and conversion to effect sizes

\normalsize

No investigators were contacted for obtaining or confirming additional data and no automated tools were used in the data collection process.

## Effect size measures

For the meta-analysis of mental rotation performance, one outcome measure per experiment was converted into a standardized mean difference with small sample correction (Hedges' $g$) using the formulas provided in Table 1. The standard error of Hedges' $g$ for each experiment was computed using the formula provided by @goulet-pelletier2018: $${SE}_\text{rotation}=\sqrt{\frac{{df}}{{df}-2}\frac{2(1-r)}{n}\left(1+g_\text{rotation}^2\frac{n}{2(1-r)}\right)-\frac{g_\text{rotation}^2}{J({df})^2}}$$ where $n$ is the sample size of the experiment, ${df}$ are the degrees of freedom (with ${df} = 2*(n-1)$), $r$ is the correlation between the two dependent measures in the experiment, and $J({df})$ is the correction factor for small samples as described in Table 1. The correlation $r$ was not reported in any of the original articles [@harrer2021]. We therefore always assumed a correlation of $r = .50$ to make our analysis comparable to standard (between-group) meta-analyses [@cohen1988; @lakens2013; @morris2002] and because we were able to infer an average correlation of $r \approx .50$ from a subsample of articles which provided sufficient information (Supplementary Methods 1). A sensitivity analysis indicated that changing the assumed correlation to values from $r = -.90$ via $r = .00$ to $r = .90$ had no meaningful impact on the meta-analytic effect size (Supplementary Table 5).

For the meta-analysis of gender differences in mental rotation performance, one outcome measure per contrast between non-redundant male and female groups of infants was converted into a standardized mean difference with small sample correction (Hedges' $g$) using the formulas provided in Table 2. The standard error of Hedges' $g$ for each gender contrast was computed using the formula provided by @goulet-pelletier2018: $${SE}_\text{gender}=\sqrt{\frac{{df}}{{df}-2}\frac{2}{\tilde{n}}\left(1+g_\text{gender}^2\frac{\tilde{n}}{2}\right)-\frac{g_\text{gender}^2}{J({df})^2}}$$ where $df$ are the degrees of freedom (with $df=n_\text{female}+n_\text{male}-2$), $\tilde{n}$ is the harmonic mean of the group sizes (i.e., $\tilde{n}=\frac{2}{n_\text{female}^{-1}+n_\text{male}^{-1}}$), and $J(df)$ is the correction factor for small samples as described in Row (1) of Table 2.

## Bayesian meta-analysis

We synthesized the effect sizes and their sampling variances using a Bayesian multilevel model. This model had three levels, with infant participants nested in experiments and experiments nested in articles [@vandennoortgate2013]. We used a weakly-informative $\mathcal{N}(0,1)$ (normal) prior for the meta-analytic effect size and a weakly-informative $\mathcal{HC}(0,0.3)$ (half-Cauchy) prior for all standard deviations [@williams2018]. A prior sensitivity analysis indicated that making these priors either more informative or less informative did not change the meta-analytic results (Supplementary Table 5). For the meta-analysis of mental rotation performance, the dependent variable was the standardized mean difference (Hedges' $g$) between the novel and familiar rotation condition, weighted by its standard error (see Effect size measures above). For the meta-analysis of gender differences, the dependent variable was the standardized mean difference (Hedges' $g$) between male infants' mental rotation performance and female infants' mental rotation performance, weighted by its standard error. All Bayesian models were fitted using the brms package (Version `r packageVersion("brms")`) [@burkner2017; @burkner2018] in R (Version `r packageVersion("base")`) [@rcoreteam2021] and the Stan language (Version `r packageVersion("rstan")`) [@standevelopmentteam2022]. Markov Chain Monte Carlo (MCMC) sampling was used with four parallel chains, each sampling `r formatC(n_iter, big.mark = ",")` draws (including `r formatC(n_warmup, big.mark = ",")` warm-up draws) from the posterior distribution. To verify the convergence of the Markov chains, we examined rank plots as well as the $R_\text{hat}$ and $N_\text{eff}$ statistics (Supplementary Fig. 2) [@vehtari2021]. For reporting, the credible interval (CrI) for each model parameter was computed as the 95% equal-tailed interval (ETI) of its posterior distribution, although replacing this with the 95% highest density interval (HDI) yielded highly similar results [@kruschke2015].

## Bayesian meta-regression

We examined the influence of three moderator variables on the mental rotation outcomes across studies, namely (a) the gender of the sample of infants, (b) the age of the sample of infants, and (c) the type of mental rotation task. Gender was coded as a categorical predictor (mixed-gender sample, all-female sample, all-male sample) and contrast-coded using two successive difference contrasts [@schad2020] so that we could compare all-female versus mixed samples and all-male samples versus all-female samples. Age was coded as a continuous predictor in years and centered by subtracting the average across all studies. Task was coded as a categorical predictor (habituation task, violation of expectation task) and contrast-coded using a scaled sum contrast [@schad2020]. We then included these predictors for gender, age, and task type as well as two predictors for the interaction between gender task type (i.e., [female - mixed] $\times$ age and [male - female] $\times$ age) into a Bayesian meta-regression model. This model used the same random effects structure and sampling parameters as described above.

## Frequentist meta-analysis

We verified the results obtained from our Bayesian analyses using classical frequentist meta-analysis and meta-regression. To this end, we used the metafor package (Version `r packageVersion("metafor")`) [@viechtbauer2010] in R to specify the same three-level models as described above but without the Bayesian priors (Supplementary Table 5). These models were fitted using restricted maximum likelihood estimation (REML). To verify that the REML converged on the correct estimates, we examined profile likelihood plots [@raue2009; @viechtbauer2010] for the two variance components in the model (i.e., the between-experiment variance and the between-article variance; Supplementary Fig. 3).

## Reporting bias and certainty assessment

Publication bias was evaluated based on funnel plots and Egger regression tests [@egger1997; @sterne2005]. Funnel plots visualize the relationship between standard errors and effect sizes. They were created by adapting code from the R package metaviz (Version `r packageVersion("metaviz")`) [@kossmeier2020]. The Egger regression test is a formal statistical test for this relationship between standard errors and effect sizes, probing if the weighted linear regression weight of the effect sizes on the standard errors is significantly different from zero. This test was performed using code from the metafor package and applying a two-sided false-positive error rate of $\alpha = .05$.

To scrutinize the robustness of the meta-analytic effect size against the influence of any individual experiment (which may or may not be a false positive), we conducted a jackknife leave-one-out-analysis for the meta-analysis of mental rotation performance [@gee2005; @efron1993]. To this end, we adapted code from the bootstrap R package (Version `r packageVersion("bootstrap")`) [@kostyshak2019]. Specifically, we refitted the Bayesian three-level model repeatedly while leaving out one of the original experiments on every iteration. To take into account the variance inherent in Bayesian model estimation, we averaged over $x$ iterations of the jackknife.

We also performed trim-and-fill analyses and tested selection models to confirm the robustness of the results obtained from the frequentist meta-analyses against publication bias (Supplementary Methods 2; Supplementary Tables 8 and 9; Supplementary Figure 4) [@duval2000; @vevea1995; @vevea2005].

## Data availability

The data for this study is available  from an   [Open Science Framework](https://osf.io/k3wdg/?view_only=06a4a0ac3d5f4681baab11751c1498b8) repository [@enge2022a]. This link is intended for peer review only and will be replaced with a public link upon acceptance.

## Code availability

The data for this study is available from an  [Open Science Framework](https://osf.io/k3wdg/?view_only=06a4a0ac3d5f4681baab11751c1498b8) repository [@enge2022a].  This link is intended for peer review only and will be replaced with a public link upon acceptance.

\newpage

# References

\bigskip

<div id="refs"></div>

\newpage

# Contributions

M.A.S. conceived, designed, and obtained funding for the study.  

A.E., S.K., and A.K. designed and executed the search strategy, performed study selection and screening procedures, managed the database of search results and performed data analysis in consultation with M.A.S. 

A.E. and M.A.S. wrote the manuscript with feedback from S.K. and A.K.

\newpage

```{r child = "supplement.Rmd"}
```
