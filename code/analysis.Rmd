---
title: "A meta-analysis of mental rotation ability in the first years of life"
author: "Alexander Enge, Shreya Kapoor, Anne-Sophie Kieslinger & Michael A. Skeide"
date: "`r paste('Commit', substr(git2r::commits()[[1]]$sha, 1, 7))`"
output:
  pdf_document:
    latex_engine: xelatex
---

```{r, setup, include=FALSE}
# Load packages
library(here)
library(ggridges)
library(tidyverse)
library(magrittr)
library(metafor)
library(brms)
library(tidybayes)
library(cowplot)

# Global chunk options
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  fig.height = 10,
  fig.width = 7.5,
  out.width = "100%"
)

# Directory paths
data_dir <- here("data")
figures_dir <- here("results/figures")
tables_dir <- here("results/tables")

# Download literature search spreadsheet from Google Drive
excel_url <- "https://docs.google.com/spreadsheets/d/1xnC0NlQYTXavXaeqQidhi7UKb1pCGAl9Ry3h3Uz3mi0"
excel_file <- here(data_dir, "literature_search.xlsx")
# googledrive::drive_auth(use_oob = TRUE)
# googledrive::drive_download(excel_url, excel_file, overwrite = TRUE)

# Read sheets
screening <- readxl::read_excel(excel_file, sheet = "screening")
included <- readxl::read_excel(excel_file, sheet = "included", na = "NA")

# Add columns to the table of included experiments
included %>%
  mutate(

    # Add unique experiment identifier
    experiment = str_c(year, article, group, sep = ", "),

    # Add difference between condition means
    mean_diff = case_when(
      !is.na(mean_diff) ~ mean_diff,
      TRUE ~ mean_novel - mean_familiar
    ),
    # Add d_z from paired t test of condition means (Rosenthal, 1991)
    d_z_t = t / sqrt(sample_size),
    # Add d_z from ANOVA F value via conversion to a t value
    d_z_f = sqrt(f) / sqrt(sample_size) * sign_f,
    # Add d_z from mean and standard deviation of the difference
    d_z_diff = mean_diff / sd_diff,
    # Add d_av from mean difference and standard devations
    # See http://dx.doi.org/10.20982/tqmp.14.4.p242
    sd_av = sqrt((sd_novel^2 + sd_familiar^2) / 2),
    d_av = mean_diff / sd_av,
    # Add d from one-sample t test of novelty preference scores
    d_nov_pref = (nov_pref - 0.5) / sd_nov_pref,

    # Choose one type of outcome variable for each experiment
    di = case_when(
      # 1. If d was reported directed
      !is.na(d) ~ d,
      # 2. If a paired sample t test was reported
      !is.na(d_z_t) ~ d_z_t,
      # 3. If ANOVA was reported
      !is.na(d_z_f) ~ d_z_f,
      # 4. If the difference between means and its SD were reported
      !is.na(d_z_diff) ~ d_z_diff,
      # 5. If the individual condition means and their SDs were reported
      !is.na(d_av) ~ d_av,
      # 6. If a novelty preference score and its SD were reported
      !is.na(d_nov_pref) ~ d_nov_pref
    ),
    # Keep track which type of outcome measure was chosen for each article
    di_type = case_when(
      !is.na(d) ~ "d",
      !is.na(d_z_t) ~ "d_z_t",
      !is.na(d_z_f) ~ "d_z_f",
      !is.na(d_z_diff) ~ "d_z_diff",
      !is.na(d_av) ~ "d_av",
      !is.na(d_nov_pref) ~ "d_nov_pref",
      TRUE ~ "none"
    ) %>%
      factor(levels = c(
        "d", "d_z_t", "d_z_f", "d_z_diff", "d_av", "d_nov_pref", "none"
      )),

    # Apply small sample correction using Hedges' exact method
    # See http://dx.doi.org/10.20982/tqmp.14.4.p242
    dfi = 2 * (sample_size - 1),
    ji = exp(lgamma(dfi / 2) - log(sqrt(dfi / 2)) - lgamma((dfi - 1) / 2)),
    gi = di * ji,

    # Compute empirical correlation based on sd_z and condition SDs
    d_z = case_when(
      !is.na(d_z_t) ~ d_z_t,
      !is.na(d_z_f) ~ d_z_f,
      !is.na(d_z_diff) ~ d_z_diff
    ),
    sd_z = mean_diff / d_z,
    ri = (sd_z^2 - sd_novel^2 - sd_familiar^2) / (-2 * sd_novel * sd_familiar)
  ) %>%
  # Order rows by experiment ID
  arrange(experiment) -> dat_all

# Overview of the different effect sizes
dat_all %>%
  select(
    article,
    group,
    gender_split,
    gi,
    di,
    di_type,
    d,
    d_z_t,
    d_z_f,
    d_z_diff,
    d_av,
    d_nov_pref,
    ri
  ) %>%
  print(n = Inf)

# Get empirical estimate of the correlation between dependent samples
summary(dat_all$ri)

# Compute standard error of Cohen's d based on assumed correlation
# See Hedges' formula on p. 253 in http://dx.doi.org/10.20982/tqmp.14.4.p242
# This will need a sensitivity analysis regarding the values of `r_assumed`
r_assumed <- 0.5
dat_all %>%
  mutate(
    ni = sample_size,
    vi = (dfi / (dfi - 2)) * ((2 * (1 - r_assumed)) / ni) *
      (1 + gi^2 * (ni / (2 * (1 - r_assumed)))) - (gi^2 / ji^2),
    sei = sqrt(vi)
  ) %>%
  filter(!is.na(gi)) -> dat_all_r

# Show number of experiments per gender grouping strategy
table(dat_all_r$gender_split)

# Extract split or mixed experiments only
dat_split <- filter(dat_all_r, gender_split %in% c("split", "split_only"))
dat_mixed <- filter(dat_all_r, gender_split %in% c("mixed", "mixed_only"))

# Combine both strategies, preferring split experiments
dat_both_split <- filter(
  dat_all_r, gender_split %in% c("split", "mixed_only", "split_only")
)

# Combine both strategies, preferring mixed experiments
dat_both_mixed <- filter(
  dat_all_r, gender_split %in% c("mixed", "mixed_only", "split_only")
)

# We go ahead with the last solution as to use the maximum amount of information
# while not biasing the gender results
dat <- dat_both_mixed
```

# Introduction

```{r, results_literature_search}
# Number of experiments
nrow(dat)

# Number of infants
sum(dat$sample_size)

# Age range in months
min(dat$age_min, na.rm = TRUE) / 30.417
max(dat$age_max, na.rm = TRUE) / 30.417

# Mean age in months
sum((dat$age_mean * dat$sample_size)) / sum(dat$sample_size) / 30.417

# Number of experiments per task type
table(dat$task)
```

# Results

## Mental rotation ability

```{r, meta_analysis}
# Three-level model
res_ml <- rma.mv(
  gi, vi,
  random = ~ 1 | article / experiment,
  data = dat,
  slab = experiment
)
print(res_ml)
# forest(res_ml)

# Check heterogeneity
(i2 <- dmetar::var.comp(res_ml))
# plot(i2)

# Check share of variance at each level of the model
round(res_ml$sigma2[1] / sum(res_ml$sigma2), 3) # Between-article (ICC)
round(res_ml$sigma2[2] / sum(res_ml$sigma2), 3) # Within-article (between-exp.)

# # Profile likelihodd plots for checking that REML has converged
# profile(res_ml)
```

```{r, meta_analysis_bayes}
# Specify priors
prior_c <- c(
  set_prior("normal(0, 1)", class = "Intercept"),
  set_prior("cauchy(0, 0.3)", class = "sd")
)

# Run prior predictive simulation
res_prior <- brm(
  gi | se(sei) ~ 1 + (1 | article / experiment),
  data = dat,
  prior = prior_c,
  sample_prior = "only",
  save_pars = save_pars(all = TRUE),
  chains = 4,
  iter = 10000,
  cores = 4,
  control = list(adapt_delta = 0.99)
)
summary(res_prior)
# plot(res_prior)

# Run Bayesian multilevel model
res_brm <- update(res_prior, sample_prior = FALSE)
summary(res_brm)
# plot(res_brm)

# Compute intra-class correlation
sd_article <- VarCorr(res_brm)$article$sd
sd_experiment <- VarCorr(res_brm)$`article:experiment`$sd
(icc <- sd_article / (sd_article + sd_experiment))

# Compute probabilities of the meta-analytic being greater than 0
hypothesis(res_brm, "Intercept > 0")$hypothesis
```

```{r, fig_forest}
# Define some plotting parameters
n_experiments <- length(unique(dat$experiment))
linewidth <- 0.5

# Helper functions for printing confidence intervals
print_num <- function(x, digits = 2) {
  x <- format(round(x, digits), trim = TRUE, nsmall = digits)
  x[x == "NA"] <- NA
  return(x)
}
print_ci <- function(est, lb, ub) {
  paste0(print_num(est), " [", print_num(lb), ", ", print_num(ub), "]")
}

# Get posterior draws for each experiment
draws <- epred_draws(res_brm, dat, ndraws = NULL) %>%
  mutate(experiment_f = factor(experiment))

# Get posterior draws for the meta-analytic effect
meta_draws <- spread_draws(res_brm, b_Intercept, ndraws = NULL)
meta_effect_size <- summary(res_brm)$fixed

# Create forest plot
dat %>%
  # Make sure the plot will be ordered alphabetically by experiment IDs
  arrange(experiment) %>%
  mutate(
    experiment_f = fct_rev(fct_expand(factor(experiment), "model")),
    # Show article labels only for the first experiment per article
    article = if_else(article == lag(article, default = ""), "", article),
    # Compute frequentist confidence intervals
    ci_lb = gi - qnorm(0.05 / 2, lower.tail = FALSE) * sqrt(vi),
    ci_ub = gi + qnorm(0.05 / 2, lower.tail = FALSE) * sqrt(vi),
    ci_print = print_ci(gi, ci_lb, ci_ub)
  ) %>%
  # Prepare plotting canvas
  ggplot(aes(x = gi, y = experiment_f)) +
  geom_vline(
    xintercept = seq(-3, 3, 0.5), size = linewidth / 2, color = "grey70"
  ) +
  # Add article and group labels as text on the left
  geom_text(aes(x = -9.9, label = article), hjust = 0) +
  geom_text(aes(x = -7.1, label = group_long), hjust = 0) +
  # Add experiment-specific effect sizes and CIs as text on the right
  geom_text(aes(x = 3.7, label = print_num(gi)), hjust = 1) +
  geom_text(aes(x = 4.4, label = print_num(ci_lb)), hjust = 1) +
  geom_text(aes(x = 5.1, label = print_num(ci_ub)), hjust = 1) +
  # Add Bayesian highest posterior density intervals for each experiment
  stat_interval(
    aes(x = .epred),
    data = draws,
    alpha = .8,
    point_interval = "mean_qi",
    .width = c(0.5, 0.95),
  ) +
  scale_color_grey(
    start = 0.85, end = 0.65,
    labels = as_mapper(~ scales::percent(as.numeric(.x)))
  ) +
  # Add experiment-specific effect sizes and CIs as dots with error bars
  geom_linerange(aes(xmin = ci_lb, xmax = ci_ub), size = 0.35) +
  geom_point(aes(size = ni), shape = 22, fill = "white") + # Or (1 / vi)?
  # Add posterior distribution for the meta-analytic effect
  stat_halfeye(
    aes(x = b_Intercept, y = -1),
    meta_draws,
    point_interval = "mean_qi",
    .width = c(0.95)
  ) +
  annotate(
    "text",
    x = c(-9.9, 3.7, 4.4, 5.1),
    y = -0.5,
    label = c(
      "Three-level model",
      print_num(meta_effect_size$Estimate),
      print_num(meta_effect_size$`l-95% CI`),
      print_num(meta_effect_size$`u-95% CI`)
    ),
    hjust = c(0, 1, 1, 1),
    fontface = "bold"
  ) +
  # Add headers for each of the for columns
  annotate( # Just to make the grid lines disappear
    "rect",
    xmin = -Inf,
    xmax = Inf,
    ymin = n_experiments + 0.5,
    ymax = Inf,
    fill = "white"
  ) +
  annotate(
    "text",
    x = c(-9.9, -7.1, 0, 3.7, 4.4, 5.1),
    y = n_experiments + 1.5,
    label = c(
      "Article",
      "Experiment",
      "Effect size plot",
      "Effect size",
      "Lower",
      "Upper"
    ),
    hjust = c(0, 0, 0.5, 1, 1, 1),
    fontface = "bold"
  ) +
  # Styling
  coord_cartesian(ylim = c(-1.5, n_experiments + 2), expand = FALSE) +
  scale_x_continuous(breaks = seq(-3, 3, 0.5)) +
  labs(
    x = expression("Hedges'" ~ italic("g")),
    size = "Sample size",
    color = "CrI level"
  ) +
  theme_minimal() +
  theme(
    legend.position = "bottom",
    axis.text.x = element_text(family = "Helvetica", color = "black"),
    axis.text.y = element_blank(),
    axis.title.x = element_text(hjust = 0.67, margin = margin(t = 7, b = -10)),
    axis.title.y = element_blank(),
    panel.grid = element_blank(),
    text = element_text(family = "Helvetica")
  )

# Save the plot
ggsave(here(figures_dir, "forest.pdf"), width = 12, height = 14)
```

```{r, tab_within}
# Helper functions to re-format age in years and/or months
format_days_months <- function(days) {
  days_per_month <- 30.417
  months <- days %/% days_per_month
  days_left <- round(days - months * days_per_month)
  str <- paste0(as.character(months), "m ", as.character(days_left), "d")
  str[is.na(days)] <- NA
  return(str)
}

# Save within-analysis table of experiments
dat %>%
  mutate(
    age_mean = format_days_months(age_mean),
    age_sd = str_c(as.character(round(age_sd)), "d"),
  ) %>%
  transmute(
    Article = if_else(article == lag(article, default = ""), "", article),
    Experiment = group_long,
    `Sample size` = sample_size,
    `Females` = round(female_percent * sample_size),
    Age = str_c(age_mean, "±", age_sd, sep = " "),
    Task = task,
    `Stimulus type` = str_to_sentence(stimuli_presentation),
    `Stimulus dimensions` = stimuli_dimensions
  ) %>%
  write_csv(
    file = here(tables_dir, "within_experiments.csv"),
    na = "n/a"
  )
```

## Moderator variables

```{r, meta_regression}
# Recode predictor variables for meta-regression and plotting
dat %>%
  mutate(

    # Gender as a categorical (factor) variable
    gender = case_when(
      female_percent == 1.0 ~ "Female",
      female_percent == 0.0 ~ "Male",
      TRUE ~ "Mixed"
    ) %>% factor(levels = c("Mixed", "Female", "Male")),

    # Mean sample age in years, centered around the mean
    age = age_mean / 365.25,
    age_c = age - mean(age, na.rm = TRUE),
    age_sd = age_sd / 365.25,

    # Task type as a categorical (factor) variale
    task = factor(task, levels = c("Habituation", "VoE")),

    # Combine gender and task into one column for plotting
    gender_task = factor(
      str_c(gender, task, sep = ", "),
      levels = c(
        "Female, Habituation",
        "Male, Habituation",
        "Mixed, Habituation",
        "Mixed, VoE"
      )
    )
  ) -> dat_reg

# Set numerical contrasts for factor variables
contrasts(dat_reg$gender) <- MASS::contr.sdif(3)
contrasts(dat_reg$task) <- MASS::contr.sdif(2)

# Meta-regression with gender, age, and task
res_reg <- rma.mv(
  gi, vi,
  mods = ~ gender * age_c + task,
  random = ~ 1 | article / experiment,
  data = dat_reg,
  slab = experiment
)
print(res_reg)
# forest(res_full)

# Compute intra-class correlation
sd_article_reg <- VarCorr(res_brm_reg)$article$sd
sd_experiment_reg <- VarCorr(res_brm_reg)$`article:experiment`$sd
(icc_reg <- sd_article_reg / (sd_article_reg + sd_experiment_reg))

# Compute reduction in heterogeneity compared to the original meta-analysis
1 - (sd_article_reg + sd_experiment_reg) / (sd_article + sd_experiment)

# Compute probabilities of the different effects being greater than 0
hypothesis(res_brm_reg, "gender3M2 > 0")$hypothesis
hypothesis(res_brm_reg, "gender2M1 < 0")$hypothesis
hypothesis(res_brm_reg, "task2M1 > 0")$hypothesis
```

```{r, meta_regression_bayes}
# Specify priors
prior_c <- c(
  set_prior("normal(0, 1)", class = "Intercept"),
  set_prior("normal(0, 0.5)", class = "b"),
  set_prior("cauchy(0, 0.3)", class = "sd")
)

# Run prior predictive simulation
res_prior_reg <- brm(
  gi | se(sei) ~ gender * age_c + task + (1 | article / experiment),
  data = dat_reg,
  prior = prior_c,
  sample_prior = "only",
  save_pars = save_pars(all = TRUE),
  chains = 4,
  iter = 10000,
  cores = 4,
  control = list(adapt_delta = 0.99)
)
summary(res_prior_reg)
# plot(res_prior_reg)

# Run Bayesian multilevel model
res_brm_reg <- update(res_prior_reg, sample_prior = FALSE)
summary(res_brm_reg)
# plot(res_brm_reg)
```

```{r, fig_regression}
# Get draws from the posterior distribution
draws_reg <- epred_draws(
  res_brm_reg,
  dat_reg,
  ndraws = NULL,
  re_formula = NA
)

# Summarise to obtain HPDIs
draws_reg_hdi <- mean_qi(draws_reg)

# Use colors as proposed in https://arxiv.org/abs/2107.02270
habi_colors <- c(
  "Female, Habituation" = "#5790fc",
  "Male, Habituation" = "#f89c20",
  "Mixed, Habituation" = "#e42536"
)
voe_colors <- c("Mixed, VoE" = "#964a8b")

# Regression plot
dat_reg %>%
  ggplot(aes(x = age * 12, y = gi)) +
  geom_hline(yintercept = 0, size = linewidth / 2) +
  # Regression lines and HPDIs - Habituation tasks
  stat_lineribbon(
    aes(y = .epred, color = gender_task),
    data = draws_reg,
    alpha = .4,
    point_interval = "mean_qi",
    .width = c(0.5, 0.95)
  ) +
  # Individual study effect sizes - Habituation tasks
  geom_point(aes(color = gender_task, size = ni), shape = 0) +
  scale_color_manual(
    values = habi_colors,
    breaks = names(habi_colors),
    labels = c("Females", "Males", "Mixed gender"),
    na.value = NA
  ) +
  guides(color = guide_legend(
    title = "Habituation tasks",
    override.aes = list(fill = NA),
    order = 1
  )) +
  # Regression lines and HPDIs - VoE tasks
  ggnewscale::new_scale_color() +
  stat_lineribbon(
    aes(y = .epred, color = gender_task),
    data = draws_reg,
    fill = NA,
    alpha = .4,
    point_interval = "mean_qi",
    .width = c(0.5, 0.95)
  ) +
  # Individual study effect sizes - VoE tasks
  geom_point(aes(color = gender_task, size = ni), shape = 0) +
  scale_color_manual(
    values = voe_colors,
    breaks = names(voe_colors),
    labels = c("Mixed gender"),
    na.value = NA
  ) +
  guides(color = guide_legend(title = "VoE tasks", order = 2)) +
  # Styling
  coord_cartesian(expand = FALSE) +
  scale_x_continuous(limits = c(2.9, 16.1), breaks = seq(3, 16, 1)) +
  scale_y_continuous(limits = c(-1.2, 2.2), breaks = seq(-1, 2, 0.5)) +
  scale_fill_grey(
    start = 0.85, end = 0.65,
    labels = as_mapper(~ scales::percent(as.numeric(.x)))
  ) +
  labs(
    x = "Age (months)",
    y = expression("Hedges'" ~ italic("g")),
    fill = "CrI level",
    size = "Sample size"
  ) +
  theme_bw() +
  theme(
    axis.text = element_text(family = "Helvetica", color = "black"),
    axis.ticks = element_line(color = "black", size = linewidth / 2),
    legend.direction = "vertical",
    legend.key = element_blank(),
    legend.position = "none",
    panel.border = element_rect(color = "black", size = linewidth),
    panel.grid = element_blank(),
    text = element_text(family = "Helvetica", color = "black")
  ) -> plot_reg

# Extract the legend so that we can put it inside the plotting area
plot_reg_legend <- get_legend(plot_reg + theme(legend.position = "top"))

# Define new labels for the regression coefficients
coef_colnames <- c(
  "Intercept" = "b_Intercept",
  "Females - mixed" = "b_gender2M1",
  "Males - females" = "b_gender3M2",
  "Age (per year)" = "b_age_c",
  "Habituation - VoE" = "b_task2M1",
  "(Females - Mixed) × age" = "b_gender2M1:age_c",
  "(Males - Females) × age" = "b_gender3M2:age_c"
)

# Plot posterior distributions of the regression coefficients
draws_reg_coef <- tidy_draws(res_brm_reg)
draws_reg_coef %>%
  select(all_of(coef_colnames)) %>%
  gather() %>%
  mutate(coef = factor(key, levels = names(coef_colnames))) %>%
  ggplot(aes(x = value, y = fct_rev(coef))) +
  geom_vline(xintercept = 0, size = linewidth / 2) +
  stat_halfeye(point_interval = "mean_qi", .width = c(0.5, 0.95)) +
  coord_cartesian(xlim = c(-1.25, 1.25)) +
  scale_x_continuous(breaks = seq(-1, 1, 0.5)) +
  labs(
    x = expression("Regression weight (" * Delta * italic("g") * ")"),
    y = "Fixed effect"
  ) +
  theme_bw() +
  theme(
    axis.text = element_text(family = "Helvetica", color = "black"),
    axis.title.y = element_text(margin = margin(l = 17, r = -17)),
    axis.ticks = element_line(color = "black", size = linewidth / 2),
    panel.grid = element_blank(),
    axis.text.y = element_text(hjust = 1),
    panel.border = element_rect(color = "black", size = linewidth),
    text = element_text(family = "Helvetica", color = "black")
  ) -> plot_coef

# Combine plots
plot_grid(
  plot_reg, plot_coef,
  nrow = 1, rel_widths = c(3, 2), labels = "auto",
  label_size = 12, label_fontfamily = "Helvetica",
  label_x = 0.008, label_y = 0.995
) +
  draw_plot(plot_reg_legend, x = 0.37, y = 0.84, hjust = 0.5, vjust = 0.5)

# Save plot
ggsave(here(figures_dir, "regression_coef.pdf"), width = 12, height = 5)
```

# Methods

## Information sources and search strategy

Article sources:

```{r}
table(screening$source)
```

## Selection process

### Interrater agreement

Percent agreement for binary decision (include/exclude):

```{r}
with(screening, mean(bin_1 == bin_2))
```

Cohen's kappa for binary decision (include/exclude):

```{r}
with(screening, psych::cohen.kappa(cbind(bin_1, bin_2)))
```

Correlation (phi) for binary decision (include/exclude):

```{r}
with(screening, cor.test(bin_1, bin_2))
```

Percent agreement for exclusion codes:

```{r}
with(screening, mean(code_1 == code_2))
```

Cohen's kappa for exclusion codes:

```{r}
with(screening, psych::cohen.kappa(cbind(code_1, code_2)))
```

### Final decisions

Exlucsion codes:

```{r}
cat("1 = not in english
2 = not a group study
3 = not infants
4 = not typically developing
5 = no mental rotation
6 = no within-group statistics
7 = include paper
8 = no access or insufficient statistics")
table(screening$code_final)
```

### Included experiments

Total number of articles (according to `screening` table):

```{r}
sum(screening$code_final == 7)
```

Total number of articles (according to `included` table):

```{r}
length(unique(included$article))
```

Total number of experiments:

```{r}
nrow(included)
```

Number of non-redundant experiments:

```{r}
nrow(filter(included, !redundant))
```

Number of experiments per type of effect size:

```{r}
table(included$di_type)
```

Total number of infants across experiments:

```{r}
sum(included$sample_size)
```

Descriptive information about the infant samples:

```{r}
included %>%
  select(sample_size, age_mean, age_sd, age_min, age_max, female_percent) %>%
  summary()
```

Age and gender distributions of all experiments:

```{r}
included %>%
  uncount(1e4) %>%
  mutate(
    group_text = if_else(is.na(group), "NA", group),
    id_group = str_c(article, ", ", group_text),
    id_group_ordered = fct_reorder(id_group, age_mean, .desc = TRUE),
    age_sd = if_else(!is.na(age_sd), age_sd, 10.),
    days = rnorm(n(), age_mean, age_sd),
    months = days / 30.417,
  ) %>%
  ggplot(aes(x = months, y = id_group_ordered, fill = female_percent)) +
  geom_density_ridges() +
  scale_fill_distiller(palette = "RdYlBu") +
  coord_cartesian(xlim = c(1, 20), expand = FALSE) +
  labs(x = "Age (m)", fill = "Percent\nfemale") +
  theme_minimal() +
  theme(
    axis.title.y = element_blank(),
    legend.position = "bottom",
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    text = element_text(family = "Helvetica", size = 10)
  )
```

Sample sizes and ages of all experiments:

```{r}
included %>%
  mutate(months = age_mean / 30.417) %>%
  ggplot(aes(
    x = months,
    y = sample_size,
    size = sample_size,
    color = female_percent
  )) +
  geom_point() +
  scale_color_viridis_c() +
  scale_size(guide = "none") +
  coord_cartesian(xlim = c(0, 16)) +
  labs(x = "Age (m)", y = "Sample size", color = "Percent\nfemale") +
  theme_minimal() +
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    text = element_text(family = "Helvetica", size = 10)
  )
```

```{r, simulation}
generate_exp <- function(n_boys = 1e3,
                         n_girls = 1e3,
                         mean_diff_boys = 0,
                         mean_diff_girls = 2,
                         sd_diff_boys = 4,
                         sd_diff_girls = 4) {

  # Create randomly sampled data for boys and girls
  # Each element is the mean looking time difference for one infant
  boys <- rnorm(n_boys, mean_diff_boys, sd_diff_boys)
  girls <- rnorm(n_girls, mean_diff_girls, sd_diff_girls)

  # Compute separate effect sizes for the two split gender groups
  d_boys <- mean(boys) / sd(boys)
  d_girls <- mean(girls) / sd(girls)

  # Compute common effect size for the mixed gender group
  infants <- c(boys, girls)
  n_infants <- length(infants)
  d_infants <- mean(infants) / sd(infants)

  # Return all results for this experiment as a list
  return(list(
    n_boys = n_boys,
    n_girls = n_girls,
    n_infants = n_infants,
    d_boys = d_boys,
    d_girls = d_girls,
    d_infants = d_infants
  ))
}

# Generate random experiments
n_boys <- 1e3
n_girls <- 1e3
n_exps <- 100
dat <- replicate(n_exps, generate_exp(n_boys, n_girls), simplify = FALSE)
dat <- do.call(rbind.data.frame, dat)
dat$article <- paste0("exp_", 1:n_exps)

### MIXED EXPERIMENTS ONLY ###

# Compute sampling variance of the effect size for each study; see
# https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/effects.html#w-group-smd
r_assumed <- .5
dat$v_d_infants <- with( # Sampling variances of the effect sizes
  dat, ((2 * (1 - r_assumed)) / n_infants) + (d_infants^2 / (2 * n_infants))
)

# Fit 3 level meta-analysis
res_full <- metafor::rma.mv(
  d_infants, v_d_infants,
  # random = ~ article | article,
  data = dat,
  slab = article
)

# Check results
summary(res_full)

### SPLIT EXPERIMENTS ONLY ###

# Put effect sizes for boys and girls into separate rows
dat_split <- tidyr::pivot_longer(
  dat,
  cols = c(d_boys, d_girls),
  names_to = "gender",
  values_to = "d_gender"
)

# Compute sampling variance of the gender-specific effect size
dat_split$v_d_gender <- with(
  dat_split, ((2 * (1 - r_assumed)) / n_girls) + (d_gender^2 / (2 * n_girls))
)

# Use rma.mv to compute MA on d_gender and v_d_gender values

# Repeat 100 times with generate_meta

# Compare mixed gender and split gender MAs
# Same distribution of meta-analytic effect size?
# Same variance / standard error?
# Is the difference significant?

### MIXED/SPLIT GENDER ANALYSIS ###

# Make a percentage of study use mixed vs. split and choose randomly
# Use different percentages
# Make split vs. mixed dependent on the observed gender difference
# Note for this we need to draw study specific effect sizes from a distribution

### MAKE IT MORE REALISTIC ###

# Make sample sizes per study different

# Automate
generate_meta <- function(n_exps, n_boys, n_girls) {

  # Generate random experiments
  dat <- replicate(n_exps, generate_exp(n_boys, n_girls), simplify = FALSE)
  dat <- do.call(rbind.data.frame, dat)
  dat$article <- paste0("exp_", 1:n_exps)

  # Compute sampling variance of the effect size for each study; see
  # https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/effects.html#w-group-smd
  r_assumed <- .5
  dat$v_d_infants <- with( # Sampling variances of the effect sizes
    dat, ((2 * (1 - r_assumed)) / n_infants) + (d_infants^2 / (2 * n_infants))
  )

  # Fit meta-analysis
  res_full <- metafor::rma.mv(
    d_infants, v_d_infants,
    # random = ~ article | article,
    data = dat,
    slab = article
  )

  # Return coefficients table
  summ <- summary(res_full)
  return(coef(summ))
}

n_metas <- 100
metas <- replicate(n_metas, generate_meta(100, 100, 100), simplify = FALSE)
metas <- do.call(rbind.data.frame, metas)
metas$article <- paste0("meta_", 1:n_metas)

mean(metas$estimate)
```

# Supplementary information

```{r, prior_sens}
# Prior sensitivity analysis
list(
  "interept_uninformative" = c(
    set_prior("uniform(-3, 3)", class = "Intercept"),
    set_prior("cauchy(0, 0.3)", class = "sd")
  ),
  "interept_informative" = c(
    set_prior("normal(0, 0.2)", class = "Intercept"),
    set_prior("cauchy(0, 0.3)", class = "sd")
  ),
  "sd_uninformative" = c(
    set_prior("normal(0, 1)", class = "Intercept"),
    set_prior("uniform(0, 10)", class = "sd", ub = 10)
  ),
  "sd_informative" = c(
    set_prior("normal(0, 1)", class = "Intercept"),
    set_prior("student_t(10, 0, 0.2)", class = "sd")
  )
) %>%
  map(function(prior_sens) update(res_brm, prior = prior_sens)) -> res_sens
map(res_sens, summary)
```
