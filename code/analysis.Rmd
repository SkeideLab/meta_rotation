---
title: "A meta-analysis of mental rotation ability in the first years of life"
author: "Alexander Enge, Shreya Kapoor, Anne-Sophie Kieslinger & Michael A. Skeide"
date: "`r paste('Commit', substr(git2r::commits()[[1]]$sha, 1, 7))`"
output:
  pdf_document:
    latex_engine: xelatex
---

```{r, setup, include=FALSE}
# Load packages
library(here)
library(ggridges)
library(tidyverse)
library(magrittr)
library(metafor)
library(brms)
library(tidybayes)

# Global chunk options
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  fig.height = 10,
  fig.width = 7.5,
  out.width = "100%"
)

# Directory paths
data_dir <- here("data")
figures_dir <- here("results/figures")

# Download literature search spreadsheet from Google Drive
excel_url <- "https://docs.google.com/spreadsheets/d/1xnC0NlQYTXavXaeqQidhi7UKb1pCGAl9Ry3h3Uz3mi0"
excel_file <- here(data_dir, "literature_search.xlsx")
# googledrive::drive_auth(use_oob = TRUE)
# googledrive::drive_download(excel_url, excel_file, overwrite = TRUE)

# Read sheets
screening <- readxl::read_excel(excel_file, sheet = "screening")
included <- readxl::read_excel(excel_file, sheet = "included", na = "NA")
```

# Results

## Mental rotation ability

```{r, prepare_effect_sizes}
# Add columns to the table of included experiments
included %>%
  mutate(

    # Add unique experiment identifier
    experiment = str_c(article, group, seq = ", "),

    # Add difference between condition means
    mean_diff = case_when(
      !is.na(mean_diff) ~ mean_diff,
      TRUE ~ mean_novel - mean_familiar
    ),
    # Add d_z from paired t test of condition means (Rosenthal, 1991)
    d_z_t = t / sqrt(sample_size),
    # Add d_z from ANOVA F value via conversion to a t value
    d_z_f = sqrt(f) / sqrt(sample_size) * sign_f,
    # Add d_z from mean and standard deviation of the difference
    d_z_diff = mean_diff / sd_diff,
    # Add d_av from mean difference and standard devations
    # See http://dx.doi.org/10.20982/tqmp.14.4.p242
    sd_av = sqrt((sd_novel^2 + sd_familiar^2) / 2),
    d_av = mean_diff / sd_av,
    # Add d from one-sample t test of novelty preference scores
    d_nov_pref = (nov_pref - 0.5) / sd_nov_pref,

    # Choose one type of outcome variable for each experiment
    di = case_when(
      # 1. If d was reported directed
      !is.na(d) ~ d,
      # 2. If a paired sample t test was reported
      !is.na(d_z_t) ~ d_z_t,
      # 3. If ANOVA was reported
      !is.na(d_z_f) ~ d_z_f,
      # 4. If the difference between means and its SD were reported
      !is.na(d_z_diff) ~ d_z_diff,
      # 5. If the individual condition means and their SDs were reported
      !is.na(d_av) ~ d_av,
      # 6. If a novelty preference score and its SD were reported
      !is.na(d_nov_pref) ~ d_nov_pref
    ),
    # Keep track which type of outcome measure was chosen for each article
    di_type = case_when(
      !is.na(d) ~ "d",
      !is.na(d_z_t) ~ "d_z_t",
      !is.na(d_z_f) ~ "d_z_f",
      !is.na(d_z_diff) ~ "d_z_diff",
      !is.na(d_av) ~ "d_av",
      !is.na(d_nov_pref) ~ "d_nov_pref",
      TRUE ~ "none"
    ) %>%
      factor(levels = c(
        "d", "d_z_t", "d_z_f", "d_z_diff", "d_av", "d_nov_pref", "none"
      )),

    # Apply small sample correction using Hedges' exact method
    # See http://dx.doi.org/10.20982/tqmp.14.4.p242
    dfi = 2 * (sample_size - 1),
    ji = exp(lgamma(dfi / 2) - log(sqrt(dfi / 2)) - lgamma((dfi - 1) / 2)),
    gi = di * ji,

    # Compute empirical correlation based on sd_z and condition SDs
    d_z = case_when(
      !is.na(d_z_t) ~ d_z_t,
      !is.na(d_z_f) ~ d_z_f,
      !is.na(d_z_diff) ~ d_z_diff
    ),
    sd_z = mean_diff / d_z,
    ri = (sd_z^2 - sd_novel^2 - sd_familiar^2) / (-2 * sd_novel * sd_familiar)
  ) -> dat_all

# Overview of the different effect sizes
dat_all %>%
  select(
    article,
    group,
    gender_split,
    gi,
    di,
    di_type,
    d,
    d_z_t,
    d_z_f,
    d_z_diff,
    d_av,
    d_nov_pref,
    ri
  ) %>%
  print(n = Inf)

# Get empirical estimate of the correlation between dependent samples
summary(dat_all$ri)

# Compute standard error of Cohen's d based on assumed correlation
# See Hedges' formula on p. 253 in http://dx.doi.org/10.20982/tqmp.14.4.p242
# This will need a sensitivity analysis regarding the values of `r_assumed`
r_assumed <- 0.5
dat_all %>%
  mutate(
    ni = sample_size,
    vi = (dfi / (dfi - 2)) * ((2 * (1 - r_assumed)) / ni) *
      (1 + gi^2 * (ni / (2 * (1 - r_assumed)))) - (gi^2 / ji^2),
    sei = sqrt(vi)
  ) %>%
  filter(!is.na(gi)) %>%
  select(
    article,
    group,
    experiment,
    gender_split,
    gi,
    ni,
    vi,
    sei,
    female_percent,
    age_mean,
    age_sd,
    age_min,
    age_max
  ) -> dat_all_r

# Show number of experiments per gender grouping strategy
table(dat_all_r$gender_split)

# Extract split or mixed experiments only
dat_split <- filter(dat_all_r, gender_split %in% c("split", "split_only"))
dat_mixed <- filter(dat_all_r, gender_split %in% c("mixed", "mixed_only"))

# Combine both strategies, preferring split experiments
dat_both_split <- filter(
  dat_all_r, gender_split %in% c("split", "mixed_only", "split_only")
)

# Combine both strategies, preferring mixed experiments
dat_both_mixed <- filter(
  dat_all_r, gender_split %in% c("mixed", "mixed_only", "split_only")
)

# We go ahead with the last solution as to use the maximum amount of information
# while not biasing the gender results
dat_select <- dat_both_mixed

# Recode predictor variables for meta-regression and plotting
dat_select %>%
  mutate(

    # Gender as a categorical variable
    gender = case_when(
      female_percent == 1.0 ~ "Female",
      female_percent == 0.0 ~ "Male",
      TRUE ~ "Mixed"
    ) %>% factor(levels = c("Mixed", "Female", "Male")),

    # Mean sample age in months, centered around the mean
    age = age_mean / 30.417,
    age_c = age - mean(age, na.rm = TRUE),
    age_sd = age_sd / 30.417,
    .keep = "unused"
  ) -> dat
```

```{r, meta_analysis}
# Three-level model
res_ml <- rma.mv(
  gi, vi,
  random = ~ 1 | article / experiment,
  data = dat,
  slab = experiment
)
print(res_ml)
# forest(res_ml)

# # Profile likelihodd plots for checking that REML has converged
# profile(res_ml)
```

```{r, meta_analysis_bayes}
# Specify priors
prior_c <- c(
  set_prior("normal(0, 1)", class = "Intercept"),
  set_prior("cauchy(0, 0.3)", class = "sd")
)

# Run prior predictive simulation
res_prior <- brm(
  gi | se(sei) ~ 1 + (1 | article / experiment),
  data = dat,
  prior = prior_c,
  sample_prior = "only",
  save_pars = save_pars(all = TRUE),
  chains = 4,
  iter = 10000,
  cores = 4,
  control = list(adapt_delta = 0.99)
)
summary(res_prior)
# plot(res_prior)

# Run Bayesian multilevel model
res_brm <- update(res_prior, sample_prior = FALSE)
summary(res_brm)
# plot(res_brm)
```

```{r, fig_forest}
# Forest plot inputs
level <- 0.05
ndraws <- 1000

# Helper function for printing confidence intervals
print_num <- function(x) format(round(x, 2), trim = TRUE, nsmall = 2)
print_ci <- function(est, lb, ub) {
  paste0(print_num(est), " [", print_num(lb), ", ", print_num(ub), "]")
}

# Get draws from the Bayesian posterior distribution
draws <- epred_draws(res_brm, dat, ndraws = ndraws)
meta_draws <- spread_draws(res_brm, b_Intercept, ndraws = ndraws) %>%
  mutate(article = "Three-level model", experiment = "zzz") # For the last line

# Create forest plot
dat %>%
  # Compute frequentist confidence intervals
  mutate(
    ci_lb = gi - qnorm(level / 2, lower.tail = FALSE) * sqrt(vi),
    ci_ub = gi + qnorm(level / 2, lower.tail = FALSE) * sqrt(vi),
    fontface = "plain" # For study labels and confidence interval
  ) %>%
  # Add meta-analytic effect size + CI
  bind_rows(list(
    article = "Three-level model",
    group = "",
    experiment = "zzz", # Just so it's displayed as the last line
    gi = res_ml$b,
    ci_lb = res_ml$ci.lb,
    ci_ub = res_ml$ci.ub,
    fontface = "bold"
  )) %>%
  # Format effect size + CI for printing them on the plot
  mutate(ci_print = print_ci(gi, ci_lb, ci_ub)) %>%
  # Reverse order of experiments so they are plotted alphabetically
  mutate(experiment = forcats::fct_rev(factor(experiment))) %>%
  arrange(experiment) %>%
  # Show article labels only for the first experiment per article
  mutate(
    article = if_else(article == lead(article, default = ""), "", article)
  ) %>%
  # Prepare plot
  ggplot(aes(x = gi, y = experiment)) +
  geom_vline(xintercept = seq(-1, 2, 1), size = 0.8, color = "grey90") +
  geom_vline(xintercept = seq(-1.5, 2.5, 1), size = 0.4, color = "grey90") +
  # Add article and group labels as text to the left
  geom_text(aes(x = -5.6, label = article, fontface = fontface), hjust = 0) +
  geom_text(aes(x = -3.1, label = group, fontface = fontface), hjust = 0) +
  # Add experiment specific effect size + CI as text to the right
  geom_text(aes(x = 4.4, label = ci_print, fontface = fontface), hjust = 1) +
  # Add Bayesian highest posterior density interval in the background
  stat_interval(aes(x = .epred), draws, point_interval = "mean_hdi") +
  stat_interval(aes(x = b_Intercept), meta_draws, point_interval = "mean_hdi") +
  scale_color_grey(
    start = 0.9, end = 0.6,
    labels = as_mapper(~ scales::percent(as.numeric(.x)))
  ) +
  labs(color = "Bayesian\nHPDI") +
  # Add study specific effect size + CIs on top
  ggnewscale::new_scale_color() +
  geom_errorbar(aes(xmin = ci_lb, xmax = ci_ub, color = gender)) +
  geom_point(aes(size = ni, color = gender), shape = 15) + # Or (1 / vi)?
  scale_color_brewer(palette = "Dark2", na.translate = FALSE) +
  # Add meta-analytic effect size as a line
  annotate("segment", x = res_ml$b, xend = res_ml$b, y = 0.7, yend = 1.3) +
  annotate("errorbar", xmin = res_ml$ci.lb, xmax = res_ml$ci.ub, y = 1.0) +
  # Styling
  coord_cartesian(expand = FALSE) +
  scale_x_continuous(breaks = seq(-1.5, 2.5, 0.5)) +
  labs(
    x = expression("Hedges'" ~ italic("g")),
    size = "Sample\nsize",
    color = "Gender"
  ) +
  theme_minimal() +
  theme(
    legend.position = "bottom",
    axis.title.x = element_text(hjust = 0.584),
    axis.title.y = element_blank(),
    axis.text.y = element_blank(),
    legend.title = element_text(hjust = 0.5),
    panel.grid = element_blank(),
    text = element_text(family = "Helvetica")
  )

# Save the plot
ggsave(here(figures_dir, "forest.pdf"), width = 9, height = 13)
```

## Moderator variables

```{r, meta_regression}
# Apply sliding difference contrast coding for the gender categories
# This means that the Intercept will be the grand mean (i.e., the average across
# studies) whereas the betas will test female vs. mixed and male vs. female
(contrasts(dat$gender) <- MASS::contr.sdif(3))

# Meta-regression with gender
res_gender <- rma.mv(
  gi, vi,
  mods = ~ gender - 1,
  random = ~ 1 | article / experiment,
  data = dat,
  slab = experiment
)
print(res_gender)
# forest(res_gender)

# Pairwise comparison between the gender groups
anova(res_gender, X = rbind(c(-1, 1, 0), c(-1, 0, 1), c(0, -1, 1)))

# Meta-regression with age
res_age <- rma.mv(
  gi, vi,
  mods = ~age_c,
  random = ~ 1 | article / experiment,
  data = dat,
  slab = experiment
)
print(res_age)
# forest(res_age)

# Meta-regression with gender, age, and their interaction
res_full <- rma.mv(
  gi, vi,
  mods = ~ gender * age_c,
  random = ~ 1 | article / experiment,
  data = dat,
  slab = experiment
)
print(res_full)
# forest(res_full)
```

```{r, fig_regression}
# Plot regression with gender and age
alph <- 0.7
dat %>%
  ggplot(aes(x = age, y = gi, color = gender)) +
  # Data points
  # geom_errorbar(aes(xmin = age - age_sd, xmax = age + age_sd), alpha = alph) +
  # geom_errorbar(aes(ymin = gi - sei, ymax = gi + sei), alpha = alph) +
  geom_point(aes(size = ni), shape = 16, alpha = alph) +
  # Regression lines - currently not reflecting the meta-analytic model
  geom_smooth(method = lm, formula = y ~ x, alpha = .1) +
  # Styling
  scale_x_continuous(limits = c(3, 16), breaks = seq(4, 16, 2)) +
  scale_y_continuous(limits = c(-1.3, 2.5), breaks = seq(-1, 2.5, 0.5)) +
  scale_color_brewer(palette = "Dark2") +
  labs(
    x = "Age (months)",
    y = expression("Hedges'" ~ italic("g")),
    color = "Gender",
    size = "Sample size"
  ) +
  theme_bw() +
  theme(
    panel.border = element_rect(size = 1),
    panel.grid = element_line(color = "grey90"),
    text = element_text(family = "Helvetica"),
  )

# Save the plot
ggsave(here(figures_dir, "regression.pdf"), width = 7, height = 4)
```

# Methods

## Information sources and search strategy

Article sources:

```{r}
table(screening$source)
```

## Selection process

### Interrater agreement

Percent agreement for binary decision (include/exclude):

```{r}
with(screening, mean(bin_1 == bin_2))
```

Cohen's kappa for binary decision (include/exclude):

```{r}
with(screening, psych::cohen.kappa(cbind(bin_1, bin_2)))
```

Correlation (phi) for binary decision (include/exclude):

```{r}
with(screening, cor.test(bin_1, bin_2))
```

Percent agreement for exclusion codes:

```{r}
with(screening, mean(code_1 == code_2))
```

Cohen's kappa for exclusion codes:

```{r}
with(screening, psych::cohen.kappa(cbind(code_1, code_2)))
```

### Final decisions

Exlucsion codes:

```{r}
cat("1 = not in english
2 = not a group study
3 = not infants
4 = not typically developing
5 = no mental rotation
6 = no within-group statistics
7 = include paper
8 = no access or insufficient statistics")
table(screening$code_final)
```

### Included experiments

Total number of articles (according to `screening` table):

```{r}
sum(screening$code_final == 7)
```

Total number of articles (according to `included` table):

```{r}
length(unique(included$article))
```

Total number of experiments:

```{r}
nrow(included)
```

Number of non-redundant experiments:

```{r}
nrow(filter(included, !redundant))
```

Number of experiments per type of effect size:

```{r}
table(included$di_type)
```

Total number of infants across experiments:

```{r}
sum(included$sample_size)
```

Descriptive information about the infant samples:

```{r}
included %>%
  select(sample_size, age_mean, age_sd, age_min, age_max, female_percent) %>%
  summary()
```

Age and gender distributions of all experiments:

```{r}
included %>%
  uncount(1e4) %>%
  mutate(
    group_text = if_else(is.na(group), "NA", group),
    id_group = str_c(article, ", ", group_text),
    id_group_ordered = fct_reorder(id_group, age_mean, .desc = TRUE),
    age_sd = if_else(!is.na(age_sd), age_sd, 10.),
    days = rnorm(n(), age_mean, age_sd),
    months = days / 30.417,
  ) %>%
  ggplot(aes(x = months, y = id_group_ordered, fill = female_percent)) +
  geom_density_ridges() +
  scale_fill_distiller(palette = "RdYlBu") +
  coord_cartesian(xlim = c(1, 20), expand = FALSE) +
  labs(x = "Age (m)", fill = "Percent\nfemale") +
  theme_minimal() +
  theme(
    axis.title.y = element_blank(),
    legend.position = "bottom",
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    text = element_text(family = "Helvetica", size = 10)
  )
```

Sample sizes and ages of all experiments:

```{r}
included %>%
  mutate(months = age_mean / 30.417) %>%
  ggplot(aes(
    x = months,
    y = sample_size,
    size = sample_size,
    color = female_percent
  )) +
  geom_point() +
  scale_color_viridis_c() +
  scale_size(guide = "none") +
  coord_cartesian(xlim = c(0, 16)) +
  labs(x = "Age (m)", y = "Sample size", color = "Percent\nfemale") +
  theme_minimal() +
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    text = element_text(family = "Helvetica", size = 10)
  )
```

```{r, simulation}
generate_exp <- function(n_boys = 1e3,
                         n_girls = 1e3,
                         mean_diff_boys = 0,
                         mean_diff_girls = 2,
                         sd_diff_boys = 4,
                         sd_diff_girls = 4) {

  # Create randomly sampled data for boys and girls
  # Each element is the mean looking time difference for one infant
  boys <- rnorm(n_boys, mean_diff_boys, sd_diff_boys)
  girls <- rnorm(n_girls, mean_diff_girls, sd_diff_girls)

  # Compute separate effect sizes for the two split gender groups
  d_boys <- mean(boys) / sd(boys)
  d_girls <- mean(girls) / sd(girls)

  # Compute common effect size for the mixed gender group
  infants <- c(boys, girls)
  n_infants <- length(infants)
  d_infants <- mean(infants) / sd(infants)

  # Return all results for this experiment as a list
  return(list(
    n_boys = n_boys,
    n_girls = n_girls,
    n_infants = n_infants,
    d_boys = d_boys,
    d_girls = d_girls,
    d_infants = d_infants
  ))
}

# Generate random experiments
n_boys <- 1e3
n_girls <- 1e3
n_exps <- 100
dat <- replicate(n_exps, generate_exp(n_boys, n_girls), simplify = FALSE)
dat <- do.call(rbind.data.frame, dat)
dat$article <- paste0("exp_", 1:n_exps)

### MIXED EXPERIMENTS ONLY ###

# Compute sampling variance of the effect size for each study; see
# https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/effects.html#w-group-smd
r_assumed <- .5
dat$v_d_infants <- with( # Sampling variances of the effect sizes
  dat, ((2 * (1 - r_assumed)) / n_infants) + (d_infants^2 / (2 * n_infants))
)

# Fit 3 level meta-analysis
res_full <- metafor::rma.mv(
  d_infants, v_d_infants,
  # random = ~ article | article,
  data = dat,
  slab = article
)

# Check results
summary(res_full)

### SPLIT EXPERIMENTS ONLY ###

# Put effect sizes for boys and girls into separate rows
dat_split <- tidyr::pivot_longer(
  dat,
  cols = c(d_boys, d_girls),
  names_to = "gender",
  values_to = "d_gender"
)

# Compute sampling variance of the gender-specific effect size
dat_split$v_d_gender <- with(
  dat_split, ((2 * (1 - r_assumed)) / n_girls) + (d_gender^2 / (2 * n_girls))
)

# Use rma.mv to compute MA on d_gender and v_d_gender values

# Repeat 100 times with generate_meta

# Compare mixed gender and split gender MAs
# Same distribution of meta-analytic effect size?
# Same variance / standard error?
# Is the difference significant?

### MIXED/SPLIT GENDER ANALYSIS ###

# Make a percentage of study use mixed vs. split and choose randomly
# Use different percentages
# Make split vs. mixed dependent on the observed gender difference
# Note for this we need to draw study specific effect sizes from a distribution

### MAKE IT MORE REALISTIC ###

# Make sample sizes per study different

# Automate
generate_meta <- function(n_exps, n_boys, n_girls) {

  # Generate random experiments
  dat <- replicate(n_exps, generate_exp(n_boys, n_girls), simplify = FALSE)
  dat <- do.call(rbind.data.frame, dat)
  dat$article <- paste0("exp_", 1:n_exps)

  # Compute sampling variance of the effect size for each study; see
  # https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/effects.html#w-group-smd
  r_assumed <- .5
  dat$v_d_infants <- with( # Sampling variances of the effect sizes
    dat, ((2 * (1 - r_assumed)) / n_infants) + (d_infants^2 / (2 * n_infants))
  )

  # Fit meta-analysis
  res_full <- metafor::rma.mv(
    d_infants, v_d_infants,
    # random = ~ article | article,
    data = dat,
    slab = article
  )

  # Return coefficients table
  summ <- summary(res_full)
  return(coef(summ))
}

n_metas <- 100
metas <- replicate(n_metas, generate_meta(100, 100, 100), simplify = FALSE)
metas <- do.call(rbind.data.frame, metas)
metas$article <- paste0("meta_", 1:n_metas)

mean(metas$estimate)
```

# Supplementary information

```{r, prior_sens}
# Prior sensitivity analysis
list(
  "interept_uninformative" = c(
    set_prior("uniform(-3, 3)", class = "Intercept"),
    set_prior("cauchy(0, 0.3)", class = "sd")
  ),
  "interept_informative" = c(
    set_prior("normal(0, 0.2)", class = "Intercept"),
    set_prior("cauchy(0, 0.3)", class = "sd")
  ),
  "sd_uninformative" = c(
    set_prior("normal(0, 1)", class = "Intercept"),
    set_prior("uniform(0, 10)", class = "sd", ub = 10)
  ),
  "sd_informative" = c(
    set_prior("normal(0, 1)", class = "Intercept"),
    set_prior("student_t(10, 0, 0.2)", class = "sd")
  )
) %>%
  map(function(prior_sens) update(res_brm, prior = prior_sens)) -> res_sens
map(res_sens, summary)
```
