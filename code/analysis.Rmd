---
title: "A meta-analysis of mental rotation ability in the first years of life"
author: "Alexander Enge, Shreya Kapoor, Anne-Sophie Kieslinger & Michael A. Skeide"
date: "`r paste('Commit', substr(git2r::commits()[[1]]$sha, 1, 7))`"
output:
  pdf_document:
    latex_engine: xelatex
---

```{r, setup, include=FALSE}
# Load packages
library(here)
library(ggridges)
library(tidyverse)
library(magrittr)
library(metafor)
library(brms)

# Global chunk options
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  fig.height = 10,
  fig.width = 7.5,
  out.width = "100%"
)
```

```{r, get_data}
# Directory paths
data_dir <- here("data")

# Download literature search spreadsheet from Google Drive
excel_url <- "https://docs.google.com/spreadsheets/d/1xnC0NlQYTXavXaeqQidhi7UKb1pCGAl9Ry3h3Uz3mi0"
excel_file <- here(data_dir, "literature_search.xlsx")
# googledrive::drive_auth(use_oob = TRUE)
# googledrive::drive_download(excel_url, excel_file, overwrite = TRUE)

# Read sheets
screening <- readxl::read_excel(excel_file, sheet = "screening")
included <- readxl::read_excel(excel_file, sheet = "included", na = "NA")
```

# Results

Effect sizes of individual experiments:

```{r, compute_effects, echo=TRUE}
# Add columns to the table of included experiments
included %>%
  mutate(
    # Convert mean sample age from days to months and center
    age_months = age_mean / 30.417,
    age_months_c = age_months - mean(age_months, na.rm = TRUE),
    # Add difference between condition means
    mean_diff = case_when(
      !is.na(mean_diff) ~ mean_diff,
      TRUE ~ mean_novel - mean_familiar
    ),
    # Add d_z from paired t test of condition means (Rosenthal, 1991)
    d_z_t = t / sqrt(sample_size),
    # Add d_z from ANOVA F value via conversion to a t value
    d_z_f = sqrt(f) / sqrt(sample_size) * sign_f,
    # Add d_z from mean and standard deviation of the difference
    d_z_diff = mean_diff / sd_diff,
    # Add d_av from mean difference and standard devations (assumes r = 0.5)
    # (Cumming, 2012)
    sd_av = (sd_novel + sd_familiar) / 2,
    d_av = mean_diff / sd_av,
    # Add d from one-sample t test of novelty preference scores
    d_nov_pref = (nov_pref - 0.5) / sd_nov_pref,
    # Choose one type of outcome variable for each experiment
    di = case_when(
      # 1. If d was reported directed
      !is.na(d) ~ d,
      # 2. If a paired sample t test was reported
      !is.na(d_z_t) ~ d_z_t,
      # 3. If ANOVA was reported
      !is.na(d_z_f) ~ d_z_f,
      # 4. If the difference between means and its SD were reported
      !is.na(d_z_diff) ~ d_z_diff,
      # 5. If the individual condition means and their SDs were reported
      !is.na(d_av) ~ d_av,
      # 6. If a novelty preference score and its SD were reported
      !is.na(d_nov_pref) ~ d_nov_pref
    ),
    # Keep track which type of outcome measure was chosen for each article
    di_type = case_when(
      !is.na(d) ~ "d",
      !is.na(d_z_t) ~ "d_z_t",
      !is.na(d_z_f) ~ "d_z_f",
      !is.na(d_z_diff) ~ "d_z_diff",
      !is.na(d_av) ~ "d_av",
      !is.na(d_nov_pref) ~ "d_nov_pref",
      TRUE ~ "none"
    ) %>%
      factor(levels = c(
        "d", "d_z_t", "d_z_f", "d_z_diff", "d_av", "d_nov_pref", "none"
      )),
    # Find studies with any value of d_z (from t test, ANOVA, or mean_diff)
    d_z = case_when(
      !is.na(d_z_t) ~ d_z_t,
      !is.na(d_z_f) ~ d_z_f,
      !is.na(d_z_diff) ~ d_z_diff
    ),
    # Apply small sample correction using Hedges' exact method
    # See http://dx.doi.org/10.20982/tqmp.14.4.p242
    df = 2 * (sample_size - 1),
    j = exp(lgamma(df / 2) - log(sqrt(df / 2)) - lgamma((df - 1) / 2)),
    gi = di * j,
    # Compute empirical correlation based on sd_z and condition SDs
    sd_z = mean_diff / d_z,
    ri = (sd_z^2 - sd_novel^2 - sd_familiar^2) / (-2 * sd_novel * sd_familiar)
  ) -> dat

# Overview of the different effect sizes
dat %>%
  select(
    article,
    group,
    gender_split,
    gi,
    di,
    di_type,
    d,
    d_z_t,
    d_z_f,
    d_z_diff,
    d_av,
    d_nov_pref,
    ri
  ) %>%
  print(n = Inf)

# Get empirical estimate of the correlation between dependent samples
summary(dat$ri)

# Compute standard error of Cohen's d based on assumed correlation
# This will need a sensitivity analysis
r_assumed <- 0.5
dat %>%
  mutate(
    ni = sample_size,
    vi = ((2 * (1 - r_assumed)) / ni) + (gi^2 / (2 * ni)),
    sei = sqrt(vi)
  ) %>%
  filter(!is.na(gi)) %>%
  select(
    article, group, gender_split, gi, ni, vi, sei, age_months_c, female_percent
  ) -> dat_r

# Show number of experiments per gender grouping strategy
table(dat_r$gender_split)

# Extract mixed/split experiments only
dat_mixed <- filter(dat_r, gender_split %in% c("mixed", "mixed_only"))
dat_split <- filter(dat_r, gender_split %in% c("split", "split_only"))

# Combine both strategies, preferring mixed experiments
dat_both_mixed <- filter(
  dat_r, gender_split %in% c("mixed", "mixed_only", "split_only")
)

# Combine both strategies, preferring mixed experiments
dat_both_split <- filter(
  dat_r, gender_split %in% c("split", "mixed_only", "split_only")
)
```

Actual meta-analysis:

```{r, compute_meta, echo=TRUE}
# # Two-level model
# res_rma <- rma(
#   gi, vi,
#   data = dat_r,
#   slab = experiment_ids
# )
# print(res_rma)
# forest(res_rma)

# Three-level model
res_ml <- rma.mv(
  gi, vi,
  random = ~ 1 | article / group,
  data = dat_both_mixed,
  slab = paste(article, group, sep = ", ")
)
print(res_ml)
# forest(res_ml)

# # Saving the forest plot
# pdf("forest.pdf", width = 12, height = 12)
# forest(res_ml)
# dev.off()

# # Profile likelihodd plots for checking that REML has converged
# profile(res_ml)

# Meta-regression with age
res_age <- rma.mv(
  gi, vi,
  mods = ~age_months_c,
  random = ~ 1 | article / group,
  data = dat_both_mixed,
  slab = paste(article, group, sep = ", ")
)
print(res_age)
# forest(res_age)

# Meta-regression with gender
res_gender <- rma.mv(
  gi, vi,
  mods = ~female_percent,
  random = ~ 1 | article / group,
  data = dat_both_mixed,
  slab = paste(article, group, sep = ", ")
)
print(res_gender)
# forest(res_gender)

# Meta-regression with age, gender, and their interaction
res_full <- rma.mv(
  gi, vi,
  mods = ~ age_months_c * female_percent,
  random = ~ 1 | article / group,
  data = dat_both_mixed,
  slab = paste(article, group, sep = ", ")
)
print(res_full)
# forest(res_full)
```

```{r, brms, echo=TRUE}
# Specify priors
prior_c <- c(
  set_prior("normal(0, 1)", class = "Intercept"),
  set_prior("cauchy(0, 0.3)", class = "sd")
)

# Run prior predictive simulation
res_prior <- brm(
  gi | se(sei) ~ 1 + (1 | article / group),
  data = dat_both_mixed,
  prior = prior_c,
  sample_prior = "only",
  save_pars = save_pars(all = TRUE),
  chains = 4,
  iter = 2000,
  cores = 4,
  control = list(adapt_delta = 0.99)
)
summary(res_prior)
# plot(res_prior)

# Run Bayesian multilevel model
res_brm <- update(res_prior, sample_prior = FALSE)
summary(res_brm)
# plot(res_brm)

# Sensitivity analysis
list(
  "interept_uninformative" = c(
    set_prior("uniform(-3, 3)", class = "Intercept"),
    set_prior("cauchy(0, 0.3)", class = "sd")
  ),
  "interept_informative" = c(
    set_prior("normal(0, 0.2)", class = "Intercept"),
    set_prior("cauchy(0, 0.3)", class = "sd")
  ),
  "sd_uninformative" = c(
    set_prior("normal(0, 1)", class = "Intercept"),
    set_prior("uniform(0, 10)", class = "sd", ub = 10)
  ),
  "sd_informative" = c(
    set_prior("normal(0, 1)", class = "Intercept"),
    set_prior("student_t(10, 0, 0.2)", class = "sd")
  )
) %>%
  map(function(prior_sens) update(res_brm, prior = prior_sens)) -> res_sens
map(res_sens, summary)
```

# Methods

## Information sources and search strategy

Article sources:

```{r}
table(screening$source)
```

## Selection process

### Interrater agreement

Percent agreement for binary decision (include/exclude):

```{r}
with(screening, mean(bin_1 == bin_2))
```

Cohen's kappa for binary decision (include/exclude):

```{r}
with(screening, psych::cohen.kappa(cbind(bin_1, bin_2)))
```

Correlation (phi) for binary decision (include/exclude):

```{r}
with(screening, cor.test(bin_1, bin_2))
```

Percent agreement for exclusion codes:

```{r}
with(screening, mean(code_1 == code_2))
```

Cohen's kappa for exclusion codes:

```{r}
with(screening, psych::cohen.kappa(cbind(code_1, code_2)))
```

### Final decisions

Exlucsion codes:

```{r}
cat("1 = not in english
2 = not a group study
3 = not infants
4 = not typically developing
5 = no mental rotation
6 = no within-group statistics
7 = include paper
8 = no access or insufficient statistics")
table(screening$code_final)
```

### Included experiments

Total number of articles (according to `screening` table):

```{r}
sum(screening$code_final == 7)
```

Total number of articles (according to `included` table):

```{r}
length(unique(included$article))
```

Total number of experiments:

```{r}
nrow(included)
```

Number of non-redundant experiments:

```{r}
nrow(filter(included, !redundant))
```

Number of experiments per type of effect size:

```{r}
table(included$di_type)
```

Total number of infants across experiments:

```{r}
sum(included$sample_size)
```

Descriptive information about the infant samples:

```{r}
included %>%
  select(sample_size, age_mean, age_sd, age_min, age_max, female_percent) %>%
  summary()
```

Age and gender distributions of all experiments:

```{r}
included %>%
  uncount(1e4) %>%
  mutate(
    group_text = if_else(is.na(group), "NA", group),
    id_group = str_c(article, ", ", group_text),
    id_group_ordered = fct_reorder(id_group, age_mean, .desc = TRUE),
    age_sd = if_else(!is.na(age_sd), age_sd, 10.),
    days = rnorm(n(), age_mean, age_sd),
    months = days / 30.417,
  ) %>%
  ggplot(aes(x = months, y = id_group_ordered, fill = female_percent)) +
  geom_density_ridges() +
  scale_fill_distiller(palette = "RdYlBu") +
  coord_cartesian(xlim = c(1, 20), expand = FALSE) +
  labs(x = "Age (m)", fill = "Percent\nfemale") +
  theme_minimal() +
  theme(
    axis.title.y = element_blank(),
    legend.position = "bottom",
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    text = element_text(family = "Helvetica", size = 10)
  )
```

Sample sizes and ages of all experiments:

```{r}
included %>%
  mutate(months = age_mean / 30.417) %>%
  ggplot(aes(
    x = months,
    y = sample_size,
    size = sample_size,
    color = female_percent
  )) +
  geom_point() +
  scale_color_viridis_c() +
  scale_size(guide = "none") +
  coord_cartesian(xlim = c(0, 16)) +
  labs(x = "Age (m)", y = "Sample size", color = "Percent\nfemale") +
  theme_minimal() +
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    text = element_text(family = "Helvetica", size = 10)
  )
```

```{r, simulation}
generate_exp <- function(n_boys = 1e3,
                         n_girls = 1e3,
                         mean_diff_boys = 0,
                         mean_diff_girls = 2,
                         sd_diff_boys = 4,
                         sd_diff_girls = 4) {

  # Create randomly sampled data for boys and girls
  # Each element is the mean looking time difference for one infant
  boys <- rnorm(n_boys, mean_diff_boys, sd_diff_boys)
  girls <- rnorm(n_girls, mean_diff_girls, sd_diff_girls)

  # Compute separate effect sizes for the two split gender groups
  d_boys <- mean(boys) / sd(boys)
  d_girls <- mean(girls) / sd(girls)

  # Compute common effect size for the mixed gender group
  infants <- c(boys, girls)
  n_infants <- length(infants)
  d_infants <- mean(infants) / sd(infants)

  # Return all results for this experiment as a list
  return(list(
    n_boys = n_boys,
    n_girls = n_girls,
    n_infants = n_infants,
    d_boys = d_boys,
    d_girls = d_girls,
    d_infants = d_infants
  ))
}

# Generate random experiments
n_boys <- 1e3
n_girls <- 1e3
n_exps <- 100
dat <- replicate(n_exps, generate_exp(n_boys, n_girls), simplify = FALSE)
dat <- do.call(rbind.data.frame, dat)
dat$article <- paste0("exp_", 1:n_exps)

### MIXED EXPERIMENTS ONLY ###

# Compute sampling variance of the effect size for each study; see
# https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/effects.html#w-group-smd
r_assumed <- .5
dat$v_d_infants <- with( # Sampling variances of the effect sizes
  dat, ((2 * (1 - r_assumed)) / n_infants) + (d_infants^2 / (2 * n_infants))
)

# Fit 3 level meta-analysis
res_full <- metafor::rma.mv(
  d_infants, v_d_infants,
  # random = ~ article | article,
  data = dat,
  slab = article
)

# Check results
summary(res_full)

### SPLIT EXPERIMENTS ONLY ###

# Put effect sizes for boys and girls into separate rows
dat_split <- tidyr::pivot_longer(
  dat,
  cols = c(d_boys, d_girls),
  names_to = "gender",
  values_to = "d_gender"
)

# Compute sampling variance of the gender-specific effect size
dat_split$v_d_gender <- with(
  dat_split, ((2 * (1 - r_assumed)) / n_girls) + (d_gender^2 / (2 * n_girls))
)

# Use rma.mv to compute MA on d_gender and v_d_gender values

# Repeat 100 times with generate_meta

# Compare mixed gender and split gender MAs
# Same distribution of meta-analytic effect size?
# Same variance / standard error?
# Is the difference significant?

### MIXED/SPLIT GENDER ANALYSIS ###

# Make a percentage of study use mixed vs. split and choose randomly
# Use different percentages
# Make split vs. mixed dependent on the observed gender difference
# Note for this we need to draw study specific effect sizes from a distribution

### MAKE IT MORE REALISTIC ###

# Make sample sizes per study different

# Automate
generate_meta <- function(n_exps, n_boys, n_girls) {

  # Generate random experiments
  dat <- replicate(n_exps, generate_exp(n_boys, n_girls), simplify = FALSE)
  dat <- do.call(rbind.data.frame, dat)
  dat$article <- paste0("exp_", 1:n_exps)

  # Compute sampling variance of the effect size for each study; see
  # https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/effects.html#w-group-smd
  r_assumed <- .5
  dat$v_d_infants <- with( # Sampling variances of the effect sizes
    dat, ((2 * (1 - r_assumed)) / n_infants) + (d_infants^2 / (2 * n_infants))
  )

  # Fit meta-analysis
  res_full <- metafor::rma.mv(
    d_infants, v_d_infants,
    # random = ~ article | article,
    data = dat,
    slab = article
  )

  # Return coefficients table
  summ <- summary(res_full)
  return(coef(summ))
}

n_metas <- 100
metas <- replicate(n_metas, generate_meta(100, 100, 100), simplify = FALSE)
metas <- do.call(rbind.data.frame, metas)
metas$article <- paste0("meta_", 1:n_metas)

mean(metas$estimate)
```

