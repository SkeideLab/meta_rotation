---
title: "A meta-analysis of mental rotation ability in the first years of life"
author: "Alexander Enge, Shreya Kapoor, Anne-Sophie Kieslinger & Michael A. Skeide"
date: "`r paste('Commit', substr(git2r::commits()[[1]]$sha, 1, 7))`"
output:
  pdf_document:
    latex_engine: xelatex
---

```{r, setup, include=FALSE}
# Load packages
library(here)
library(ggridges)
library(tidyverse)
library(magrittr)
library(metafor)
library(brms)
library(bayestestR)
library(tidybayes)
library(cowplot)

# Global chunk options
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  fig.height = 10,
  fig.width = 7.5,
  out.width = "100%"
)

# Directory paths
data_dir <- here("data")
figures_dir <- here("results/figures")
tables_dir <- here("results/tables")

# Download literature search spreadsheet from Google Drive
excel_url <- "https://docs.google.com/spreadsheets/d/1xnC0NlQYTXavXaeqQidhi7UKb1pCGAl9Ry3h3Uz3mi0"
excel_file <- here(data_dir, "literature_search.xlsx")
# googledrive::drive_auth(use_oob = TRUE)
# googledrive::drive_download(excel_url, excel_file, overwrite = TRUE)

# Read sheets
screening <- readxl::read_excel(excel_file, sheet = "screening")
included <- readxl::read_excel(excel_file, sheet = "included", na = "NA")

# Add columns to the table of included experiments
included %>%
  mutate(

    # Add unique experiment identifier
    experiment = str_c(year, article, group, sep = ", "),

    # Add difference between condition means
    mean_diff = case_when(
      !is.na(mean_diff) ~ mean_diff,
      TRUE ~ mean_novel - mean_familiar
    ),
    # Add d_z from paired t test of condition means (Rosenthal, 1991)
    d_z_t = t / sqrt(sample_size),
    # Add d_z from ANOVA F value via conversion to a t value
    d_z_f = sqrt(f) / sqrt(sample_size) * sign_f,
    # Add d_z from mean and standard deviation of the difference
    d_z_diff = mean_diff / sd_diff,
    # Add d_av from mean difference and standard devations
    # See http://dx.doi.org/10.20982/tqmp.14.4.p242
    sd_av = sqrt((sd_novel^2 + sd_familiar^2) / 2),
    d_av = mean_diff / sd_av,
    # Add d from one-sample t test of novelty preference scores
    d_nov_pref = (nov_pref - 0.5) / sd_nov_pref,

    # Choose one type of outcome variable for each experiment
    di = case_when(
      # 1. If d was reported directed
      !is.na(d) ~ d,
      # 2. If a paired sample t test was reported
      !is.na(d_z_t) ~ d_z_t,
      # 3. If ANOVA was reported
      !is.na(d_z_f) ~ d_z_f,
      # 4. If the difference between means and its SD were reported
      !is.na(d_z_diff) ~ d_z_diff,
      # 5. If the individual condition means and their SDs were reported
      !is.na(d_av) ~ d_av,
      # 6. If a novelty preference score and its SD were reported
      !is.na(d_nov_pref) ~ d_nov_pref
    ),
    # Keep track which type of outcome measure was chosen for each article
    di_type = case_when(
      !is.na(d) ~ "d",
      !is.na(d_z_t) ~ "d_z_t",
      !is.na(d_z_f) ~ "d_z_f",
      !is.na(d_z_diff) ~ "d_z_diff",
      !is.na(d_av) ~ "d_av",
      !is.na(d_nov_pref) ~ "d_nov_pref",
      TRUE ~ "none"
    ) %>%
      factor(levels = c(
        "d", "d_z_t", "d_z_f", "d_z_diff", "d_av", "d_nov_pref", "none"
      )),

    # Apply small sample correction using Hedges' exact method
    # See http://dx.doi.org/10.20982/tqmp.14.4.p242
    dfi = 2 * (sample_size - 1),
    ji = exp(lgamma(dfi / 2) - log(sqrt(dfi / 2)) - lgamma((dfi - 1) / 2)),
    gi = di * ji
  ) %>%
  # Order rows by experiment ID
  arrange(experiment) -> dat_all

# Overview of the different effect sizes
dat_all %>%
  select(
    article,
    group,
    gender_split,
    gi,
    di,
    di_type,
    d,
    d_z_t,
    d_z_f,
    d_z_diff,
    d_av,
    d_nov_pref
  ) %>%
  print(n = Inf)

# Compute standard error of Cohen's d based on assumed correlation
# See Hedges' formula on p. 253 in http://dx.doi.org/10.20982/tqmp.14.4.p242
# This will need a sensitivity analysis regarding the values of `r_assumed`
r_assumed <- 0.5
dat_all %>%
  mutate(
    ni = sample_size,
    vi = (dfi / (dfi - 2)) * ((2 * (1 - r_assumed)) / ni) *
      (1 + gi^2 * (ni / (2 * (1 - r_assumed)))) - (gi^2 / ji^2),
    sei = sqrt(vi)
  ) %>%
  filter(!is.na(gi)) -> dat_all_r

# Show number of experiments per gender grouping strategy
table(dat_all_r$gender_split)

# Extract split or mixed experiments only
dat_split <- filter(dat_all_r, gender_split %in% c("split", "split_only"))
dat_mixed <- filter(dat_all_r, gender_split %in% c("mixed", "mixed_only"))

# Combine both strategies, preferring split experiments
dat_both_split <- filter(
  dat_all_r, gender_split %in% c("split", "mixed_only", "split_only")
)

# Combine both strategies, preferring mixed experiments
dat_both_mixed <- filter(
  dat_all_r, gender_split %in% c("mixed", "mixed_only", "split_only")
)

# We go ahead with the last solution as to use the maximum amount of information
# while not biasing the gender results
dat <- dat_both_mixed
```

# Introduction

```{r, results_literature_search}
# Number of experiments
nrow(dat)

# Number of infants
sum(dat$sample_size)

# Age range in months
min(dat$age_min, na.rm = TRUE) / 30.417
max(dat$age_max, na.rm = TRUE) / 30.417

# Mean age in months
sum((dat$age_mean * dat$sample_size)) / sum(dat$sample_size) / 30.417

# Number of experiments per task type
table(dat$task)
```

# Results

## Mental rotation ability

```{r, meta_analysis}
# Three-level model
res_ml <- rma.mv(
  gi, vi,
  random = ~ 1 | article / experiment,
  data = dat,
  slab = experiment
)
print(res_ml)
# forest(res_ml)

# Check heterogeneity
(i2 <- dmetar::var.comp(res_ml))
# plot(i2)

# Check share of variance at each level of the model
round(res_ml$sigma2[1] / sum(res_ml$sigma2), 3) # Between-article (ICC)
round(res_ml$sigma2[2] / sum(res_ml$sigma2), 3) # Within-article (between-exp.)

# # Profile likelihodd plots for checking that REML has converged
# profile(res_ml)
```

```{r, meta_analysis_bayes}
# Specify priors
prior_c <- c(
  set_prior("normal(0, 1)", class = "b"),
  set_prior("cauchy(0, 0.3)", class = "sd")
)

# Run prior predictive simulation
n_iter <- 20000
res_prior <- brm(
  gi | se(sei) ~ 0 + Intercept + (1 | article / experiment),
  data = dat,
  prior = prior_c,
  sample_prior = "only",
  save_pars = save_pars(all = TRUE),
  chains = 4,
  iter = n_iter,
  warmup = 1000,
  cores = 4,
  control = list(adapt_delta = 0.99)
)
summary(res_prior)
# plot(res_prior)

# Run Bayesian multilevel model
res_brm <- update(res_prior, sample_prior = FALSE)
summary(res_brm)
# plot(res_brm)

# Summarise fixed effects (incl. Bayes factors)
describe_posterior(
  res_brm,
  centrality = "mean", ci = 0.95, ci_method = "ETI",
  test = c("p_direction", "rope", "bayesfactor"),
  rope_range = c(-0.1, 0.1)
)

# Compute by-experiment variance
var_experiment <- as.matrix(
  res_brm,
  variable = "sd_article:experiment__Intercept"
)^2
mean_qi(var_experiment)

# Compute by-article variance
var_article <- as.matrix(
  res_brm,
  variable = "sd_article__Intercept"
)^2
mean_qi(var_article)

# Compute intra-class correlation
var_total <- (var_experiment + var_article)
icc_draws <- var_article / var_total
mean_qi(icc_draws)
```

```{r, fig_forest}
# Helper functions for printing confidence intervals
print_num <- function(x, digits = 2) {
  x <- format(round(x, digits), trim = TRUE, nsmall = digits)
  x[x == "NA"] <- NA
  return(x)
}
print_ci <- function(est, lb, ub) {
  paste0(print_num(est), " [", print_num(lb), ", ", print_num(ub), "]")
}

# Get posterior draws for each experiment
draws <- epred_draws(res_brm, dat, ndraws = NULL) %>%
  mutate(experiment_f = factor(experiment))

# Get posterior draws for the meta-analytic effect
meta_draws <- spread_draws(res_brm, b_Intercept, ndraws = NULL)
meta_effect_size <- summary(res_brm)$fixed

# Create forest plot
n_experiments <- length(unique(dat$experiment))
dat %>%
  # Make sure the plot will be ordered alphabetically by experiment IDs
  arrange(experiment) %>%
  mutate(
    experiment_f = fct_rev(fct_expand(factor(experiment), "model")),
    # Show article labels only for the first experiment per article
    article = if_else(article == lag(article, default = ""), "", article),
    # Compute frequentist confidence intervals
    ci_lb = gi - qnorm(0.05 / 2, lower.tail = FALSE) * sqrt(vi),
    ci_ub = gi + qnorm(0.05 / 2, lower.tail = FALSE) * sqrt(vi),
    ci_print = print_ci(gi, ci_lb, ci_ub)
  ) %>%
  # Prepare plotting canvas
  ggplot(aes(x = gi, y = experiment_f)) +
  geom_vline(xintercept = seq(-3, 3, 0.5), color = "grey90") +
  # Add article and group labels as text on the left
  geom_text(aes(x = -9.9, label = article), hjust = 0) +
  geom_text(aes(x = -7.1, label = group_long), hjust = 0) +
  # Add experiment-specific effect sizes and CIs as text on the right
  geom_text(aes(x = 3.7, label = print_num(gi)), hjust = 1) +
  geom_text(aes(x = 4.4, label = print_num(ci_lb)), hjust = 1) +
  geom_text(aes(x = 5.1, label = print_num(ci_ub)), hjust = 1) +
  # Add Bayesian highest posterior density intervals for each experiment
  stat_interval(
    aes(x = .epred),
    data = draws,
    alpha = .8,
    point_interval = "mean_qi",
    .width = c(0.5, 0.95),
  ) +
  scale_color_grey(
    start = 0.85, end = 0.65,
    labels = as_mapper(~ scales::percent(as.numeric(.x)))
  ) +
  # Add experiment-specific effect sizes and CIs as dots with error bars
  geom_linerange(aes(xmin = ci_lb, xmax = ci_ub), size = 0.35) +
  geom_point(aes(size = ni), shape = 22, fill = "white") + # Or (1 / vi)?
  # Add posterior distribution for the meta-analytic effect
  stat_halfeye(
    aes(x = b_Intercept, y = -1),
    meta_draws,
    point_interval = "mean_qi",
    .width = c(0.95)
  ) +
  annotate(
    "text",
    x = c(-9.9, 3.7, 4.4, 5.1),
    y = -0.5,
    label = c(
      "Three-level model",
      print_num(meta_effect_size$Estimate),
      print_num(meta_effect_size$`l-95% CI`),
      print_num(meta_effect_size$`u-95% CI`)
    ),
    hjust = c(0, 1, 1, 1),
    fontface = "bold"
  ) +
  # Add headers for each of the for columns
  annotate( # Just to make the grid lines disappear
    "rect",
    xmin = -Inf,
    xmax = Inf,
    ymin = n_experiments + 0.5,
    ymax = Inf,
    fill = "white"
  ) +
  annotate(
    "text",
    x = c(-9.9, -7.1, 0, 3.7, 4.4, 5.1),
    y = n_experiments + 1.5,
    label = c(
      "Article",
      "Experiment",
      "Effect size plot",
      "Effect size",
      "Lower",
      "Upper"
    ),
    hjust = c(0, 0, 0.5, 1, 1, 1),
    fontface = "bold"
  ) +
  # Styling
  coord_cartesian(
    ylim = c(-1.5, n_experiments + 2), expand = FALSE, clip = "off"
  ) +
  scale_x_continuous(breaks = seq(-3, 3, 0.5)) +
  annotate("segment", x = -3.3, xend = 3.3, y = -1.5, yend = -1.5) +
  labs(
    x = expression("Hedges'" ~ italic("g")),
    size = "Sample size",
    color = "CrI level"
  ) +
  theme_minimal() +
  theme(
    legend.position = "bottom",
    axis.text.x = element_text(family = "Helvetica", color = "black"),
    axis.text.y = element_blank(),
    axis.ticks.x = element_line(colour = "black"),
    axis.title.x = element_text(hjust = 0.67, margin = margin(b = -15)),
    axis.title.y = element_blank(),
    panel.grid = element_blank(),
    text = element_text(family = "Helvetica")
  )

# Save the plot
ggsave(here(figures_dir, "forest.pdf"), width = 12, height = 14)
```

```{r, tab_within}
# Helper functions to re-format age in years and/or months
format_days_months <- function(days) {
  days_per_month <- 30.417
  months <- days %/% days_per_month
  days_left <- round(days - months * days_per_month)
  str <- paste0(as.character(months), "m ", as.character(days_left), "d")
  str[is.na(days)] <- NA
  return(str)
}

# Save within-analysis table of experiments
dat %>%
  mutate(
    age_mean = format_days_months(age_mean),
    age_sd = str_c(as.character(round(age_sd)), "d"),
  ) %>%
  transmute(
    Article = if_else(article == lag(article, default = ""), "", article),
    Experiment = group_long,
    `Sample size` = sample_size,
    `Females` = round(female_percent * sample_size),
    Age = str_c(age_mean, "±", age_sd, sep = " "),
    Task = task,
    `Stimulus type` = str_to_sentence(stimuli_presentation),
    `Stimulus dimensions` = stimuli_dimensions
  ) %>%
  write_csv(
    file = here(tables_dir, "within_experiments.csv"),
    na = "n/a"
  )
```

## Moderator variables

```{r, meta_regression}
# Recode predictor variables for meta-regression and plotting
dat %>%
  mutate(

    # Gender as a categorical (factor) variable
    gender = case_when(
      female_percent == 1.0 ~ "Female",
      female_percent == 0.0 ~ "Male",
      TRUE ~ "Mixed"
    ) %>% factor(levels = c("Mixed", "Female", "Male")),

    # Mean sample age in years, centered around the mean
    age = age_mean / 365.25,
    age_c = age - mean(age, na.rm = TRUE),
    age_sd = age_sd / 365.25,

    # Task type as a categorical (factor) variale
    task = factor(task, levels = c("Habituation", "VoE")),

    # Combine gender and task into one column for plotting
    gender_task = factor(
      str_c(gender, task, sep = ", "),
      levels = c(
        "Female, Habituation",
        "Male, Habituation",
        "Mixed, Habituation",
        "Mixed, VoE"
      )
    )
  ) -> dat_reg

# Set numerical contrasts for factor variables
contrasts(dat_reg$gender) <- MASS::contr.sdif(3)
contrasts(dat_reg$task) <- MASS::contr.sdif(2)

# Meta-regression with gender, age, and task
res_reg <- rma.mv(
  gi, vi,
  mods = ~ gender * age_c + task,
  random = ~ 1 | article / experiment,
  data = dat_reg,
  slab = experiment
)
print(res_reg)
# forest(res_full)
```

```{r, meta_regression_bayes}
# Specify priors
prior_c <- c(
  set_prior("normal(0, 1)", class = "b", coef = "Intercept"),
  set_prior("normal(0, 0.5)", class = "b"),
  set_prior("cauchy(0, 0.3)", class = "sd")
)

# Run prior predictive simulation
res_prior_reg <- brm(
  gi | se(sei) ~ 0 + Intercept + gender * age_c + task +
    (1 | article / experiment),
  data = dat_reg,
  prior = prior_c,
  sample_prior = "only",
  save_pars = save_pars(all = TRUE),
  chains = 4,
  iter = n_iter,
  warmup = 1000,
  cores = 4,
  control = list(adapt_delta = 0.99)
)
summary(res_prior_reg)
# plot(res_prior_reg)

# Run Bayesian multilevel model
res_brm_reg <- update(res_prior_reg, sample_prior = FALSE)
summary(res_brm_reg)
# plot(res_brm_reg)

# Summarise fixed effects (incl. Bayes factors)
describe_posterior(
  res_brm_reg,
  centrality = "mean", ci = 0.95, ci_method = "ETI",
  test = c("p_direction", "rope", "bayesfactor"),
  rope_range = c(-0.1, 0.1)
)

# Compute by-experiment variance
var_experiment_reg <- as.matrix(
  res_brm_reg,
  variable = "sd_article:experiment__Intercept"
)^2
mean_qi(var_experiment_reg)

# Compute by-article variance
var_article_reg <- as.matrix(
  res_brm_reg,
  variable = "sd_article__Intercept"
)^2
mean_qi(var_article_reg)

# Compute intra-class correlation
var_total_reg <- var_experiment_reg + var_article_reg
icc_reg <- var_article_reg / var_total_reg
mean_qi(icc_reg)

# Compute reduction in heterogeneity compared to the original meta-analysis
1 - mean(var_total_reg / var_total)
```

```{r, fig_regression}
# Get draws from the posterior distribution
draws_reg <- epred_draws(
  res_brm_reg,
  dat_reg,
  ndraws = NULL,
  re_formula = NA
)

# Summarise to obtain HPDIs
draws_reg_hdi <- mean_qi(draws_reg)

# Use colors as proposed in https://arxiv.org/abs/2107.02270
habi_colors <- c(
  "Female, Habituation" = "#5790fc",
  "Male, Habituation" = "#f89c20",
  "Mixed, Habituation" = "#e42536"
)
voe_colors <- c("Mixed, VoE" = "#964a8b")

# Regression plot
dat_reg %>%
  ggplot(aes(x = age * 12, y = gi)) +
  geom_hline(yintercept = seq(-1, 2, 0.5), color = "grey90") +
  annotate(
    "rect",
    xmin = 5.5, xmax = Inf, ymin = 1.25, ymax = Inf,
    color = NA, fill = "white"
  ) +
  # Regression lines and HPDIs - Habituation tasks
  stat_lineribbon(
    aes(y = .epred, color = gender_task),
    data = draws_reg,
    alpha = .4,
    point_interval = "mean_qi",
    .width = c(0.5, 0.95)
  ) +
  # Individual study effect sizes - Habituation tasks
  geom_point(aes(color = gender_task, size = ni), shape = 0) +
  scale_color_manual(
    values = habi_colors,
    breaks = names(habi_colors),
    labels = c("Females", "Males", "Mixed gender"),
    na.value = NA
  ) +
  guides(color = guide_legend(
    title = "Habituation tasks",
    override.aes = list(fill = NA),
    order = 1
  )) +
  # Regression lines and HPDIs - VoE tasks
  ggnewscale::new_scale_color() +
  stat_lineribbon(
    aes(y = .epred, color = gender_task),
    data = draws_reg,
    fill = NA,
    alpha = .4,
    point_interval = "mean_qi",
    .width = c(0.5, 0.95)
  ) +
  # Individual study effect sizes - VoE tasks
  geom_point(aes(color = gender_task, size = ni), shape = 0) +
  scale_color_manual(
    values = voe_colors,
    breaks = names(voe_colors),
    labels = c("Mixed gender"),
    na.value = NA
  ) +
  guides(color = guide_legend(title = "VoE tasks", order = 2)) +
  # Styling
  coord_cartesian(expand = FALSE) +
  scale_x_continuous(limits = c(2.9, 16.1), breaks = seq(3, 16, 1)) +
  scale_y_continuous(limits = c(-1.2, 2.2), breaks = seq(-1, 2, 0.5)) +
  scale_fill_grey(
    start = 0.85, end = 0.65,
    labels = as_mapper(~ scales::percent(as.numeric(.x)))
  ) +
  labs(
    x = "Age (months)",
    y = expression("Hedges'" ~ italic("g")),
    fill = "CrI level",
    size = "Sample size"
  ) +
  theme_classic() +
  theme(
    axis.text = element_text(family = "Helvetica", color = "black"),
    axis.ticks = element_line(color = "black"),
    legend.direction = "vertical",
    legend.key = element_blank(),
    legend.position = "none",
    panel.grid = element_blank(),
    text = element_text(family = "Helvetica", color = "black")
  ) -> plot_reg

# Extract the legend so that we can put it inside the plotting area
plot_reg_legend <- get_legend(plot_reg + theme(legend.position = "top"))

# Define new labels for the regression coefficients
coef_colnames <- c(
  "Intercept" = "b_Intercept",
  "Females - mixed" = "b_gender2M1",
  "Males - females" = "b_gender3M2",
  "Age (per year)" = "b_age_c",
  "Habituation - VoE" = "b_task2M1",
  "(Females - Mixed) × age" = "b_gender2M1:age_c",
  "(Males - Females) × age" = "b_gender3M2:age_c"
)

# Plot posterior distributions of the regression coefficients
draws_reg_coef <- tidy_draws(res_brm_reg)
draws_reg_coef %>%
  select(all_of(coef_colnames)) %>%
  gather() %>%
  mutate(coef = factor(key, levels = names(coef_colnames))) %>%
  ggplot(aes(x = value, y = fct_rev(coef))) +
  geom_vline(xintercept = seq(-1, 1, 0.5), color = "grey90") +
  stat_halfeye(point_interval = "mean_qi", .width = c(0.5, 0.95)) +
  coord_cartesian(xlim = c(-1.25, 1.25), clip = "off") +
  scale_x_continuous(breaks = seq(-1, 1, 0.5)) +
  labs(x = expression("Regression weight (" * Delta * italic("g") * ")")) +
  annotate(
    "text",
    label = "Fixed effects", x = -3.175, y = 7.86, hjust = 0,
    family = "Helvetica", fontface = "bold", color = "black"
  ) +
  theme_minimal() +
  theme(
    axis.line.x = element_line(colour = "black"),
    axis.text.x = element_text(family = "Helvetica", color = "black"),
    axis.text.y = element_text(
      family = "Helvetica", color = "black", size = 3.88 * .pt,
      hjust = 0, vjust = -0.1, margin = margin(l = 20)
    ),
    axis.ticks.x = element_line(color = "black"),
    axis.ticks.y = element_blank(),
    axis.title.y = element_blank(),
    panel.grid = element_blank(),
    text = element_text(family = "Helvetica", color = "black")
  ) -> plot_coef

# Combine plots
plot_grid(
  plot_reg, plot_coef,
  nrow = 1, rel_widths = c(3, 2), labels = "auto",
  label_size = 11, label_fontfamily = "Helvetica",
  label_x = 0.008, label_y = 0.99
) +
  draw_plot(plot_reg_legend, x = 0.385, y = 0.865, hjust = 0.5, vjust = 0.5)

# Save plot
ggsave(here(figures_dir, "regression_coef.pdf"), width = 12, height = 5)
```

# Supplementary information

```{r, ri_assumed_sens}
# Compute empirical estimate of the correlation between dependent samples
dat %>%
  mutate(
    # Get effect size from paired samples t-test, one sample t-test, or ANOVA
    d_diff = case_when(
      !is.na(d) ~ d,
      !is.na(d_z_t) ~ d_z_t,
      !is.na(d_z_f) ~ d_z_f,
      !is.na(d_z_diff) ~ d_z_diff
    ),
    # Compute empirical correlation
    # Basesd on the SD of the difference and the SDs within the two conditions
    sd_diff = mean_diff / d_diff,
    ri = (sd_diff^2 - sd_novel^2 - sd_familiar^2) /
      (-2 * sd_novel * sd_familiar)
  ) %>%
  pull(ri) -> ri_empirical

# Summarise the estimated correlations
summary(ri_empirical)

# Re-run the meta-analysis for different values of r_assumed
seq(-0.9, 0.9, by = 0.3) %>%
  map_dfr(function(ri_sens) {

    # Re-compute standard errors of the effect sizes
    mutate(
      dat,
      vi = (dfi / (dfi - 2)) * ((2 * (1 - ri_sens)) / ni) *
        (1 + gi^2 * (ni / (2 * (1 - ri_sens)))) - (gi^2 / ji^2),
      sei = sqrt(vi)
    ) -> dat_ri_sens

    # Re-run meta-analysis
    res_ri_sens <- update(res_brm, newdata = dat_ri_sens, refresh = 0)

    # Compute ICC
    var_experiment_ri_sens <- as.matrix(
      res_ri_sens,
      variable = "sd_article:experiment__Intercept"
    )^2
    var_article_ri_sens <- as.matrix(
      res_ri_sens,
      variable = "sd_article__Intercept"
    )^2
    var_total_ri_sens <- var_experiment_ri_sens + var_article_ri_sens
    icc_ri_sens <- var_article_ri_sens / var_total_ri_sens
    icc_row <- mean_qi(icc_ri_sens) %>%
      rename(Estimate = y, `l-95% CI` = ymin, `u-95% CI` = ymax)

    # Extract summary statistics as a data frame row
    with(summary(res_ri_sens), bind_rows(fixed, bind_rows(random))) %>%
      bind_rows(icc_row) %>%
      transmute(
        parameter = c("Hedges' g", "SD_{article}", "SD_{experiment}", "ICC"),
        Estimate = print_ci(Estimate, `l-95% CI`, `u-95% CI`)
      ) %>%
      pivot_wider(names_from = parameter, values_from = Estimate) %>%
      bind_cols(`Assumed r_i` = print_num(ri_sens), .)
  }) -> tab_ri_sens

# Save the table
write_csv(tab_ri_sens, file = here(tables_dir, "ri_sens.csv"))
```

```{r, prior_sens}
# Prior sensitivity analysis
list(
  "interept_uninformative" = c(
    set_prior("uniform(-3, 3)", class = "Intercept"),
    set_prior("cauchy(0, 0.3)", class = "sd")
  ),
  "interept_informative" = c(
    set_prior("normal(0, 0.2)", class = "Intercept"),
    set_prior("cauchy(0, 0.3)", class = "sd")
  ),
  "sd_uninformative" = c(
    set_prior("normal(0, 1)", class = "Intercept"),
    set_prior("uniform(0, 10)", class = "sd", ub = 10)
  ),
  "sd_informative" = c(
    set_prior("normal(0, 1)", class = "Intercept"),
    set_prior("student_t(10, 0, 0.2)", class = "sd")
  )
) %>%
  map(function(prior_sens) update(res_brm, prior = prior_sens)) -> res_sens
map(res_sens, summary)
```
